[{"id": "f056cfa4-8caf-4dec-9ea4-f0f72788add5", "name": "Main", "value": [{"id": "94840f22-ac29-4abc-ac81-88a4bd33d9a2", "type": "block_code", "value": "if __name__ == '__main__':      # Skips next line if file was imported.\n    main()                      # Runs `def main(): ...` function."}], "sub_concepts": [], "short_description": "`__main__` is a special attribute that determines if a Python file is executed as the main program or imported as a module, enabling conditional code execution based on context.", "description": "In Python, the `__main__` module represents the entry point of a program when executed directly. It is a built-in attribute of modules used to determine whether a script is being run as the main module or if it's being imported into another module. When a Python file is executed, Python assigns the special value `__name__ = '__main__'` to the `__name__` variable within that script. This allows developers to write code that can be used both as an importable module and as a standalone program.\n\nThe significance of `__main__` lies in its ability to provide conditional execution, ensuring certain parts of the code only run when the file is executed directly rather than being imported. This pattern is widely utilized for testing or running scripts. For instance, encapsulating test functions within an `if __name__ == '__main__':` block ensures they don't execute during module imports in other contexts.\n\nThe design promotes modularity and reusability by allowing code to be packaged into functions or classes that can operate independently of their execution context. This is particularly useful for large-scale applications, where separating concerns (like configuration vs. functionality) enhances maintainability.\n\nUnderlying this mechanism are Python's module importing system and name resolution rules. When a script runs, it first processes all top-level code not inside functions or classes before assigning the `__name__` variable. This means that any initialization required for a script to function correctly as an import must precede this assignment.\n\nWhile PEPs specifically dedicated to `__main__` are scarce due to its fundamental nature, it plays a critical role in idiomatic Python code practices outlined in various community style guides and tutorials. For example, PEP 8 emphasizes the importance of clear separation between module initialization logic and script execution through this mechanism.\n\nAdvanced use cases include creating command-line interfaces (CLIs) where scripts can import utility functions from other modules while containing their own CLI-specific logic under `if __name__ == '__main__':`. It also facilitates test-driven development by allowing the inclusion of test suites directly in scripts that don't execute during regular imports.\n\nIn terms of performance, using `__main__` does not introduce significant overhead. However, it can impact code organization and readability, especially if overused or misapplied (e.g., placing substantial execution logic outside the main block). Proper structuring ensures clear separation between module-level definitions and script-specific logic.", "difficulty": "intermediate", "common_pitfalls": ["Placing substantial script-specific logic outside of the `if __name__ == '__main__':` block, leading to unintended execution during imports.", "Misunderstanding scope and initialization order when using `__main__`, which can lead to hard-to-debug errors if import time side effects occur.", "Failing to encapsulate test code within the main block, causing tests to run unintentionally when modules are imported."], "related_concepts": ["`import` statement", "Modules and Packages", "Name Resolution in Python", "PEP 8 -- Style Guide for Python Code", "Command-line Interfaces (CLI) with argparse or click"], "tags": []}, {"id": "a7ed27d1-5356-4707-aee0-96a5b8cd4547", "name": "List", "value": [{"id": "b0fb4608-5479-49a3-82ca-3aadef5405c4", "type": "block_code", "value": "<list> = [<el_1>, <el_2>, ...]  # Creates a list object. Also list(<collection>)."}, {"id": "ee3d8291-6b70-4a00-9313-4ed62c9714c1", "type": "block_code", "value": "<el>   = <list>[index]          # First index is 0. Last -1. Allows assignments.\n<list> = <list>[<slice>]        # Also <list>[from_inclusive : to_exclusive : \u00b1step]."}, {"id": "dfee7a15-d97a-4f6e-9e40-af81ec8e5e28", "type": "block_code", "value": "<list>.append(<el>)             # Appends element to the end. Also <list> += [<el>].\n<list>.extend(<collection>)     # Appends elements to the end. Also <list> += <coll>."}, {"id": "9a5575fc-d678-4584-87f8-d752947d95ab", "type": "block_code", "value": "<list>.sort()                   # Sorts elements in ascending order.\n<list>.reverse()                # Reverses the list in-place.\n<list> = sorted(<collection>)   # Returns new list with sorted elements.\n<iter> = reversed(<list>)       # Returns reversed iterator of elements."}, {"id": "7dd2a8f4-b150-411e-a24c-2c48814edf0c", "type": "block_code", "value": "<el>  = max(<collection>)       # Returns largest element. Also min(<el_1>, ...).\n<num> = sum(<collection>)       # Returns sum of elements. Also math.prod(<coll>)."}, {"id": "b9725a7a-727a-4b2b-a482-a799581c620e", "type": "block_code", "value": "elementwise_sum  = [sum(pair) for pair in zip(list_a, list_b)]\nsorted_by_second = sorted(<collection>, key=lambda el: el[1])\nsorted_by_both   = sorted(<collection>, key=lambda el: (el[1], el[0]))\nflatter_list     = list(itertools.chain.from_iterable(<list>))"}, {"id": "675eb5a4-317f-41a5-ac6b-a5da5e7e851c", "type": "list", "value": "<li><strong>For details about sort(), sorted(), min() and max() see <a href=\"#sortable\">Sortable</a>.</strong></li>\n<li><strong>Module <a href=\"#operator\">operator</a> has function itemgetter() that can replace listed <a href=\"#lambda\">lambdas</a>.</strong></li>\n<li><strong>This text uses the term collection instead of iterable. For rationale see <a href=\"#collection\">Collection</a>.</strong></li>"}, {"id": "c54f854a-11b6-46d0-ba1e-dede63778ae0", "type": "block_code", "value": "<int> = len(<list>)             # Returns number of items. Also works on dict, set and string.\n<int> = <list>.count(<el>)      # Returns number of occurrences. Also `if <el> in <coll>: ...`.\n<int> = <list>.index(<el>)      # Returns index of the first occurrence or raises ValueError.\n<el>  = <list>.pop()            # Removes and returns item from the end or at index if passed.\n<list>.insert(<int>, <el>)      # Inserts item at index and moves the rest to the right.\n<list>.remove(<el>)             # Removes first occurrence of the item or raises ValueError.\n<list>.clear()                  # Removes all items. Also works on dictionary and set."}], "sub_concepts": [], "short_description": "A versatile, mutable sequence type in Python, supporting dynamic resizing and a wide range of operations.", "description": "In Python, a `list` is a versatile, mutable sequence type that supports indexing, slicing, appending, removing elements, and several other operations. Lists are implemented as dynamic arrays, which means they allocate more space than necessary to accommodate future growth without having to resize the underlying array with each insertion. This strategy results in amortized constant time complexity for append operations, making lists highly efficient for tasks involving frequent additions.\n\nFrom an advanced perspective, Python lists support a wide range of operations that can be performed both in-place and returning new instances (e.g., `append()` vs. `+`). They are iterable, supporting the iterator protocol by implementing `__iter__` and `__next__`, making them compatible with loops, comprehensions, and functions like `map()`, `filter()`, etc. Lists can also contain mixed data types, providing flexibility but potentially impacting performance due to type-checking overhead.\n\nAdvanced use cases for lists include leveraging list comprehensions for concise construction of new lists by iterating over sequences or other iterables, utilizing nested lists for matrix-like structures, and employing slicing for efficient sub-sequence extraction. Moreover, the `list.sort()` method and its counterpart `sorted()` allow for customization via key functions and reverse sorting, enabling complex sorting operations on list elements.\n\nPerformance implications are notable; while list operations like indexing (`O(1)`) and appending (`amortized O(1)`) are efficient, searching or removing elements by value (`O(n)` in the worst case) can be costly for large datasets. Thus, alternative data structures such as sets or dictionaries might be preferred when lookup speed is critical.\n\nIn recent Python versions (3.9+), lists benefit from optimizations and additional methods like `list.remove(i, j)` for removing slices and enhancements to list comprehensions that support multiple input sequences through the `zip` function directly in the comprehension syntax. These improvements provide advanced users with more tools for writing clean, efficient code.", "difficulty": "Intermediate", "common_pitfalls": ["Overusing lists for performance-sensitive tasks where alternative data structures might be more appropriate (e.g., using sets or dictionaries for fast lookups).", "Forgetting that list comprehensions create new lists, leading to unnecessary memory usage if not used judiciously.", "Misunderstanding the mutability of lists; inadvertently modifying a list while iterating over it can lead to unexpected behavior.", "Ignoring the type-checking overhead when lists contain mixed data types."], "related_concepts": ["List Comprehensions", "Mutable Sequences", "Slicing", "Dynamic Arrays", "Iterators", "Tuples (for immutable sequences)", "Sets (for unique, unordered collections)", "Dictionaries (for key-value pairs)"], "tags": []}, {"id": "973449d2-62d9-47fc-9a45-69bb222df8d3", "name": "Dictionary", "value": [{"id": "8b2e3dd5-bb72-431c-bfbf-72faae60362a", "type": "block_code", "value": "<dict> = {key_1: val_1, key_2: val_2, ...}      # Use `<dict>[key]` to get or set the value."}, {"id": "a4bac44c-eadf-4e03-802d-e2aff23ee68b", "type": "block_code", "value": "<view> = <dict>.keys()                          # Collection of keys that reflects changes.\n<view> = <dict>.values()                        # Collection of values that reflects changes.\n<view> = <dict>.items()                         # Coll. of key-value tuples that reflects chgs."}, {"id": "96f16209-8546-4412-97d7-086c3e48c7f4", "type": "block_code", "value": "value  = <dict>.get(key, default=None)          # Returns default if key is missing.\nvalue  = <dict>.setdefault(key, default=None)   # Returns and writes default if key is missing.\n<dict> = collections.defaultdict(<type>)        # Returns a dict with default value `<type>()`.\n<dict> = collections.defaultdict(lambda: 1)     # Returns a dict with default value 1."}, {"id": "3ea04801-7a97-4fc3-8695-febfc0c7df1d", "type": "block_code", "value": "<dict> = dict(<collection>)                     # Creates a dict from coll. of key-value pairs.\n<dict> = dict(zip(keys, values))                # Creates a dict from two collections.\n<dict> = dict.fromkeys(keys [, value])          # Creates a dict from collection of keys."}, {"id": "b25ed780-9915-4213-976d-5b0baff8b79b", "type": "block_code", "value": "<dict>.update(<dict>)                           # Adds items. Replaces ones with matching keys.\nvalue = <dict>.pop(key)                         # Removes item or raises KeyError if missing.\n{k for k, v in <dict>.items() if v == value}    # Returns set of keys that point to the value.\n{k: v for k, v in <dict>.items() if k in keys}  # Filters the dictionary by keys."}], "sub_concepts": [{"id": "19087384-a333-485e-ac74-e0d7d73127d1", "name": "Counter", "value": [{"id": "91553bc8-283e-4b28-8fd1-265f52baf7df", "type": "block_code", "value": ">>> from collections import Counter\n>>> counter = Counter(['blue', 'blue', 'blue', 'red', 'red'])\n>>> counter['yellow'] += 1\n>>> print(counter.most_common())\n[('blue', 3), ('red', 2), ('yellow', 1)]"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "Dictionaries are mutable, hash-based collections that map keys to values with average O(1) time complexity for key operations and maintain insertion order since Python 3.7.", "description": "In Python, dictionaries are mutable, unordered collections of key-value pairs. They are implemented as hash tables, providing average-case time complexity of O(1) for lookup, insertion, and deletion operations. Starting with Python 3.7, dictionaries maintain the order of item insertion, which was officially guaranteed in PEP 468. This ordering is based on an internal mechanism that leverages a combination of arrays and linked lists to efficiently manage key hashing and collision resolution. Each entry in a dictionary consists of a hash table slot for quick access using hashed keys, while collisions are handled using open addressing with quadratic probing.\n\nAdvanced usage often involves leveraging dictionaries for tasks such as memoization, implementing caches or counters due to their rapid lookup capabilities. They can also be used effectively in metaprogramming contexts like decorators and context managers where dynamic mapping of functions and resources is required. Python's `collections.defaultdict` provides a subclass that allows the definition of default values, which can significantly simplify handling missing keys scenarios.\n\nPEPs relevant to dictionaries include PEP 3107 which introduced dictionary comprehension syntax and PEP 468 for insertion-order preservation. The `dict` type also supports methods like `.items()`, `.keys()`, and `.values()` that return view objects in Python 3, allowing dynamic updating of these views when the dictionary is modified.\n\nIn performance-sensitive applications, understanding how hash collisions and resizing affect dictionary operations can be crucial. Rehashing occurs when a threshold load factor is exceeded, which involves re-allocating memory and recalculating hashes for all keys, potentially impacting performance temporarily during this process. Thus, knowing how to pre-allocate dictionaries (using the `dict()` constructor with an initial size) or control their behavior through custom hash functions can be beneficial in high-performance scenarios.\n\nDictionaries are pivotal in Python's data model and serve as foundational structures for numerous standard library implementations like JSON parsing (`json` module), HTTP requests handling (`requests` library), and more. Understanding the internal workings of dictionaries, such as their resizing algorithm or how they maintain insertion order, can greatly enhance one's ability to write efficient, high-performing Python code.", "difficulty": "advanced", "common_pitfalls": ["Overlooking the impact of poor hash functions leading to performance degradation due to increased collisions.", "Failing to recognize that dictionaries do not guarantee iteration order prior to Python 3.7, which might lead to unexpected behavior in older versions.", "Using mutable objects as keys can result in unpredictable behaviors and errors since these objects' hash values may change during dictionary lifetime.", "Neglecting the cost of resizing operations in memory-constrained environments or when performing frequent insertions."], "related_concepts": ["Hash tables", "PEP 468 (Insertion Order Preservation)", "collections.defaultdict", "Dictionary comprehension", "Custom hash functions", "Memoization"], "tags": []}, {"id": "a182b984-e306-4f26-b535-9a5d78c19ac5", "name": "Set", "value": [{"id": "8ab02414-4458-4938-9c8a-353ecbfa2f77", "type": "block_code", "value": "<set> = {<el_1>, <el_2>, ...}                   # Use `set()` for empty set."}, {"id": "e79645a9-0032-4eac-8b94-90404bce6702", "type": "block_code", "value": "<set>.add(<el>)                                 # Or: <set> |= {<el>}\n<set>.update(<collection> [, ...])              # Or: <set> |= <set>"}, {"id": "54978be5-e589-40af-a55b-45da836b12c2", "type": "block_code", "value": "<set>  = <set>.union(<coll.>)                   # Or: <set> | <set>\n<set>  = <set>.intersection(<coll.>)            # Or: <set> & <set>\n<set>  = <set>.difference(<coll.>)              # Or: <set> - <set>\n<set>  = <set>.symmetric_difference(<coll.>)    # Or: <set> ^ <set>\n<bool> = <set>.issubset(<coll.>)                # Or: <set> <= <set>\n<bool> = <set>.issuperset(<coll.>)              # Or: <set> >= <set>"}, {"id": "3cfc67ae-c8a9-4187-bbc7-b3633a2c0261", "type": "block_code", "value": "<el> = <set>.pop()                              # Raises KeyError if empty.\n<set>.remove(<el>)                              # Raises KeyError if missing.\n<set>.discard(<el>)                             # Doesn't raise an error."}], "sub_concepts": [{"id": "5e96f735-b174-46f6-8d74-f2e9d658fdf7", "name": "Frozen Set", "value": [{"id": "431f269d-3df4-428d-847d-0b181fe77b40", "type": "list", "value": "<li><strong>Is immutable and hashable.</strong></li>\n<li><strong>That means it can be used as a key in a dictionary or as an element in a set.</strong></li>"}, {"id": "b04f98a6-a225-41d7-b0ca-af971ce5ca61", "type": "block_code", "value": "<frozenset> = frozenset(<collection>)"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "A set is an unordered collection of unique elements, optimized for fast membership tests and supporting mathematical set operations.", "description": "In Python, a `set` is an unordered collection of unique elements. It is mutable, allowing for dynamic updates such as adding or removing items. Sets are implemented using hash tables, which provide average-case constant time complexity O(1) for lookups, insertions, and deletions. This makes sets highly efficient for operations involving membership tests and deduplication.\n\nSets support a variety of mathematical set operations like union, intersection, difference, and symmetric difference. These operations are implemented efficiently due to the underlying hash table structure. For example, the union operation combines elements from two sets without duplicates, while intersection finds common elements between sets.\n\nIn Python 3.9 and later, the `|` operator can be used for set union and `-` for set difference, providing a more intuitive syntax compared to the traditional methods like `union()` or `difference()`. The introduction of these operators aligns with PEP 572, which aimed to enhance readability.\n\nSets are particularly useful in scenarios requiring uniqueness constraints or where operations on collections need to be optimized. For instance, they are commonly used for filtering duplicates from a list or checking the presence of an item efficiently. However, sets do not maintain order and cannot contain mutable elements like lists or other sets.\n\nFrom an advanced perspective, understanding how Python implements sets can provide insights into performance optimizations. The use of hash tables means that while average-case operations are O(1), worst-case scenarios (e.g., many hash collisions) could degrade to O(n). This is why choosing the right data structure for a task based on its characteristics and requirements is crucial.\n\nSets also support advanced features like set comprehensions, which allow for concise construction of sets with specific conditions. For example, `{x**2 for x in range(10) if x % 2 == 0}` creates a set of squares of even numbers from 0 to 9.\n\nIn summary, Python's `set` is a powerful tool for handling unique collections with efficient operations, crucial for performance-critical applications. However, its unordered nature and restriction against mutable elements require careful consideration in design choices.", "difficulty": "intermediate", "common_pitfalls": ["Attempting to use unhashable (mutable) types like lists or dictionaries as set elements.", "Assuming sets maintain insertion order, which can lead to unexpected behavior in certain applications.", "Overlooking the potential for hash collisions that could degrade performance."], "related_concepts": ["Dictionary", "List comprehension", "Hashing and hash tables", "Mutable vs Immutable types", "Set operations (union, intersection, etc.)"], "tags": []}, {"id": "8af20375-bd8d-4aa6-a448-b3b26deedbc2", "name": "Tuple", "value": [{"id": "4d88142b-3aa3-4c98-ad0d-a64c5cd66dca", "type": "paragraph", "value": "<strong>Tuple is an immutable and hashable list.</strong>"}, {"id": "d24d668c-e7df-44ce-91d3-78e852a44fc1", "type": "block_code", "value": "<tuple> = ()                               # Empty tuple.\n<tuple> = (<el>,)                          # Or: <el>,\n<tuple> = (<el_1>, <el_2> [, ...])         # Or: <el_1>, <el_2> [, ...]"}], "sub_concepts": [{"id": "6b3ef821-2b7c-47bf-aedd-f92987f12c8c", "name": "Named Tuple", "value": [{"id": "2487f9dd-b0d9-4145-b30f-db80157381d1", "type": "paragraph", "value": "<strong>Tuple's subclass with named elements.</strong>"}, {"id": "3b7d6a21-fbd5-4856-9fce-b9bf8ed50676", "type": "block_code", "value": ">>> from collections import namedtuple\n>>> Point = namedtuple('Point', 'x y')\n>>> p = Point(1, y=2)\n>>> print(p)\nPoint(x=1, y=2)\n>>> p[0], p.x\n(1, 1)"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "A tuple is an immutable sequence type optimized for fixed collections of items, enabling efficient memory usage and supporting multiple return values from functions.", "description": "In Python, a tuple is an immutable sequence type that can hold a collection of items. Tuples are defined by enclosing the values in parentheses `()`, separated by commas. Unlike lists, which are mutable, tuples cannot be changed once created; this immutability provides several advantages, such as allowing them to be used as keys in dictionaries and elements in sets, unlike lists.\n\nTuples are optimized for performance compared to lists due to their immutable nature. They consume less memory than lists because they do not need additional space to handle element changes. The underlying C implementation of tuples is more efficient when dealing with fixed collections of items, which also makes them ideal for use as records or data that should remain constant throughout the program's execution.\n\nTuples support all sequence operations like indexing and slicing, but since they are immutable, methods like `append`, `extend`, or `pop` are not applicable. Instead, functions such as `len()` can be used to get the tuple length, while concatenation can create new tuples using the `+` operator.\n\nFrom an advanced perspective, understanding how tuples work with Python's memory management and garbage collection is crucial. Tuples' immutability means they are hashable; thus, Python stores them efficiently in memory, reusing instances of identical tuples to save space (interning). This behavior can have significant performance implications, especially when working with large datasets or frequently accessed values.\n\nTuples also play a critical role in multiple return values from functions and unpacking sequences. By returning tuples, functions can provide multiple outputs simultaneously, which are then easily unpacked into variables using the assignment syntax. The `*` operator introduced in PEP 448 allows for extended iterable unpacking, where it can capture additional items as part of a tuple during assignments.\n\nFurthermore, tuples can be used effectively with advanced Python features like decorators and context managers to manage resources or maintain state across function calls without side effects. Understanding these mechanisms offers developers flexibility and power in structuring their applications efficiently.", "difficulty": "advanced", "common_pitfalls": ["Attempting to modify a tuple after its creation raises a TypeError.", "Overlooking the fact that tuples are hashable while lists are not, leading to errors when using tuples as dictionary keys or set elements.", "Forgetting that Python uses tuple interning for small integers and short strings; thus, identical tuples can point to the same memory location, which may not be apparent in terms of performance.", "Misunderstanding the behavior of extended iterable unpacking, particularly with `*` used in assignment."], "related_concepts": ["List", "Immutable types", "Sequence operations", "Memory management", "Garbage collection", "Unpacking", "Multiple return values", "Hashable objects"], "tags": []}, {"id": "f8194220-0542-4dc3-b87a-c118823bf9e3", "name": "Range", "value": [{"id": "8f267463-5c9f-4b65-8363-d64b58cf157f", "type": "paragraph", "value": "<strong>Immutable and hashable sequence of integers.</strong>"}, {"id": "3aae8ac0-55b6-4a7d-a38e-0b745a5de94d", "type": "block_code", "value": "<range> = range(stop)                      # I.e. range(to_exclusive).\n<range> = range(start, stop)               # I.e. range(from_inclusive, to_exclusive).\n<range> = range(start, stop, \u00b1step)        # I.e. range(from_inclusive, to_exclusive, \u00b1step)."}, {"id": "e45d1788-ebad-4f11-88bf-48733533aad7", "type": "block_code", "value": ">>> [i for i in range(3)]\n[0, 1, 2]"}], "sub_concepts": [], "short_description": "`range()` generates an immutable sequence of numbers used for iteration, optimized for memory efficiency by computing values on-the-fly.", "description": "The `range()` function in Python is a versatile tool that generates a sequence of numbers. It is commonly used for iteration in loops, particularly `for` loops. Unlike lists, `range()` returns an immutable sequence type, which means it doesn't store all the numbers in memory at once but rather computes each number on-the-fly as needed. This lazy evaluation makes `range()` highly efficient when dealing with large sequences, as it significantly reduces memory usage compared to generating a list of numbers.\n\nIntroduced in Python 2.0 and refined over subsequent versions, `range()` supports three arguments: start, stop, and step, where 'start' is the beginning value (inclusive), 'stop' is the ending value (exclusive), and 'step' defines the increment between each number in the sequence. The function's signature is `range([start], stop[, step])`. If only one argument is provided, it is treated as the 'stop' value with a default start of 0 and a step of 1.\n\nAdvanced usage of `range()` often involves its interaction with other iterable types and functions. For instance, when combined with list comprehensions or generator expressions, `range()` can be used to create complex sequences efficiently. Additionally, the introduction of Python 3's `range()` as an immutable sequence type aligns it closely with `xrange()` from Python 2, which was a memory-efficient iterator. This change reflects Python's ongoing commitment to improving performance and resource management.\n\nIn terms of performance implications, using `range()` is generally more efficient than creating lists for iteration due to its lazy evaluation. This efficiency becomes particularly important in data-intensive applications or when working with large datasets where memory constraints are a concern. Furthermore, the integration of `range()` with Python's iterator protocol allows it to be used seamlessly with other iterable-based functions like `zip()`, `map()`, and `filter()`, enhancing its utility in functional programming paradigms.\n\nThe concept of `range()` is also closely tied to PEP 255, which introduced generator functions and expressions, providing a foundation for lazy evaluation patterns in Python. While `range()` itself is not a generator, its design philosophy shares similarities with the lazy evaluation approach that generators embody.\n\nIn summary, `range()` is an essential tool for generating number sequences efficiently in Python, particularly beneficial for iterating over large ranges without consuming significant memory resources. Its design and functionality make it a cornerstone of efficient looping constructs in both simple scripts and complex applications.", "difficulty": "intermediate", "common_pitfalls": ["Forgetting that `range()` excludes the stop value, leading to off-by-one errors.", "Using `range()` with non-integer step sizes or types other than integers, which raises a TypeError.", "Attempting to modify a `range` object directly since it is immutable.", "Overlooking performance benefits by substituting `range()` with list comprehensions for large sequences."], "related_concepts": ["List Comprehensions", "Generator Expressions", "Iterators", "Iterator Protocol", "Memory Management in Python", "Functional Programming Constructs"], "tags": []}, {"id": "cb836710-749e-4442-bb62-fec95f4099dd", "name": "Enumerate", "value": [{"id": "d8104612-3f52-43cc-8e41-22811da5dba8", "type": "block_code", "value": "for i, el in enumerate(<coll>, start=0):   # Returns next element and its index on each pass.\n    ..."}], "sub_concepts": [], "short_description": "`enumerate()` adds a counter to any iterable and returns it as an enumerate object, facilitating the retrieval of both indices and values during loops.", "description": "The `enumerate()` function in Python is a built-in utility that transforms any iterable into an iterator of tuples, where each tuple contains the index of the item and the item itself. This function simplifies the process of looping over both the indices and elements of an iterable, which is particularly useful when you need to track element positions during iteration. The signature of `enumerate()` is: `enumerate(iterable, start=0)`. Here, `iterable` is any object capable of returning its members one at a time (e.g., list, string), and `start` specifies the starting index for the enumeration.\n\nInternally, `enumerate()` leverages Python's iterator protocol. It yields tuples `(index, element)` by maintaining an internal state of both the current position in the iterable and the value obtained from calling the `__next__()` method on it. This mechanism ensures that each call to `next()` on the resulting enumerate object provides a tuple with the next index and corresponding element, incrementing the index appropriately.\n\nAdvanced use cases include integrating with list comprehensions or generator expressions for complex data transformations where indexed operations are necessary. Moreover, when combined with unpacking in loops (`for i, value in enumerate(iterable)`), it elegantly sidesteps common pitfalls like manually managing an index variable.\n\nPerformance implications of using `enumerate()` over manual indexing (e.g., using a range-based loop) are minimal for most cases since the function itself is highly optimized. However, `enumerate()` can be particularly advantageous when working with large datasets or within functions where maintaining code readability and reducing cognitive load are paramount.\n\nIn terms of relevant Python Enhancement Proposals (PEPs), while there isn't one specifically dedicated to `enumerate()`, PEP 3102 introduced iterable unpacking in for-loops, which complements the use of `enumerate()` by simplifying syntax and improving clarity. Additionally, PEP 484 discusses type hints, which can be applied when using `enumerate()` with more complex iterables to ensure better static analysis.\n\nOverall, `enumerate()` is an elegant solution provided by Python to handle indexed iteration without resorting to less efficient or error-prone manual index tracking.", "difficulty": "Intermediate", "common_pitfalls": ["Forgetting that `enumerate()` produces a new iterator; each call will recompute results unless explicitly stored.", "Overlooking that the starting index defaults to 0; failing to specify it when a different start is needed can lead to off-by-one errors.", "Confusing `enumerate()` with functions like `zip()`, which serve different purposes in handling multiple iterables.", "Neglecting the potential of combining `enumerate()` with slicing, unpacking, and other iterable operations for more complex data manipulation."], "related_concepts": ["Iterator Protocol", "List Comprehensions", "Generator Expressions", "Unpacking in Loops", "Slicing", "zip()"], "tags": []}, {"id": "635d3297-10f9-4c48-8ce4-774dc34d4ee7", "name": "Iterator", "value": [{"id": "e58e5c88-5984-40a2-adfc-872863a6c6f9", "type": "paragraph", "value": "<strong>Potentially endless stream of elements.</strong>"}, {"id": "104379f2-9ed4-46ec-bfe7-a0c7bd758b4a", "type": "block_code", "value": "<iter> = iter(<collection>)                # `iter(<iter>)` returns unmodified iterator.\n<iter> = iter(<function>, to_exclusive)    # A sequence of return values until 'to_exclusive'.\n<el>   = next(<iter> [, default])          # Raises StopIteration or returns 'default' on end.\n<list> = list(<iter>)                      # Returns a list of iterator's remaining elements."}], "sub_concepts": [{"id": "1d0cef81-6b7b-403c-b0e8-cca2ebaf8bc3", "name": "Itertools", "value": [{"id": "2b49b65e-db34-4140-b8aa-901d10666c37", "type": "block_code", "value": "import itertools as it"}, {"id": "7d4a1b6d-c18f-41b8-9f7b-7464f7c83578", "type": "block_code", "value": "<iter> = it.count(start=0, step=1)         # Returns updated value endlessly. Accepts floats.\n<iter> = it.repeat(<el> [, times])         # Returns element endlessly or 'times' times.\n<iter> = it.cycle(<collection>)            # Repeats the sequence endlessly."}, {"id": "d57c3df0-e8d0-4be5-8013-1451763dae95", "type": "block_code", "value": "<iter> = it.chain(<coll>, <coll> [, ...])  # Empties collections in order (figuratively).\n<iter> = it.chain.from_iterable(<coll>)    # Empties collections inside a collection in order."}, {"id": "04326cbe-9a74-4f11-8210-a613e5ca045c", "type": "block_code", "value": "<iter> = it.islice(<coll>, to_exclusive)   # Only returns first 'to_exclusive' elements.\n<iter> = it.islice(<coll>, from_inc, \u2026)    # `to_exclusive, +step_size`. Indices can be None."}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "An iterator is an object adhering to the iterator protocol, enabling efficient element-by-element traversal of collections in Python through lazy evaluation.", "description": "In Python, an iterator is a fundamental construct that allows for iterating over elements of a container or sequence in a memory-efficient manner. Iterators adhere to the iterator protocol, which consists of two essential methods: `__iter__()` and `__next__()`. The `__iter__()` method returns the iterator object itself, enabling it to be used with constructs like loops (e.g., `for` loops). The `__next__()` method retrieves the next element in the sequence, raising a `StopIteration` exception when no further elements are available. This design allows for lazy evaluation of sequences, meaning elements are computed on-demand rather than stored in memory all at once.\n\nPython's iterators enable efficient data processing with minimal memory overhead, making them ideal for working with large datasets or infinite streams. The underlying mechanism leverages the object-oriented nature of Python, encapsulating state and control flow within iterator objects. This is particularly powerful when combined with generator functions (which yield values one at a time) to produce custom iterable sequences without precomputing an entire dataset.\n\nPerformance-wise, iterators can significantly reduce memory usage compared to list comprehensions or equivalent constructs that generate full lists in memory. For example, using generators or the `itertools` module's iterator-producing functions allows for creating complex pipelines of data transformations with minimal resource consumption. Advanced users leverage iterators to create custom iterable objects by implementing the iterator protocol, enabling integration with Python\u2019s built-in iteration tools.\n\nCommon advanced use cases include customizing data traversal and processing workflows using generators, integrating with asynchronous programming patterns via `async` iterators (introduced in PEP 492), and employing `__iter__()` for classes to make them iterable. In addition, the iterator protocol is crucial for understanding how Python's iteration mechanics work under the hood, such as in comprehensions, unpacking operations, and functions like `zip()`, `map()`, and `filter()`. The use of iterators aligns well with functional programming paradigms embraced by advanced Python developers.\n\nRelevant PEPs include PEP 255 which introduced generators, providing a straightforward way to implement the iterator protocol, and PEP 492 for asynchronous iteration. These enhancements allow developers to write cleaner, more efficient code that can handle complex data processing tasks with ease.", "difficulty": "advanced", "common_pitfalls": ["Forgetting that `__next__()` raises a StopIteration exception when there are no more elements, leading to runtime errors if not handled properly.", "Confusing iterators with iterables; while all iterators are iterables, not all iterables are iterators as some can be traversed multiple times (e.g., lists).", "Overlooking the memory benefits of using iterators in contexts where large datasets or infinite sequences are involved.", "Misunderstanding how to reset an iterator, since they cannot be reused once exhausted; a new iterator must be created for another pass."], "related_concepts": ["Generator", "Iterable", "Comprehensions", "Asynchronous Iterators (async generators)", "PEP 255", "PEP 492"], "tags": []}, {"id": "04ec7834-bc72-4bca-8613-901874e2f368", "name": "Generator", "value": [{"id": "4669cd74-565e-40be-ae30-82512c8f8a1d", "type": "list", "value": "<li><strong>Any function that contains a yield statement returns a generator.</strong></li>\n<li><strong>Generators and iterators are interchangeable.</strong></li>"}, {"id": "fd199e1a-d1c5-4563-8216-dc9a01462597", "type": "block_code", "value": "def count(start, step):\n    while True:\n        yield start\n        start += step"}, {"id": "9a87a407-c1de-4263-9787-34fcfa4ca913", "type": "block_code", "value": ">>> counter = count(10, 2)\n>>> next(counter), next(counter), next(counter)\n(10, 12, 14)"}], "sub_concepts": [], "short_description": "Generators provide an efficient way to iterate over data without storing it all in memory, using `yield` for lazy evaluation.", "description": "Generators in Python are a sophisticated tool for creating iterators in a memory-efficient manner. They allow developers to iterate over sequences of data without the need to store the entire sequence in memory, which is particularly advantageous when working with large datasets or streams of data. A generator function is defined like a regular function but uses the `yield` statement instead of `return`. When called, it returns an iterator that can be iterated upon (e.g., using a for loop). Each call to `next()` on this iterator resumes execution of the generator function until another `yield` is encountered. This behavior adheres to the iterator protocol, which requires implementing `__iter__()` and `__next__()`, but generators abstract these details away from the user.\n\nGenerators are an implementation of the iterator protocol with a few key benefits: they automatically keep track of their internal state, only produce one value at a time (hence being lazily evaluated), and free up resources once exhausted. The use of `yield` allows for values to be generated on-the-fly, which can significantly reduce memory overhead when compared to building and storing lists or other iterable objects in memory.\n\nPerformance-wise, generators are optimal for large datasets due to their lazy evaluation; they compute one element at a time, thus reducing initial load times and memory usage. They're especially useful in pipeline processing where each step feeds into the next without requiring intermediate storage of entire sequences.\n\nAdvanced use cases include generating infinite sequences, creating co-routines using `yield from`, which simplifies generator delegation by yielding all values from another generator or iterable. In terms of performance implications, while generators save memory, they can sometimes introduce overhead due to function calls and state maintenance. However, for I/O bound tasks and when processing streams of data, the trade-off is often worthwhile.\n\nGenerators are also central to asynchronous programming in Python, especially with `asyncio`, where coroutines behave much like generator functions but are designed to be non-blocking. Understanding generators is crucial when working on any form of lazy evaluation or stream processing in Python, and their design is a powerful example of the language's support for functional programming patterns.\n\nSeveral PEPs have been introduced that impact generator functionality, such as PEP 342 which formalized generator expressions akin to list comprehensions but returning generators instead. Another related concept is PEP 525 on coroutine-related syntax like `async` and `await`, which evolved from generators' capabilities.", "difficulty": "advanced", "common_pitfalls": ["Confusing generator functions with regular functions due to similar syntax but different execution (lazily evaluated).", "Attempting to reuse a generator after exhaustion without reinitializing, as generators are single-use objects.", "Forgetting that `yield` expressions can be used for sending values back into the generator via the `.send()` method.", "Overlooking that a `return` statement in a generator function will raise a `StopIteration` exception with the return value."], "related_concepts": ["Iterator Protocol", "Generator Expressions", "Yield From (Delegation)", "Coroutine and Asyncio", "Lazy Evaluation", "Iterable Objects"], "tags": []}, {"id": "210c5a34-18ff-4300-ba98-9fb6802991b8", "name": "Type", "value": [{"id": "97610a75-2f5d-46e2-a03a-07f9d28bb283", "type": "list", "value": "<li><strong>Everything is an object.</strong></li>\n<li><strong>Every object has a type.</strong></li>\n<li><strong>Type and class are synonymous.</strong></li>"}, {"id": "9910cadc-9dfd-484e-85ed-58246aeff443", "type": "block_code", "value": "<type> = type(<el>)                          # Or: <el>.__class__\n<bool> = isinstance(<el>, <type>)            # Or: issubclass(type(<el>), <type>)"}, {"id": "0216ec2b-037c-429e-828c-dd424f55e2b3", "type": "block_code", "value": ">>> type('a'), 'a'.__class__, str\n(<class 'str'>, <class 'str'>, <class 'str'>)"}, {"id": "e7b83ea9-6d7f-4182-8de5-a4842ccad58e", "type": "heading", "value": "Some types do not have built-in names, so they must be imported:"}, {"id": "7bd536f8-01f1-4a85-8c44-8aa000491105", "type": "block_code", "value": "from types import FunctionType, MethodType, LambdaType, GeneratorType, ModuleType"}], "sub_concepts": [{"id": "57f8df50-ca59-44ce-b023-0622c6543be7", "name": "Abstract Base Classes", "value": [{"id": "bd8228b0-cf0a-4ebd-807d-abf67cc3982a", "type": "paragraph", "value": "<strong>Each abstract base class specifies a set of virtual subclasses. These classes are then recognized by isinstance() and issubclass() as subclasses of the ABC, although they are really not. ABC can also manually decide whether or not a specific class is its virtual subclass, usually based on which methods the class has implemented. For instance, Iterable ABC looks for method iter(), while Collection ABC looks for iter(), contains() and len().</strong>"}, {"id": "b8a64ef5-a28a-46e8-8855-63db8b5b02d6", "type": "block_code", "value": ">>> from collections.abc import Iterable, Collection, Sequence\n>>> isinstance([1, 2, 3], Iterable)\nTrue"}, {"id": "fc11db05-c6ef-402c-8ee4-486d8d314470", "type": "block_code", "value": "+------------------+------------+------------+------------+\n|                  |  Iterable  | Collection |  Sequence  |\n+------------------+------------+------------+------------+\n| list, range, str |    yes     |    yes     |    yes     |\n| dict, set        |    yes     |    yes     |            |\n| iter             |    yes     |            |            |\n+------------------+------------+------------+------------+"}, {"id": "8786f334-d3c6-46ef-9db7-81946437d974", "type": "block_code", "value": ">>> from numbers import Number, Complex, Real, Rational, Integral\n>>> isinstance(123, Number)\nTrue"}, {"id": "24635ce3-ee78-4285-b27a-d29ead6d7086", "type": "block_code", "value": "+--------------------+----------+----------+----------+----------+----------+\n|                    |  Number  |  Complex |   Real   | Rational | Integral |\n+--------------------+----------+----------+----------+----------+----------+\n| int                |   yes    |   yes    |   yes    |   yes    |   yes    |\n| fractions.Fraction |   yes    |   yes    |   yes    |   yes    |          |\n| float              |   yes    |   yes    |   yes    |          |          |\n| complex            |   yes    |   yes    |          |          |          |\n| decimal.Decimal    |   yes    |          |          |          |          |\n+--------------------+----------+----------+----------+----------+----------+"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "`type` is a built-in function in Python that returns an object's type, allows dynamic class creation, and serves as the default metaclass.", "description": "The `type` function in Python is a built-in utility that serves multiple purposes: it can return the type of an object, create new types (dynamic class creation), and act as a metaclass. In its simplest use-case, invoking `type(obj)` returns the type of the specified object. Beyond this fundamental functionality, `type` allows for dynamic creation of classes at runtime via the syntax `type(name, bases, dict)`, where `name` is the desired name of the new class, `bases` is a tuple containing base classes (which can be empty for a pure data class), and `dict` is a dictionary of attributes and methods. This dynamic creation capability makes it a powerful metaprogramming tool, enabling patterns often seen in frameworks that require flexibility.\n\nWhen used as a metaclass by assigning `type` to the `__metaclass__` attribute (in Python 2) or `metaclass` keyword argument (Python 3+), it allows for customizing class creation. This can be useful for enforcing certain conventions, automating registration of subclasses, or adding logging for class instantiation events. The default metaclass is `type`, which provides a base template for how classes in Python are constructed.\n\nUnderstanding the implications of using `type` dynamically involves recognizing its impact on performance and maintainability. Dynamically created types can make code more flexible but may also complicate debugging and readability due to their non-static nature. This flexibility comes with potential pitfalls, such as unexpected runtime errors if attribute names in the dictionary clash with Python's reserved keywords or method overrides.\n\nAdvanced use cases of `type` include its role in frameworks like Django, which leverage metaclasses for ORM functionality, or in testing frameworks where classes are created on-the-fly to represent test cases dynamically. This aligns closely with the principles set forth in PEP 3115, which introduced a uniform type model and clarified the role of `type` as both a class factory and the default metaclass.\n\nFurthermore, Python's dynamic nature allows developers to override `__new__` and `__init__` methods within classes created via `type`, providing even more control over instance creation processes. This deepens the potential for creating highly customized data models that adhere to specific constraints or initialization routines.", "difficulty": "advanced", "common_pitfalls": ["Forgetting that `type(name, bases, dict)` dynamically creates classes can lead to unexpected behavior if not carefully managed.", "Misunderstanding how metaclasses work with `type` can result in complex debugging situations when customizing class creation.", "Using dynamic type creation excessively can reduce code readability and maintainability.", "Naming conflicts within the attribute dictionary used for creating new types can cause runtime errors or override important methods unexpectedly."], "related_concepts": ["Metaclass", "Class", "Dynamic Class Creation", "Metaprogramming", "__new__ and __init__ methods", "PEP 3115"], "tags": []}, {"id": "652a13c7-f179-43de-b69c-e02a6864336f", "name": "String", "value": [{"id": "942e2480-2735-4b8e-8167-b514ba877f86", "type": "paragraph", "value": "<strong>Immutable sequence of characters.</strong>"}, {"id": "ec797d30-952d-406d-ae1d-7158ff13ccea", "type": "block_code", "value": "<str>  = <str>.strip()                       # Strips all whitespace characters from both ends.\n<str>  = <str>.strip('<chars>')              # Strips passed characters. Also lstrip/rstrip()."}, {"id": "b9a319e6-d7bb-4c7f-a701-c41a91e950c4", "type": "block_code", "value": "<list> = <str>.split()                       # Splits on one or more whitespace characters.\n<list> = <str>.split(sep=None, maxsplit=-1)  # Splits on 'sep' str at most 'maxsplit' times.\n<list> = <str>.splitlines(keepends=False)    # On [\\n\\r\\f\\v\\x1c-\\x1e\\x85\\u2028\\u2029] and \\r\\n.\n<str>  = <str>.join(<coll_of_strings>)       # Joins elements by using string as a separator."}, {"id": "4e4a2675-5c48-4d38-8027-e51241972f39", "type": "block_code", "value": "<bool> = <sub_str> in <str>                  # Checks if string contains the substring.\n<bool> = <str>.startswith(<sub_str>)         # Pass tuple of strings for multiple options.\n<int>  = <str>.find(<sub_str>)               # Returns start index of the first match or -1.\n<int>  = <str>.index(<sub_str>)              # Same, but raises ValueError if there's no match."}, {"id": "2e54c1c6-8a1f-464e-98ef-5180f71a2a57", "type": "block_code", "value": "<str>  = <str>.lower()                       # Changes the case. Also upper/capitalize/title().\n<str>  = <str>.replace(old, new [, count])   # Replaces 'old' with 'new' at most 'count' times.\n<str>  = <str>.translate(<table>)            # Use `str.maketrans(<dict>)` to generate table."}, {"id": "7d9b076c-a5dd-4329-be1b-eb36042414fc", "type": "block_code", "value": "<str>  = chr(<int>)                          # Converts int to Unicode character.\n<int>  = ord(<str>)                          # Converts Unicode character to int."}, {"id": "8c065ebc-9324-4e63-89c1-2e817b9947bb", "type": "list", "value": "<li><strong>Use <code>'unicodedata.normalize(&quot;NFC&quot;, &lt;str&gt;)'</code> on strings like <code>'Mot\u00f6rhead'</code> before comparing them to other strings, because <code>'\u00f6'</code> can be stored as one or two characters.</strong></li>\n<li><strong><code>'NFC'</code> converts such characters to a single character, while <code>'NFD'</code> converts them to two.</strong></li>"}], "sub_concepts": [{"id": "3fc25319-aa9c-487a-94d5-d159c7f75285", "name": "Property Methods", "value": [{"id": "3ddd78bf-8e88-468b-a2de-2b624ab06326", "type": "block_code", "value": "<bool> = <str>.isdecimal()                   # Checks for [0-9]. Also [\u0966-\u096f] and [\u0660-\u0669].\n<bool> = <str>.isdigit()                     # Checks for [\u00b2\u00b3\u00b9\u2026] and isdecimal().\n<bool> = <str>.isnumeric()                   # Checks for [\u00bc\u00bd\u00be\u2026], [\u96f6\u3007\u4e00\u2026] and isdigit().\n<bool> = <str>.isalnum()                     # Checks for [a-zA-Z\u2026] and isnumeric().\n<bool> = <str>.isprintable()                 # Checks for [ !#$%\u2026] and isalnum().\n<bool> = <str>.isspace()                     # Checks for [ \\t\\n\\r\\f\\v\\x1c-\\x1f\\x85\\xa0\u2026]."}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "Strings are immutable sequences of Unicode characters, supporting extensive manipulation methods and optimizations like interning and efficient concatenation through join().", "description": "In Python, strings are immutable sequences of Unicode characters. This immutability implies that once a string object is created, it cannot be altered; any operation that appears to modify the string actually creates a new one. This behavior is crucial for understanding performance implications and memory management in Python programs.\n\nStrings support a variety of methods for manipulation, including slicing, concatenation, and formatting. Slicing allows for extracting substrings using syntax like `s[start:end:step]`. Concatenating strings can be efficiently handled using the `join()` method rather than using the `+` operator in loops, as each `+` operation creates a new string object. Formatting is available via f-strings (PEP 498), which provide an intuitive way to embed expressions inside string literals.\n\nInternally, Python uses small integer caching for ASCII characters, allowing quick access and comparison. For longer strings or those requiring significant manipulation, techniques like `str.translate()` with a translation table can be more efficient than repeated character replacements. Understanding the underlying memory model is important when dealing with large-scale data processing tasks.\n\nAdvanced use cases include regular expressions (via the `re` module), which provide powerful pattern matching capabilities essential for text parsing and validation. Strings also integrate seamlessly with other advanced Python features like iterators and comprehensions, enabling concise and expressive code constructs.\n\nThe string interning mechanism optimizes memory usage by reusing identical strings stored in a global dictionary, which is particularly useful when handling many repeated literals or keys in dictionaries. This mechanism underscores the performance considerations tied to how strings are handled internally in Python.\n\nPEP 3131 introduced Unicode support for Python's core string type (`str`), ensuring that strings can represent any character from the Unicode standard. PEP 498 standardized f-strings, offering a more readable and efficient way of embedding expressions within string literals.\n\nFor developers working with text data in Python, understanding these mechanisms and optimizing string operations is critical for writing efficient, maintainable code.", "difficulty": "advanced", "common_pitfalls": ["Using the `+` operator in loops for string concatenation leads to inefficient memory usage.", "Failing to use f-strings or format method, resulting in less readable code.", "Overlooking immutability leading to unexpected behavior when attempting direct modification.", "Not leveraging `str.translate()` and regular expressions for complex pattern matching."], "related_concepts": ["Unicode", "PEP 498 (Formatted String Literals)", "Regular Expressions (`re` module)", "Immutable Data Structures", "String Interning", "Slicing and Indexing", "Memory Management in Python"], "tags": []}, {"id": "76bb1057-be09-4f3c-9c3c-f7ebc5fae370", "name": "Regex", "value": [{"id": "1b36743c-cd6a-4176-b73c-f19ef75ab157", "type": "paragraph", "value": "<strong>Functions for regular expression matching.</strong>"}, {"id": "0f0a8fc6-4ec2-492f-8f65-148f7a328626", "type": "block_code", "value": "import re\n<str>   = re.sub(r'<regex>', new, text, count=0)  # Substitutes all occurrences with 'new'.\n<list>  = re.findall(r'<regex>', text)            # Returns all occurrences as strings.\n<list>  = re.split(r'<regex>', text, maxsplit=0)  # Add brackets around regex to keep matches.\n<Match> = re.search(r'<regex>', text)             # First occurrence of the pattern or None.\n<Match> = re.match(r'<regex>', text)              # Searches only at the beginning of the text.\n<iter>  = re.finditer(r'<regex>', text)           # Returns all occurrences as Match objects."}, {"id": "1b142f56-7fa4-4896-8cc4-4e3c8ccc96ce", "type": "list", "value": "<li><strong>Raw string literals do not interpret escape sequences, thus enabling us to use regex-specific escape sequences that cause SyntaxWarning in normal string literals (since 3.12).</strong></li>\n<li><strong>Argument 'new' of re.sub() can be a function that accepts Match object and returns a str.</strong></li>\n<li><strong>Argument <code>'flags=re.IGNORECASE'</code> can be used with all functions.</strong></li>\n<li><strong>Argument <code>'flags=re.MULTILINE'</code> makes <code>'^'</code> and <code>'$'</code> match the start/end of each line.</strong></li>\n<li><strong>Argument <code>'flags=re.DOTALL'</code> makes <code>'.'</code> also accept the <code>'\\n'</code>.</strong></li>\n<li><strong><code>'re.compile(&lt;regex&gt;)'</code> returns a Pattern object with methods sub(), findall(), etc.</strong></li>"}], "sub_concepts": [{"id": "1161466c-6c39-472f-8ac0-308c4d2ebf48", "name": "Special Sequences", "value": [{"id": "5734b549-7309-4cd8-b4d4-d4554512e1b2", "type": "block_code", "value": "'\\d' == '[0-9]'                                   # Also [\u0966-\u096f\u2026]. Matches a decimal character.\n'\\w' == '[a-zA-Z0-9_]'                            # Also [\u00aa\u00b2\u00b3\u2026]. Matches an alphanumeric or _.\n'\\s' == '[ \\t\\n\\r\\f\\v]'                           # Also [\\x1c-\\x1f\u2026]. Matches a whitespace."}, {"id": "7130074f-36e1-4024-a9cb-17de8bdf5aa4", "type": "list", "value": "<li><strong>By default, decimal characters and alphanumerics from all alphabets are matched unless <code>'flags=re.ASCII'</code> is used. It restricts special sequence matches to the first 128 Unicode characters and also prevents <code>'\\s'</code> from accepting <code>'\\x1c'</code>, <code>'\\x1d'</code>, <code>'\\x1e'</code> and <code>'\\x1f'</code> (non-printable characters that divide text into files, tables, rows and fields, respectively).</strong></li>\n<li><strong>Use a capital letter for negation (all non-ASCII characters will be matched when used in combination with ASCII flag).</strong></li>"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "Python regex provides advanced pattern matching capabilities for efficient text processing, leveraging the `re` module for complex search and manipulation tasks.", "description": "Regular expressions (regex) in Python are a powerful tool for pattern matching and text manipulation. Implemented through the `re` module, regex allows developers to define complex search patterns using a compact syntax that can match strings, extract data, replace substrings, and split text based on sophisticated criteria. Internally, regex is compiled into bytecodes which are executed by a state machine, providing efficient pattern matching capabilities.\n\nThe regex engine supports various constructs like literal characters, character classes (`[a-z]`), quantifiers (`*`, `+`, `?`, `{m,n}`), anchors (`^`, `$`), and groups (capturing with `()`, non-capturing with `(?:)`). Advanced features include lookahead and lookbehind assertions (`(?=...)`, `(?!...)`, `(?<=...)`, `(?<!...)`), backreferences, and conditional expressions. These constructs enable complex patterns like finding repeated sequences or ensuring specific contexts for matches.\n\nRegex performance is a critical consideration; inefficient patterns can lead to catastrophic backtracking, where the engine spends exponential time on certain inputs. Techniques such as atomic grouping (`(?>...)`) and possessive quantifiers (`*+`, `++`, `?+`) help mitigate these issues by restricting how much the regex engine backtracks.\n\nAdvanced use cases involve text parsing tasks like validating email addresses or extracting URLs from logs, where regex can be combined with Python's other powerful features such as list comprehensions and generators for efficient data processing. The `re` module functions include `compile`, which pre-compiles a pattern into a regex object for repeated use, enhancing performance.\n\nWhile PEP 3136 introduced the `regex` module, an alternative to `re`, offering additional functionality like fuzzy matching and better Unicode support, it is not part of the standard library but can be installed via pip. Understanding these nuances allows developers to choose the most appropriate tool for their specific needs while avoiding common pitfalls like over-reliance on regex for complex parsing tasks.\n\nRegex's integration with Python's string methods (e.g., `str.find`, `str.replace`) and its ability to interface with other libraries make it an indispensable part of a Python developer's toolkit, especially when dealing with large datasets or streams where performance optimization is crucial.", "difficulty": "advanced", "common_pitfalls": ["Overusing regex for parsing when a dedicated parser would be more appropriate.", "Failing to account for catastrophic backtracking in complex patterns.", "Misunderstanding or misapplying advanced constructs like lookahead/lookbehind and backreferences.", "Neglecting the performance implications of non-compiled regex usage in repeated operations."], "related_concepts": ["`re` module functions (e.g., `match`, `search`, `findall`, `sub`)", "String methods for text manipulation", "PEP 3136: Alternative Regular Expression Library", "Unicode handling and regular expressions", "Performance optimization in Python"], "tags": []}, {"id": "85232994-7527-4a12-ad81-16ea5dcc782c", "name": "Format", "value": [{"id": "ab2bed2e-3088-43d2-8467-55b27d33e5be", "type": "block_code", "value": "<str> = f'{<el_1>}, {<el_2>}'            # Curly brackets can also contain expressions.\n<str> = '{}, {}'.format(<el_1>, <el_2>)  # Or: '{0}, {a}'.format(<el_1>, a=<el_2>)\n<str> = '%s, %s' % (<el_1>, <el_2>)      # Redundant and inferior C-style formatting."}], "sub_concepts": [{"id": "0ea23586-83b1-48bc-9e18-787cf7656d59", "name": "Ints", "value": [{"id": "a7ba2ce5-99d5-4015-8b6d-d495880af0e6", "type": "block_code", "value": "{90:c}                                   # 'Z'. Unicode character with value 90.\n{90:b}                                   # '1011010'. Binary representation of the int.\n{90:X}                                   # '5A'. Hexadecimal with upper-case letters."}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "`format()` is a versatile string formatting tool in Python, enabling advanced control over output through dynamic placeholders and comprehensive format specifications.", "description": "The `format()` method in Python is a powerful tool for string formatting that provides a flexible way to construct strings by inserting variable values into placeholders. Introduced as part of PEP 3101, it aims to improve upon older techniques like %-formatting and the `str.format()` method, offering enhanced readability and functionality. The `format()` function works with both positional and keyword arguments, allowing for intricate control over how data is presented.\n\nUnder the hood, `format()` uses a set of replacement fields enclosed in curly braces `{}` within the string, which can include format specifiers to control number precision, alignment, type conversion, etc. It supports various advanced formatting options like field names and indexes, dynamic formatting expressions, and custom formatting by implementing special methods on objects (like `__format__`). This method allows developers to define their own way of converting an object into a string representation when used in conjunction with `str.format()`.\n\nFor performance implications, while using format strings is convenient and readable, it may not be the fastest approach compared to simpler concatenation or f-string interpolation (introduced in Python 3.6 as per PEP 498) for straightforward scenarios due to additional parsing overhead. However, its flexibility makes it invaluable in complex formatting needs where dynamic content generation is required.\n\nCommon advanced use cases include creating dynamically generated SQL queries, custom logging formats, and building user interfaces where precise control over text layout is essential. Moreover, `format()` can be used to implement localization features by inserting language-specific data into formatted strings. It's particularly useful when the string structure needs to change based on conditions or input sizes.\n\nThe method supports a wide range of formatting options for different types like integers (binary, octal, hexadecimal), floating-point numbers, and more complex objects, making it suitable for detailed text processing tasks that require precision and customization.", "difficulty": "intermediate", "common_pitfalls": ["Overusing `format()` for simple concatenations leading to unnecessary complexity and reduced performance.", "Misunderstanding the difference between positional and keyword arguments within format strings can lead to unexpected results.", "Ignoring locale-specific formatting issues when using numeric conversions without proper localization considerations.", "Forgetting that custom objects need a `__format__` method defined to use advanced custom formatting, leading to TypeErrors."], "related_concepts": ["`f-strings` (formatted string literals)", "string interpolation", "`str.format()`", "PEP 3101 and PEP 498 for format specifications", "format specifiers", "`__format__` method"], "tags": []}, {"id": "93952fb8-b76d-4123-b849-44546256587e", "name": "Numbers", "value": [{"id": "14197267-dbec-48d2-a94b-e68ff82eceb5", "type": "block_code", "value": "<int>      = int(<float/str/bool>)           # Or: math.trunc(<float>)\n<float>    = float(<int/str/bool>)           # Or: <int/float>e\u00b1<int>\n<complex>  = complex(real=0, imag=0)         # Or: <int/float> \u00b1 <int/float>j\n<Fraction> = fractions.Fraction(0, 1)        # Or: Fraction(numerator=0, denominator=1)\n<Decimal>  = decimal.Decimal(<str/int>)      # Or: Decimal((sign, digits, exponent))"}, {"id": "03d693e7-3e01-4c9e-b7b4-2b0d9ca392ff", "type": "list", "value": "<li><strong><code>'int(&lt;str&gt;)'</code> and <code>'float(&lt;str&gt;)'</code> raise ValueError on malformed strings.</strong></li>\n<li><strong>Decimal numbers are stored exactly, unlike most floats where <code>'1.1 + 2.2 != 3.3'</code>.</strong></li>\n<li><strong>Floats can be compared with: <code>'math.isclose(&lt;float&gt;, &lt;float&gt;)'</code>.</strong></li>\n<li><strong>Precision of decimal operations is set with: <code>'decimal.getcontext().prec = &lt;int&gt;'</code>.</strong></li>\n<li><strong>Bools can be used anywhere ints can, because bool is a subclass of int: <code>'True + 1 == 2'</code>.</strong></li>"}], "sub_concepts": [{"id": "f496ce90-5d81-4c1a-8c97-bc6f2b9d94b5", "name": "Bitwise Operators", "value": [{"id": "993ce2b1-e220-4a4b-bd70-90a95087232c", "type": "block_code", "value": "<int> = <int> & <int>                        # And (0b1100 & 0b1010 == 0b1000).\n<int> = <int> | <int>                        # Or  (0b1100 | 0b1010 == 0b1110).\n<int> = <int> ^ <int>                        # Xor (0b1100 ^ 0b1010 == 0b0110).\n<int> = <int> << n_bits                      # Left shift. Use >> for right.\n<int> = ~<int>                               # Not. Also -<int> - 1."}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "Python's number types include `int`, `float`, `complex`, and `decimal.Decimal` for flexible, high-precision numeric computations essential in various domains like finance and engineering.", "description": "In Python, the 'Numbers' category encompasses several numeric types that are fundamental to many operations involving arithmetic and numerical computations. These include `int` (integer), `float` (floating-point number), `complex` (complex numbers), and as of Python 3.6, a new type called `decimal.Decimal` for precise decimal arithmetic. The design of these numeric types is deeply rooted in Python's philosophy of simplicity and ease of use while providing performance where needed.\n\nIntegers (`int`) are implemented with arbitrary precision, meaning they can grow to accommodate any size necessary at the expense of memory usage. This makes them very flexible but may impact performance for extremely large numbers due to increased computational overhead. The `float` type is based on C's double-precision floating-point format (IEEE 754), providing a compromise between range and precision.\n\nComplex numbers (`complex`) are built-in from Python 2.6 onwards, represented as `x + yj`, where `x` and `y` are floats or integers. Internally, complex numbers use two `floats`: one for the real part and one for the imaginary part.\n\nThe introduction of `decimal.Decimal` offers high precision arithmetic by avoiding binary floating-point approximations that can lead to rounding errors in decimal calculations. This is particularly useful in financial applications where exactness is paramount. The `Decimal` type is based on the General Decimal Arithmetic Specification, ensuring consistency and accuracy across different platforms.\n\nAdvanced users often leverage these numeric types with Python's rich ecosystem of libraries such as NumPy for array-based numerical operations or SymPy for symbolic mathematics, which provide further optimizations and capabilities beyond built-in types. For performance-critical applications, understanding the trade-offs between precision, speed, and memory usage when choosing among `int`, `float`, `complex`, and `decimal.Decimal` is crucial.\n\nPython's numeric tower allows for interoperability among these types through automatic type promotion (e.g., mixing an `int` with a `float` results in a `float`). However, operations involving complex numbers or decimal arithmetic require explicit handling to avoid unexpected behavior due to implicit conversions. The PEP 237 introduced `decimal.Decimal`, and its usage is encouraged for any application where precision in decimal calculations outweighs performance.\n\nUnderstanding these numeric types deeply enables Python developers to write more efficient, accurate, and robust numerical code, taking full advantage of the language's capabilities and integrating seamlessly with external libraries that demand high-performance computing or precise arithmetic.", "difficulty": "intermediate", "common_pitfalls": ["Confusing binary floating-point precision with decimal precision, leading to rounding errors in calculations using floats when exact results are required.", "Overlooking the performance implications of Python's arbitrary-precision integers (`int`) for extremely large numbers or frequent arithmetic operations.", "Mismanaging type promotions between numeric types, which can lead to loss of precision or unexpected behavior.", "Failing to use `decimal.Decimal` in applications requiring precise decimal calculations, such as financial transactions."], "related_concepts": ["Arithmetic operators", "PEP 237 (Decimal module)", "NumPy library for numerical computations", "SymPy library for symbolic mathematics", "IEEE 754 standard for floating-point arithmetic"], "tags": []}, {"id": "e50b92c8-c6bf-4603-bafc-dd6cc2838dff", "name": "Combinatorics", "value": [{"id": "32f0a910-cea8-4d06-8fd0-a0f61a71f6a0", "type": "block_code", "value": "import itertools as it"}, {"id": "4884fcb3-00c9-44fd-82fc-73464b7f0ec1", "type": "block_code", "value": ">>> list(it.product('abc', repeat=2))        #   a  b  c\n[('a', 'a'), ('a', 'b'), ('a', 'c'),         # a x  x  x\n ('b', 'a'), ('b', 'b'), ('b', 'c'),         # b x  x  x\n ('c', 'a'), ('c', 'b'), ('c', 'c')]         # c x  x  x"}, {"id": "8d051045-34a5-4ff4-88f1-b50038ed81a7", "type": "block_code", "value": ">>> list(it.permutations('abc', 2))          #   a  b  c\n[('a', 'b'), ('a', 'c'),                     # a .  x  x\n ('b', 'a'), ('b', 'c'),                     # b x  .  x\n ('c', 'a'), ('c', 'b')]                     # c x  x  ."}, {"id": "e8576b58-5740-4839-8e69-d239ea15ce20", "type": "block_code", "value": ">>> list(it.combinations('abc', 2))          #   a  b  c\n[('a', 'b'), ('a', 'c'),                     # a .  x  x\n ('b', 'c')                                  # b .  .  x\n]                                            # c .  .  ."}], "sub_concepts": [], "short_description": "Combinatorics in Python involves using the itertools module to generate combinations, permutations, and Cartesian products efficiently via iterators.", "description": "In Python, combinatorics refers to algorithms and techniques used to generate combinations, permutations, and variations of a set of items. These operations are fundamental in fields such as probability, statistics, and algorithm design. The `itertools` module in the standard library provides several tools for creating iterators for efficient looping, including functions like `combinations`, `permutations`, and `product`. These functions implement combinatorial algorithms that leverage Python's iterator protocol to yield results one at a time, making them memory-efficient compared to generating all combinations or permutations at once.\n\nThe `itertools.combinations(iterable, r)` function generates all possible combinations of length `r` from the input iterable. The order of elements within each combination does not matter, and duplicates are not repeated. This is useful for scenarios where you need to explore all subsets of a given size from a larger set.\n\nSimilarly, `itertools.permutations(iterable, r=None)` generates all possible ordered arrangements of the input iterable. If `r` is specified, it returns permutations of length `r`; otherwise, it defaults to the length of the entire iterable. This function is useful for problems where order matters, such as generating different sequences or arrangements.\n\nThe `itertools.product(*iterables, repeat=1)` function computes the Cartesian product of input iterables, effectively generating all possible tuples that can be formed by picking one element from each iterable. The optional `repeat` parameter allows repeating the same iterable multiple times in the product computation, useful for scenarios like rolling dice or creating multi-dimensional grids.\n\nAdvanced use cases involve chaining these functions with other iterator tools like `filter`, `map`, and `zip` to create complex data pipelines. For instance, filtering permutations based on a condition or mapping a function over combinations to compute results dynamically. These techniques are crucial for optimizing performance in combinatorial problems, especially when dealing with large datasets.\n\nPerformance considerations include the lazy evaluation of iterators, which avoids generating all possible outcomes at once, thus saving memory. However, this can lead to increased computation time if each result requires significant processing. Understanding these trade-offs is essential for writing efficient Python code that leverages combinatorial algorithms.\n\nRelevant PEPs include PEP 255 (Simple Generators) and PEP 380 (Syntax for Delegating to a Subgenerator), which provide foundational support for the iterator protocol used by `itertools` functions. These enhancements in Python's language design facilitate the creation of powerful, efficient combinatorial tools.", "difficulty": "advanced", "common_pitfalls": ["Forgetting that itertools functions return iterators, leading to unexpected behavior when attempting to reuse them without re-initializing.", "Misunderstanding the difference between combinations (order doesn't matter) and permutations (order matters), resulting in incorrect algorithm implementations.", "Overlooking memory efficiency benefits of lazy evaluation, which can lead to inefficient code when handling large datasets.", "Ignoring the optional `repeat` parameter in itertools.product, which is crucial for problems requiring repeated iterations over the same set."], "related_concepts": ["Iterator Protocol", "Generators", "Lazy Evaluation", "PEP 255 - Simple Generators", "PEP 380 - Syntax for Delegating to a Subgenerator"], "tags": []}, {"id": "a9fdd6b4-3855-4708-b9a4-537176973872", "name": "Datetime", "value": [{"id": "4364c5c8-4ac7-4776-b524-2bbf2ef7998e", "type": "paragraph", "value": "<strong>Provides 'date', 'time', 'datetime' and 'timedelta' classes. All are immutable and hashable.</strong>"}, {"id": "44c7b5b8-ea62-4a13-8973-6d3b214883e0", "type": "block_code", "value": "# $ pip3 install python-dateutil\nfrom datetime import date, time, datetime, timedelta, timezone\nimport zoneinfo, dateutil.tz"}, {"id": "73c36c1f-2564-49cd-9411-056e1e6539fd", "type": "block_code", "value": "<D>  = date(year, month, day)               # Only accepts valid dates from 1 to 9999 AD.\n<T>  = time(hour=0, minute=0, second=0)     # Also: `microsecond=0, tzinfo=None, fold=0`.\n<DT> = datetime(year, month, day, hour=0)   # Also: `minute=0, second=0, microsecond=0, \u2026`.\n<TD> = timedelta(weeks=0, days=0, hours=0)  # Also: `minutes=0, seconds=0, microseconds=0`."}, {"id": "bc8c8096-b5ca-419b-b988-cdeac8f33242", "type": "list", "value": "<li><strong>Times and datetimes that have defined timezone are called aware and ones that don't, naive. If object is naive, it is presumed to be in the system's timezone!</strong></li>\n<li><strong><code>'fold=1'</code> means the second pass in case of time jumping back for one hour.</strong></li>\n<li><strong>Timedelta normalizes arguments to \u00b1days, seconds (&lt; 86\u202f400) and microseconds (&lt; 1M). Its str() method returns <code>'[\u00b1D, ]H:MM:SS[.\u2026]'</code> and total_seconds() a float of all seconds.</strong></li>\n<li><strong>Use <code>'&lt;D/DT&gt;.weekday()'</code> to get the day of the week as an integer, with Monday being 0.</strong></li>"}], "sub_concepts": [{"id": "561da43f-cc2a-4410-b701-677a6cbf0bab", "name": "Arithmetics", "value": [{"id": "fb4d8746-1ed2-4f4e-b57b-b0536eaf9923", "type": "block_code", "value": "<bool>   = <D/T/DTn> > <D/T/DTn>            # Ignores time jumps (fold attribute). Also ==.\n<bool>   = <DTa>     > <DTa>                # Ignores time jumps if they share tzinfo object.\n<TD>     = <D/DTn>   - <D/DTn>              # Ignores jumps. Convert to UTC for actual delta.\n<TD>     = <DTa>     - <DTa>                # Ignores jumps if they share tzinfo object.\n<D/DT>   = <D/DT>    \u00b1 <TD>                 # Returned datetime can fall into missing hour.\n<TD>     = <TD>      * <float>              # Also `<TD> = abs(<TD>)`, `<TD> = <TD> \u00b1 <TD>`.\n<float>  = <TD>      / <TD>                 # Also `(<int>, <TD>) = divmod(<TD>, <TD>)`."}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "`datetime` provides classes to manipulate dates and times effectively in Python, supporting complex operations like arithmetic and timezone conversion.", "description": "The `datetime` module in Python provides classes for manipulating dates and times. Introduced as part of the standard library, this module is essential for dealing with date and time-related operations. The `datetime` class itself is a central component, offering a comprehensive set of methods to handle year, month, day, hour, minute, second, microsecond, and timezone information collectively.\n\nUnderlying the `datetime` module are several classes including `date`, `time`, `datetime`, `timedelta`, `tzinfo`, among others. The `datetime` class combines both date and time representations into a single object, allowing for arithmetic operations through instances of `timedelta`. This facilitates computing differences between dates or adding/subtracting time spans to/from specific points in time.\n\nThe module also supports timezone information via the `timezone` and `tzinfo` abstract base classes. With PEP 495 (introduced in Python 3.2), naive datetime objects can be converted into aware ones using these classes, allowing seamless handling of different time zones. The `datetime` module has been updated over various Python versions to enhance its capabilities with features like ISO format parsing and improved support for timezone databases.\n\nPerformance considerations include the efficiency of date arithmetic operations via `timedelta`, which are generally computationally inexpensive due to their reliance on integer calculations under the hood. When handling large datasets or performing complex date computations, these efficiencies can be leveraged to maintain performance.\n\nAdvanced use cases often involve parsing string representations of dates and times using `strptime` and formatting them with `strftime`. Additionally, when dealing with time zones, converting between aware datetime objects is critical in global applications. The module also plays a role in serialization processes where date and time data must be formatted for storage or transmission.\n\nThe `datetime` module's design reflects the complexity of real-world temporal data handling needs while maintaining simplicity for common tasks. Its comprehensive API ensures robustness, making it a cornerstone for any Python application dealing with temporal information.", "difficulty": "intermediate", "common_pitfalls": ["Confusing naive and aware datetime objects leading to incorrect timezone conversions.", "Misunderstanding the difference between date and datetime objects resulting in improper data manipulation.", "Incorrectly handling leap years or daylight saving time changes when performing arithmetic with timedelta.", "Forgetting to use `strptime` correctly for parsing dates from strings, leading to ValueError exceptions."], "related_concepts": ["time", "date", "timedelta", "timezone", "tzinfo", "pytz", "calendar"], "tags": []}, {"id": "d69eeef8-cff6-4607-9b71-3f47010a9b28", "name": "Function", "value": [{"id": "70fb5746-27c8-4932-9862-18393890914a", "type": "paragraph", "value": "<strong>Independent block of code that returns a value when called.</strong>"}, {"id": "c2c0b4c6-9bd9-4a01-bb6e-8eaafee70447", "type": "block_code", "value": "def <func_name>(<nondefault_args>): ...                  # E.g. `def func(x, y): ...`.\ndef <func_name>(<default_args>): ...                     # E.g. `def func(x=0, y=0): ...`.\ndef <func_name>(<nondefault_args>, <default_args>): ...  # E.g. `def func(x, y=0): ...`."}, {"id": "91a68046-8434-4006-8226-90a1dfbed175", "type": "list", "value": "<li><strong>Function returns None if it doesn't encounter <code>'return &lt;obj/exp&gt;'</code> statement.</strong></li>\n<li><strong>Run <code>'global &lt;var_name&gt;'</code> inside the function before assigning to global variable.</strong></li>\n<li><strong>Default values are evaluated when function is first encountered in the scope. Any mutation of a mutable default value will persist between invocations!</strong></li>"}], "sub_concepts": [{"id": "61ea5bc4-1899-4b1f-82dc-e6baa5c8d356", "name": "Function Call", "value": [{"id": "37d8c0d6-b1b3-457c-907c-3571873b49d0", "type": "block_code", "value": "<obj> = <function>(<positional_args>)                    # E.g. `func(0, 0)`.\n<obj> = <function>(<keyword_args>)                       # E.g. `func(x=0, y=0)`.\n<obj> = <function>(<positional_args>, <keyword_args>)    # E.g. `func(0, y=0)`."}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "Functions in Python are first-class objects that enable modular code with features like closures, decorators, lambda expressions, annotations, and variadic arguments for advanced use cases.", "description": "In Python, functions are first-class objects that allow for a highly modular and reusable codebase. At an advanced level, understanding functions involves delving into aspects such as closures, decorators, lambda expressions, function annotations, and variadic arguments. Functions in Python adhere to the principles of functional programming, supporting operations like currying and partial application through tools provided by modules like `functools`. The closure mechanism allows a nested function to remember the state of its enclosing scope even after the outer function has finished execution, which is crucial for creating decorators or maintaining local states. Decorators are higher-order functions that allow for the extension or modification of other functions' behavior without directly altering their code, providing a powerful means for aspect-oriented programming and meta-programming.\n\nFunction annotations introduced in PEP 3107 provide a mechanism to attach metadata to function parameters and return values, enhancing readability and serving as a basis for type checking with tools like `mypy`. Python's handling of variadic arguments (`*args` and `**kwargs`) allows functions to accept an arbitrary number of positional or keyword arguments, respectively. This capability supports the creation of highly flexible interfaces and is often used in conjunction with argument unpacking.\n\nPerformance implications are another consideration; for instance, using decorators can introduce overhead due to additional function calls. Understanding these performance nuances and optimizing function usage accordingly is key for advanced Python developers. Furthermore, Python 3 introduced changes like positional-only arguments (`/`) in PEP 570, adding more control over parameter handling.\n\nAdvanced use cases of functions include creating metaprogramming patterns via decorators, employing coroutines with `async` and `await`, and utilizing generator expressions for memory-efficient iteration. These capabilities underscore the versatility of Python functions in building complex, efficient applications.", "difficulty": "advanced", "common_pitfalls": ["Misunderstanding the scope of variables in nested functions leading to unintended behavior or errors (closure issues).", "Overusing decorators, which can obscure code logic and introduce performance overhead.", "Incorrectly using function annotations for type checking without proper tooling support.", "Confusion between `*args` and `**kwargs`, particularly when they are used together in a single function signature.", "Not leveraging the full potential of lambda functions due to their limitations, such as lack of explicit return statements."], "related_concepts": ["Closures", "Decorators", "Lambda Expressions", "Function Annotations", "Variadic Arguments (`*args`, `**kwargs`)", "Partial Functions and Currying", "Higher-Order Functions"], "tags": []}, {"id": "8fccbc9d-3693-4df4-a56f-676ef2652c79", "name": "Splat Operator", "value": [{"id": "35370dce-064a-40c5-9518-568b8bbcd9f7", "type": "paragraph", "value": "<strong>Splat expands a collection into positional arguments, while splatty-splat expands a dictionary into keyword arguments.</strong>"}, {"id": "55ab11c6-4014-4253-80dd-3137bb97efdb", "type": "block_code", "value": "args, kwargs = (1, 2), {'z': 3}\nfunc(*args, **kwargs)"}, {"id": "6e4f34b4-9514-467c-ba74-f88555b2b75e", "type": "heading", "value": "Is the same as:"}, {"id": "ce76bad3-b06f-47e9-b684-2e5971a1bdd1", "type": "block_code", "value": "func(1, 2, z=3)"}], "sub_concepts": [{"id": "d14f961e-a067-43e7-afc1-026604d1dd9e", "name": "Other Uses", "value": [{"id": "75c3a51f-290a-4c46-a8af-b935273dd048", "type": "block_code", "value": "<list>  = [*<collection> [, ...]]  # Or: list(<coll>) [+ ...]\n<tuple> = (*<collection>, [...])   # Or: tuple(<coll>) [+ ...]\n<set>   = {*<collection> [, ...]}  # Or: set(<coll>) [| ...]\n<dict>  = {**<dict> [, ...]}       # Or: <dict> | ..."}, {"id": "3b662267-a895-48e1-96e8-78839d1d9475", "type": "block_code", "value": "head, *body, tail = <collection>   # Head or tail can be omitted."}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "The splat operator (`*`) in Python allows for unpacking iterables, collecting arbitrary positional arguments, and merging dictionaries, enhancing code flexibility and readability.", "description": "The splat operator (`*`) in Python serves multiple purposes, each leveraging its underlying mechanisms to enhance flexibility and readability of code. Primarily known for unpacking iterables and collecting arbitrary positional arguments, the splat operator is a powerful tool in Python's syntax arsenal.\n\n**Unpacking Iterables**: When used in function calls or iterable assignments, `*` unpacks elements from an iterable such as lists or tuples into separate positional arguments. For instance, calling `max(*[1, 2, 3])` effectively passes `1`, `2`, and `3` individually to the `max` function. This mechanism is rooted in Python's iterator protocol, where the splat operator triggers the iterable to yield its elements sequentially.\n\n**Arbitrary Positional Arguments**: In function definitions, prefixing a parameter with `*` allows the function to accept any number of positional arguments as a tuple, enabling dynamic argument handling. For example, `def foo(*args): ...` collects all given positional arguments into `args`, which can then be iterated over or processed collectively.\n\n**Arbitrary Keyword Arguments**: Similarly, using `**` with a dictionary-like object unpacks it into keyword arguments for function calls, or in function definitions to accept any number of keyword arguments as a dictionary. This is particularly useful for functions that need to handle named parameters dynamically, such as configuration settings.\n\nFrom a performance perspective, these features allow for more expressive and flexible code without resorting to manually managing argument lists or dictionaries, thus reducing boilerplate and potential errors. However, excessive use of splat operators can lead to decreased readability if not used judiciously, especially in complex expressions where it's unclear what is being unpacked.\n\nCommon advanced use cases include using the splat operator for merging iterables, handling function arguments dynamically, and simplifying code that deals with variable-length argument lists. This feature aligns with PEP 3102 (arbitrary argument lists) and PEP 3132 (unpacking generalizations), which formalized these capabilities in Python.\n\nInternally, the splat operator leverages Python's iteration mechanics to seamlessly integrate iterable unpacking into various contexts, demonstrating Python's commitment to syntactic simplicity and expressive power. Its versatility makes it indispensable for advanced Python developers seeking to write clean, efficient, and adaptable code.", "difficulty": "intermediate", "common_pitfalls": ["Misunderstanding the difference between `*args` (for positional arguments) and `**kwargs` (for keyword arguments).", "Using splat operators inappropriately can lead to syntax errors or logical mistakes, especially when dealing with non-iterable objects.", "Overuse of unpacking in complex expressions may reduce code readability and maintainability.", "Forgetting that the order matters: positional arguments must be handled before keyword arguments in function definitions."], "related_concepts": ["Iterator Protocol", "Function Arguments (positional, keyword)", "Tuples and Lists", "Dictionaries", "PEP 3102 - Arbitrary Argument Lists", "PEP 3132 - Unpacking Generalizations"], "tags": []}, {"id": "d8779b9b-c50b-4969-a92b-9148f3bee55b", "name": "Inline", "value": [], "sub_concepts": [{"id": "da279f0e-f1e2-4e41-9633-3ce17e7d324b", "name": "Named Tuple, Enum, Dataclass", "value": [{"id": "7b572ad4-c36d-4f0c-8be5-f292b669c0d7", "type": "block_code", "value": "from collections import namedtuple\nPoint = namedtuple('Point', 'x y')                  # Creates tuple's subclass.\npoint = Point(0, 0)                                 # Returns its instance.\n\nfrom enum import Enum\nDirection = Enum('Direction', 'N E S W')            # Creates Enum's subclass.\ndirection = Direction.N                             # Returns its member.\n\nfrom dataclasses import make_dataclass\nPlayer = make_dataclass('Player', ['loc', 'dir'])   # Creates a class.\nplayer = Player(point, direction)                   # Returns its instance."}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "Embedding Python code directly within lines of other languages or scripts for dynamic execution and evaluation, commonly used in configuration files and templating systems.", "description": "Inline Python refers to embedding Python code directly within a line of another language or script, often for purposes such as configuration files, shell scripts, or templating engines. This practice leverages Python's embedded capabilities, enabling dynamic execution and evaluation without needing separate script files. Inline Python can be particularly useful in environments where Python's flexibility enhances the expressiveness and maintainability of configurations or scripts. \n\nTechnically, inline Python is often facilitated by `eval()` or `exec()`, which dynamically execute a string as Python code. However, this introduces potential security risks if untrusted input is executed. Therefore, when using inline Python in production environments, it's crucial to sanitize inputs and limit the scope of execution where possible.\n\nPerformance implications include the overhead of parsing and executing Python code on-the-fly, which can be mitigated by ensuring that only necessary computations are embedded and reused whenever feasible. In advanced use cases, inline Python can integrate with templating systems like Jinja2 or Mako, providing powerful tools for generating dynamic content in web applications or automated scripts.\n\nInline Python is particularly relevant in scenarios involving dynamic configuration generation, where the flexibility of Python allows users to embed complex logic directly into configuration files. This is common in DevOps practices, such as infrastructure-as-code tools like Ansible, which use inline Python for advanced variable manipulation and conditional logic within playbooks.\n\nRelevant PEPs include PEP 3120 ('A Restricted Execution Environment'), which introduces the `exec` function's support for a restricted execution environment. This is crucial for safely implementing inline Python by constraining what can be executed, thus reducing potential security vulnerabilities.\n\nAdvanced users often employ inline Python in conjunction with metaprogramming techniques to create highly customizable and dynamic scripts that respond to various runtime conditions without manual intervention.", "difficulty": "advanced", "common_pitfalls": ["Security vulnerabilities from unsanitized input when using `eval()` or `exec()` without restrictions.", "Performance overhead from frequent parsing and executing of Python code.", "Complexity in debugging inline Python due to lack of clear separation between languages/scripts."], "related_concepts": ["`eval()`, `exec()`", "Metaprogramming", "Templating engines (e.g., Jinja2, Mako)", "Restricted execution environment (PEP 3120)", "DevOps tools (e.g., Ansible)"], "tags": []}, {"id": "86c5b1ff-972a-48fb-81a2-b537a814131a", "name": "Imports", "value": [{"id": "6b415a1f-3fb2-4071-ba80-c8ecf9a6da23", "type": "paragraph", "value": "<strong>Mechanism that makes code in one file available to another file.</strong>"}, {"id": "47fa02af-21a1-460e-a12c-ceb73b22888c", "type": "block_code", "value": "import <module>            # Imports a built-in or '<module>.py'.\nimport <package>           # Imports a built-in or '<package>/__init__.py'.\nimport <package>.<module>  # Imports a built-in or '<package>/<module>.py'."}, {"id": "c46a7f6f-3e5a-45eb-abc8-b39f3e0fcefc", "type": "list", "value": "<li><strong>Package is a collection of modules, but it can also define its own objects.</strong></li>\n<li><strong>On a filesystem this corresponds to a directory of Python files with an optional init script.</strong></li>\n<li><strong>Running <code>'import &lt;package&gt;'</code> does not automatically provide access to the package's modules unless they are explicitly imported in its init script.</strong></li>\n<li><strong>Directory of the file that is passed to python command serves as a root of local imports.</strong></li>\n<li><strong>For relative imports use <code>'from .[\u2026][&lt;pkg/module&gt;[.\u2026]] import &lt;obj&gt;'</code>.</strong></li>"}], "sub_concepts": [], "short_description": "Python imports facilitate code reuse by allowing access to functions, classes, and variables across different modules, with advanced features for dynamic importing and dependency management.", "description": "In Python, imports are a fundamental mechanism for code reuse and organization, allowing developers to access functions, classes, and variables from other modules. The import system in Python is governed by the import statement, which can be used in several forms: `import module`, `from module import name(s)`, and `import module as alias`. Each form has specific implications on namespace management and code readability.\n\nThe standard library's import machinery is built around a series of hooks and entry points defined primarily in PEP 302. At runtime, Python searches for modules based on the sys.path list, which includes the directory containing the input script (or current working directory), PYTHONPATH directories, and the installation-dependent default path. The module search process involves locating the file associated with the module name, compiling it to bytecode if necessary, and executing its code within a new namespace.\n\nAdvanced users leverage dynamic imports using `importlib`, which provides more control over import behavior. Functions like `import_module` allow for importing modules based on string names at runtime, enabling conditional loading and reducing static dependencies. Furthermore, the `__all__` variable in a module's namespace can be used to restrict what is exported when an import statement uses `from module import *`, enhancing encapsulation.\n\nCircular imports are a common pitfall in Python, where two or more modules depend on each other. This can lead to runtime errors if not handled properly. Advanced solutions include lazy imports using functions (deferring the actual import until it's necessary) and reorganizing code structure to break cyclic dependencies.\n\nPython 3.9 introduced several enhancements like the merge of PEP 563, which introduces the postponed evaluation of type annotations. This change allows modules to be imported without triggering the evaluation of all annotations, optimizing performance in large projects with numerous imports.\n\nThe import system's flexibility and extensibility make it a powerful tool for structuring large codebases and managing dependencies. However, it requires careful consideration regarding namespace pollution, module loading order, and the potential impact on runtime performance due to repeated dynamic imports.", "difficulty": "advanced", "common_pitfalls": ["Namespace pollution from using `from module import *` excessively.", "Circular dependencies leading to runtime errors if not managed properly.", "Performance bottlenecks due to repeated dynamic imports without caching mechanisms.", "Misunderstanding of the scope and lifetime of imported modules, especially when using conditional or lazy imports."], "related_concepts": ["Modules", "Namespace", "sys.path", "importlib", "Circular Imports", "__all__ variable", "PEP 302"], "tags": []}, {"id": "ee080647-954a-4952-a102-0d89dfd95049", "name": "Closure", "value": [{"id": "52309f09-f877-465d-ad98-82581469f512", "type": "paragraph", "value": "<strong>We have/get a closure in Python when a nested function references a value of its enclosing function and then the enclosing function returns its nested function.</strong>"}, {"id": "373acaf6-8e92-466b-aac0-7e3c24c5c542", "type": "block_code", "value": "def get_multiplier(a):\n    def out(b):\n        return a * b\n    return out"}, {"id": "ab5ec686-7573-409c-9e6c-206f0a673964", "type": "block_code", "value": ">>> multiply_by_3 = get_multiplier(3)\n>>> multiply_by_3(10)\n30"}, {"id": "d791de95-7b77-4a9f-a76e-e5937ccfd17c", "type": "list", "value": "<li><strong>Any value that is referenced from within multiple nested functions gets shared.</strong></li>"}], "sub_concepts": [{"id": "a6a3571a-d243-4e47-8561-e3e2c59543cf", "name": "Non-Local", "value": [{"id": "a08a12ab-d004-416c-9162-b2feb0dee055", "type": "paragraph", "value": "<strong>If variable is being assigned to anywhere in the scope, it is regarded as a local variable, unless it is declared as a 'global' or a 'nonlocal'.</strong>"}, {"id": "5a49e0f3-c807-4b7d-8afd-71383ca63dcd", "type": "block_code", "value": "def get_counter():\n    i = 0\n    def out():\n        nonlocal i\n        i += 1\n        return i\n    return out"}, {"id": "57df98f5-7b2a-4d9e-8dfa-27dafddbf947", "type": "block_code", "value": ">>> counter = get_counter()\n>>> counter(), counter(), counter()\n(1, 2, 3)"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "A closure is a function object that retains state between calls by capturing the environment where it was defined.", "description": "A closure in Python refers to a function object that remembers values in enclosing scopes even if they are not present in memory. It is a record storing a function together with an environment: the mapping associating each free variable of the function (variables referenced in the function but not bound there) with the value or reference to which the name was bound when the closure was created. Closures provide some interesting properties, such as data hiding and encapsulation without classes.\n\nIn Python 3.9+, closures continue to leverage the lexical scoping rules defined by PEP 255 (\"Simple Generators\"). While they are often discussed in the context of nested functions, their power lies in their ability to retain state between function calls, which can be particularly useful for creating factory functions or decorators.\n\nInternally, a closure binds its non-local variables into a cell within the function object. These cells store references to objects that exist outside of the local scope but are necessary for the function's operation. When the inner function is executed, Python will look up these variables in their respective cells. This mechanism provides both the encapsulation and state retention properties.\n\nClosures are also a form of first-class functions since they can be passed around as objects. They can be used to return more complex behavior than typical local scope variables could provide, acting similarly to objects or classes but with less overhead due to not needing explicit class definitions.\n\nPerformance considerations include the fact that closures may introduce some memory overhead because they retain references to their enclosing scopes. However, this is often outweighed by the flexibility and code elegance provided by using them in place of more complex class-based solutions.\n\nCommon advanced use cases for closures include:\n1. Function factories: Functions that return other functions can customize behavior at runtime.\n2. Decorators: Modifying or enhancing function behavior dynamically, where closures capture state across calls.\n3. Partial application: Creating specialized versions of a more generic function by pre-filling some arguments.\n4. Event listeners and callback mechanisms in GUI applications or async event loops.\n\nRelevant PEPs include PEP 255 for generator functions and PEP 362 for decorators, which both utilize closures to achieve their goals.", "difficulty": "advanced", "common_pitfalls": ["Misunderstanding variable shadowing within nested functions leading to unexpected behavior.", "Overlooking memory overhead due to retained references in closures, especially in large applications.", "Incorrectly assuming that modifications inside a closure affect the outer scope directly without using nonlocal keyword (introduced in Python 3).", "Confusing closures with function factories; although related, they serve different purposes.", "Using mutable objects within closures can lead to side effects if those objects are shared across multiple closures."], "related_concepts": ["Function Decorators", "First-Class Functions", "Nonlocal Keyword", "Lexical Scoping", "Partial Application"], "tags": []}, {"id": "d2f9bf46-f2f4-459a-b448-92e6c20169c5", "name": "Decorator", "value": [{"id": "4a0e295c-ea56-49aa-8e28-b53b0abcae9c", "type": "list", "value": "<li><strong>A decorator takes a function, adds some functionality and returns it.</strong></li>\n<li><strong>It can be any <a href=\"#callable\">callable</a>, but is usually implemented as a function that returns a <a href=\"#closure\">closure</a>.</strong></li>"}, {"id": "23c3f9fe-181e-44cb-af38-4f4e9a69f333", "type": "block_code", "value": "@decorator_name\ndef function_that_gets_passed_to_decorator():\n    ..."}], "sub_concepts": [{"id": "7022ecc4-1b1a-4e6e-b12a-7ce2c1d50b6f", "name": "Parametrized Decorator", "value": [{"id": "c3823bbd-7708-47c9-a59d-f826ef35f9ee", "type": "paragraph", "value": "<strong>A decorator that accepts arguments and returns a normal decorator that accepts a function.</strong>"}, {"id": "526749e3-c728-4269-9d95-916687301352", "type": "block_code", "value": "from functools import wraps\n\ndef debug(print_result=False):\n    def decorator(func):\n        @wraps(func)\n        def out(*args, **kwargs):\n            result = func(*args, **kwargs)\n            print(func.__name__, result if print_result else '')\n            return result\n        return out\n    return decorator\n\n@debug(print_result=True)\ndef add(x, y):\n    return x + y"}, {"id": "1aa1e7ce-9273-489e-955e-1fd8941413a7", "type": "list", "value": "<li><strong>Using only <code>'@debug'</code> to decorate the add() function would not work here, because debug would then receive the add() function as a 'print_result' argument. Decorators can however manually check if the argument they received is a function and act accordingly.</strong></li>"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "Decorators dynamically modify or extend the behavior of functions or methods using higher-order functions, enabling reusable cross-cutting concerns like logging, authentication, or caching in an expressive manner.", "description": "In Python, decorators are a powerful and expressive tool for modifying or extending the behavior of functions or methods. They leverage higher-order functions to allow one function to take another as an argument, return it with modifications, or wrap additional functionality around it. Decorators are defined using the `@decorator_name` syntax above a function definition and can be seen as syntactic sugar for applying wrapper functions. Internally, decorators involve calling the target function within a nested wrapper function, allowing pre- and post-processing logic to be inserted seamlessly.\n\nThe decorator pattern is essential in scenarios requiring cross-cutting concerns like logging, authentication, or caching. By separating these concerns from business logic, code becomes more modular and reusable. For instance, a logging decorator can automatically log entry and exit points of functions without cluttering the core logic. Decorators maintain their own scope and are often used to implement aspect-oriented programming patterns in Python.\n\nOne advanced use case is decorators with arguments, achieved by returning a decorator function from another function that takes arguments. This requires an additional layer of wrapping but allows dynamic behavior based on external parameters (e.g., setting logging levels). Decorators also interact intricately with the function's metadata; hence, functions like `functools.wraps` are crucial for preserving attributes such as `__name__`, `__doc__`, and `__annotations__`. The introduction of PEP 570 allowed decorators to be applied using `@classmethod`, `@staticmethod`, and `@property`, providing more flexibility in modifying class methods or properties.\n\nA deeper understanding involves exploring how decorators can interact with Python's function closures, the descriptor protocol, and metaclasses. They play a significant role in asynchronous programming, as seen with async decorators wrapping coroutine functions to manage execution flow. Performance considerations are vital when designing complex decorators, particularly those involving I/O operations or extensive computation within wrapper logic.\n\nIn summary, decorators encapsulate functionality that can be applied across multiple function definitions without altering their core implementation, making them a cornerstone of idiomatic Python programming for advanced developers aiming at clean and maintainable code.", "difficulty": "advanced", "common_pitfalls": ["Forgetting to use `functools.wraps` leading to loss of original function metadata such as name and docstring.", "Incorrectly applying decorators with arguments, resulting in nested functions not behaving as expected.", "Overusing decorators, which can lead to code that is hard to read or debug due to multiple layers of abstraction.", "Not considering the impact on performance when adding complex logic within decorator wrappers."], "related_concepts": ["Higher-order Functions", "Closures and Function Scopes", "Descriptor Protocol", "Metaclasses", "Asynchronous Programming with `async`/`await`", "functools.wraps"], "tags": []}, {"id": "2268578e-8cad-422e-ba4d-8a9f46b9af71", "name": "Class", "value": [{"id": "717e2929-c944-423d-9632-a9d307b1d7cd", "type": "paragraph", "value": "<strong>A template for creating user-defined objects.</strong>"}, {"id": "120dabcb-51ad-4d51-8429-0d300e804b8d", "type": "block_code", "value": "class MyClass:\n    def __init__(self, a):\n        self.a = a\n    def __str__(self):\n        return str(self.a)\n    def __repr__(self):\n        class_name = self.__class__.__name__\n        return f'{class_name}({self.a!r})'\n\n    @classmethod\n    def get_class_name(cls):\n        return cls.__name__"}, {"id": "0eb90a35-6fc5-4f51-b153-e79114678a7b", "type": "block_code", "value": ">>> obj = MyClass(1)\n>>> obj.a, str(obj), repr(obj)\n(1, '1', 'MyClass(1)')"}, {"id": "4c6cc5a2-56e3-4687-b5a6-b8de8c6a5a24", "type": "list", "value": "<li><strong>Return value of str() should be readable and of repr() unambiguous.</strong></li>\n<li><strong>If only repr() is defined, it will also be used for str().</strong></li>\n<li><strong>Methods decorated with <code>'@staticmethod'</code> do not receive 'self' nor 'cls' as their first argument.</strong></li>"}, {"id": "dfa93e76-cd1f-4deb-bd21-bdc1cfc1bb33", "type": "heading", "value": "Expressions that call the str() method:"}, {"id": "b4c67905-f1f6-41b6-8d3f-6e6f92351600", "type": "block_code", "value": "print(<obj>)\nf'{<obj>}'\nlogging.warning(<obj>)\ncsv.writer(<file>).writerow([<obj>])\nraise Exception(<obj>)"}, {"id": "7e85c62c-6ffa-423f-b5ea-251740681635", "type": "heading", "value": "Expressions that call the repr() method:"}, {"id": "e209236b-e3be-4788-b2a4-8c241e642d11", "type": "block_code", "value": "print/str/repr([<obj>])\nprint/str/repr({<obj>: <obj>})\nf'{<obj>!r}'\nZ = make_dataclass('Z', ['a']); print/str/repr(Z(<obj>))\n>>> <obj>"}], "sub_concepts": [{"id": "5c963018-1050-40a2-a872-6e49f7f927d9", "name": "Copy", "value": [{"id": "7ddae401-13d5-46cc-acd4-a75dc34ddff3", "type": "block_code", "value": "from copy import copy, deepcopy\n<object> = copy/deepcopy(<object>)"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "A class in Python is a blueprint for creating objects with attributes and methods, enabling encapsulation, inheritance, and polymorphism.", "description": "In Python, classes are fundamental constructs that enable encapsulation, inheritance, and polymorphism. They serve as blueprints for creating objects (instances), each of which can have attributes (data) and methods (functions). Classes leverage the `class` keyword to define a new type with its own namespace, where attributes and methods are stored. Internally, Python uses dictionaries to hold class attributes; when an instance is created, another dictionary is used for that specific object's data.\n\nPython classes support advanced features such as descriptors, metaclasses, and special (dunder) methods. Descriptors provide a protocol for attribute access control via `__get__()`, `__set__()`, and `__delete__()`. Metaclasses allow customization of class creation itself by subclassing from `type`, Python's built-in metaclass. Dunder methods enable operator overloading and other behaviors, like implementing `__call__` to make instances callable or `__enter__`/`__exit__` for context management.\n\nInheritance allows a derived (child) class to inherit attributes and methods from a base (parent) class, promoting code reuse. Python's method resolution order (MRO), determined via the C3 linearization algorithm, dictates how methods are inherited in complex multiple inheritance scenarios. This ensures consistency and predictability when dealing with diamond inheritance problems.\n\nClasses are also central to object-oriented programming paradigms in Python, allowing for sophisticated design patterns such as factory or singleton. The `__new__` method can be overridden for customizing instance creation, while the `__init__` method is used for initialization. As of Python 3.9+, the introduction of PEP 585 allows for more straightforward generic type hinting within classes.\n\nPerformance implications include considerations around the use of class attributes versus instance attributes, as shared state can lead to unintended side effects if not carefully managed. Moreover, excessive reliance on dynamic features like metaclasses and descriptors could impact readability and maintainability.\n\nAdvanced users often leverage classes in conjunction with abstract base classes (from the `abc` module) for defining interfaces or protocols. The `dataclasses` module introduced in PEP 557 streamlines class definitions by automatically generating special methods like `__init__()`, `__repr__()`, and others, reducing boilerplate code.\n\nPython's emphasis on simplicity means that while classes provide powerful capabilities, they should be used judiciously to avoid overcomplicating the design. Mastery of Python's OOP features facilitates writing clean, efficient, and maintainable code.", "difficulty": "advanced", "common_pitfalls": ["Confusing class variables (shared among all instances) with instance variables (unique to each object).", "Overriding `__new__` without calling it correctly can lead to unexpected behavior or memory leaks.", "Misunderstanding method resolution order in complex multiple inheritance scenarios.", "Neglecting to use `super()` properly, leading to issues with MRO and missing attribute/method calls.", "Improper use of descriptors for performance-critical code paths.", "Failing to document or handle the expected behavior when implementing abstract base classes."], "related_concepts": ["Object", "Inheritance", "Metaclass", "Dunder methods (Special Methods)", "Descriptors", "Abstract Base Classes (ABCs)", "Dataclasses", "Method Resolution Order (MRO)"], "tags": []}, {"id": "d873064d-f19c-4795-a322-626740f83af6", "name": "Duck Types", "value": [{"id": "4ecaca3d-1e29-4283-8b29-4486507667ca", "type": "paragraph", "value": "<strong>A duck type is an implicit type that prescribes a set of special methods. Any object that has those methods defined is considered a member of that duck type.</strong>"}], "sub_concepts": [{"id": "f26546fa-4d47-44a5-8d8a-57b637a33f39", "name": "Context Manager", "value": [{"id": "fb3201f3-08e6-4f41-b78f-387ac34741a6", "type": "list", "value": "<li><strong>With statements only work on objects that have enter() and exit() special methods.</strong></li>\n<li><strong>Enter() should lock the resources and optionally return an object.</strong></li>\n<li><strong>Exit() should release the resources (for example close a file).</strong></li>\n<li><strong>Any exception that happens inside the with block is passed to the exit() method.</strong></li>\n<li><strong>The exit() method can suppress the exception by returning a true value.</strong></li>"}, {"id": "fc2af8a0-b136-401a-b9b9-a8307be2f14d", "type": "block_code", "value": "class MyOpen:\n    def __init__(self, filename):\n        self.filename = filename\n    def __enter__(self):\n        self.file = open(self.filename)\n        return self.file\n    def __exit__(self, exc_type, exception, traceback):\n        self.file.close()"}, {"id": "2e5f0a96-c0eb-4684-9895-70233cf8f1b1", "type": "block_code", "value": ">>> with open('test.txt', 'w') as file:\n...     file.write('Hello World!')\n>>> with MyOpen('test.txt') as file:\n...     print(file.read())\nHello World!"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "Duck typing allows objects to be used interchangeably based on behavior rather than inheritance, facilitating flexible code design in Python.", "description": "Duck typing is a fundamental concept in dynamic programming languages like Python, where the suitability of an object for use is determined by the presence of certain methods or attributes rather than the actual type of the object. The name originates from the phrase 'If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck.' This paradigm allows Python developers to write flexible and reusable code without being bound by strict class hierarchies.\n\nIn Python, duck typing is particularly powerful because of its dynamic nature. When you call a method on an object or access an attribute, the interpreter doesn't check if the object belongs to a specific class; instead, it checks whether the method or attribute exists at runtime. This enables polymorphism without inheritance: different classes can be used interchangeably as long as they implement the required methods.\n\nDuck typing is closely related to protocols in Python (introduced by PEP 484 for type hints). While there are no formal interfaces in Python like in some statically-typed languages, duck typing effectively serves a similar purpose by allowing objects of different types to be used interchangeably based on their behavior. The presence of specific methods or attributes at runtime ensures that these objects can fulfill certain roles.\n\nAdvanced use cases include implementing flexible APIs where the input data structures are varied but must adhere to expected behaviors. It is also useful in creating mocking and stubbing in tests, where you might want to create stand-ins for complex objects without caring about their exact types.\n\nHowever, duck typing can lead to runtime errors if an object does not have the expected methods or attributes. This necessitates defensive programming techniques like exception handling or using `hasattr()` checks. Performance implications are generally minimal unless there's excessive reliance on attribute lookups in performance-critical sections of code.\n\nDuck typing is a cornerstone of Python's philosophy, encapsulated by 'It's easier to ask for forgiveness than permission' (EAFP). It encourages writing more flexible and adaptable code but also requires developers to be mindful of potential runtime errors. Understanding when to rely on duck typing versus using formal abstractions like abstract base classes or interfaces can significantly impact the maintainability and robustness of Python applications.\n\nWhile PEPs directly related to duck typing are scarce, it's closely tied with concepts from several key PEPs that discuss type hints (PEP 484) and dynamic attribute access (PEP 3155 for `__getattr__`), which further enhance its utility in modern Python development.", "difficulty": "intermediate", "common_pitfalls": ["Over-reliance on duck typing can lead to runtime errors if attributes or methods are not present as expected.", "Misunderstanding that objects without explicit type declarations still require careful method and attribute management.", "Failing to handle cases where objects do not conform to the expected 'duck' behavior, leading to uncaught exceptions."], "related_concepts": ["Dynamic typing", "Polymorphism", "EAFP (Easier to ask for forgiveness than permission)", "Abstract base classes", "Type hints and PEP 484"], "tags": []}, {"id": "8de8a74b-d6e9-4a3b-af8d-9d451a864707", "name": "Iterable Duck Types", "value": [], "sub_concepts": [{"id": "a7e3741f-677e-444b-9348-cbb1f52fd14f", "name": "ABC Sequence", "value": [{"id": "b8f51fd1-460c-485b-af49-c042a935c575", "type": "list", "value": "<li><strong>It's a richer interface than the basic sequence.</strong></li>\n<li><strong>Extending it generates iter(), contains(), reversed(), index() and count().</strong></li>\n<li><strong>Unlike <code>'abc.Iterable'</code> and <code>'abc.Collection'</code>, it is not a duck type. That is why <code>'issubclass(MySequence, abc.Sequence)'</code> would return False even if MySequence had all the methods defined. It however recognizes list, tuple, range, str, bytes, bytearray, array, memoryview and deque, since they are registered as Sequence's virtual subclasses.</strong></li>"}, {"id": "5ad9678f-62ce-474a-99ec-a9be4707aca9", "type": "block_code", "value": "from collections import abc\n\nclass MyAbcSequence(abc.Sequence):\n    def __init__(self, a):\n        self.a = a\n    def __len__(self):\n        return len(self.a)\n    def __getitem__(self, i):\n        return self.a[i]"}, {"id": "2b55b034-976e-4b3d-9c79-ac4711e2ac7a", "type": "heading", "value": "Table of required and automatically available special methods:"}, {"id": "6348f53a-f8fe-499a-82c7-26377a7206c4", "type": "block_code", "value": "+------------+------------+------------+------------+--------------+\n|            |  Iterable  | Collection |  Sequence  | abc.Sequence |\n+------------+------------+------------+------------+--------------+\n| iter()     |    REQ     |    REQ     |    Yes     |     Yes      |\n| contains() |    Yes     |    Yes     |    Yes     |     Yes      |\n| len()      |            |    REQ     |    REQ     |     REQ      |\n| getitem()  |            |            |    REQ     |     REQ      |\n| reversed() |            |            |    Yes     |     Yes      |\n| index()    |            |            |            |     Yes      |\n| count()    |            |            |            |     Yes      |\n+------------+------------+------------+------------+--------------+"}, {"id": "2778b07d-9a32-4beb-813a-76145efac2cd", "type": "list", "value": "<li><strong>Method iter() is required for <code>'isinstance(&lt;obj&gt;, abc.Iterable)'</code> to return True, however any object with getitem() will work with any code expecting an iterable.</strong></li>\n<li><strong>MutableSequence, Set, MutableSet, Mapping and MutableMapping ABCs are also extendable. Use <code>'&lt;abc&gt;.__abstractmethods__'</code> to get names of required methods.</strong></li>"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "Duck typing in Python allows objects to be treated as iterables based on their implementation of iteration methods rather than their inheritance from a specific class, promoting flexibility and polymorphism.", "description": "In Python, the concept of duck typing refers to a dynamic typing philosophy where an object\u2019s suitability is determined by the presence of certain methods or attributes rather than its inheritance from a particular class. This approach aligns with the adage 'If it looks like a duck and quacks like a duck, then it probably is a duck.' In terms of iterables, this means that any object can be considered iterable as long as it implements the necessary iterator protocol methods: `__iter__()` or `__getitem__()`. The `__iter__` method should return an iterator object which defines a `__next__` method to fetch successive items. This allows objects to seamlessly integrate with Python\u2019s iteration constructs, such as loops and comprehensions.\n\nDuck typing for iterables emphasizes flexibility and extensibility in code design, promoting loose coupling and polymorphism without strict class hierarchies. This can improve code readability and maintainability by allowing different types of objects to be processed uniformly through a common interface. For performance considerations, it's important to recognize that duck-typed iterables may involve runtime checks for attribute presence or method calls, potentially introducing overhead compared to statically typed solutions.\n\nAdvanced use cases often leverage duck typing to create highly generic functions and libraries that operate on any iterable data type. This can be seen in functions like `map`, `filter`, and `zip`, which accept any sequence-like object conforming to the expected interface. Python\u2019s PEP 20, 'The Zen of Python,' implicitly endorses this philosophy with its emphasis on simplicity and readability over rigid formalism.\n\nWhile duck typing provides significant flexibility, it can lead to runtime errors if assumptions about an object's behavior are incorrect. This necessitates thorough testing and documentation to ensure that the expected interface is consistently implemented across different objects.", "difficulty": "intermediate", "common_pitfalls": ["Assuming that an object is iterable without verifying the presence of `__iter__()` or `__getitem__()`. This can lead to runtime errors if iterability is assumed incorrectly.", "Over-relying on duck typing in performance-critical sections, where explicit checks and optimizations might be necessary.", "Neglecting edge cases where objects may implement iteration methods but behave unexpectedly during iteration."], "related_concepts": ["Iterator protocol", "Protocol classes (PEP 544)", "Generators", "Sequence types", "Polymorphism"], "tags": []}, {"id": "6e7d51b1-7f5c-4ca5-b2db-57ce4fcba27e", "name": "Enum", "value": [{"id": "81a08af7-3a2c-4acf-ae14-e06276d72641", "type": "paragraph", "value": "<strong>Class of named constants called members.</strong>"}, {"id": "b913b402-e6a4-484f-8e81-a04dbb6bd868", "type": "block_code", "value": "from enum import Enum, auto"}, {"id": "27b6ab3c-eba1-4a9f-a74e-7416a1b7c7ef", "type": "block_code", "value": "class <enum_name>(Enum):\n    <member_name> = auto()              # Increment of the last numeric value or 1.\n    <member_name> = <value>             # Values don't have to be hashable.\n    <member_name> = <el_1>, <el_2>      # Values can be collections (this is a tuple)."}, {"id": "920a8a8c-caf6-4c55-a03a-b9926a3a9429", "type": "list", "value": "<li><strong>Methods receive the member they were called on as the 'self' argument.</strong></li>\n<li><strong>Accessing a member named after a reserved keyword causes SyntaxError.</strong></li>"}, {"id": "f72addc0-9b8e-4069-9cef-ea50bc3d0c22", "type": "block_code", "value": "<member> = <enum>.<member_name>         # Returns a member. Raises AttributeError.\n<member> = <enum>['<member_name>']      # Returns a member. Raises KeyError.\n<member> = <enum>(<value>)              # Returns a member. Raises ValueError.\n<str>    = <member>.name                # Returns member's name.\n<obj>    = <member>.value               # Returns member's value."}, {"id": "17a7a8e7-2236-4bc4-9f3c-76c9450c5eb5", "type": "block_code", "value": "<list>   = list(<enum>)                 # Returns enum's members.\n<list>   = [a.name for a in <enum>]     # Returns enum's member names.\n<list>   = [a.value for a in <enum>]    # Returns enum's member values."}, {"id": "717eb37f-4467-4fd8-94d1-5a56ad060501", "type": "block_code", "value": "<enum>   = type(<member>)               # Returns member's enum.\n<iter>   = itertools.cycle(<enum>)      # Returns endless iterator of members.\n<member> = random.choice(list(<enum>))  # Returns a random member."}], "sub_concepts": [{"id": "33d2c2c9-9ebb-43ea-9166-cc43a736fb69", "name": "Inline", "value": [{"id": "29c4608a-5748-43b1-99e7-8ad0b7346e76", "type": "block_code", "value": "Cutlery = Enum('Cutlery', 'FORK KNIFE SPOON')\nCutlery = Enum('Cutlery', ['FORK', 'KNIFE', 'SPOON'])\nCutlery = Enum('Cutlery', {'FORK': 1, 'KNIFE': 2, 'SPOON': 3})"}, {"id": "d82723c5-2c49-4c6a-980b-eae2b740b8fd", "type": "heading", "value": "User-defined functions cannot be values, so they must be wrapped:"}, {"id": "fd7e7a15-6df3-4b1e-8361-dfb3a62aa817", "type": "block_code", "value": "from functools import partial\nLogicOp = Enum('LogicOp', {'AND': partial(lambda l, r: l and r),\n                           'OR':  partial(lambda l, r: l or r)})"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "The `enum` module defines enumerations in Python, offering a way to create named, constant values that enhance code readability and maintainability.", "description": "The `enum` module in Python provides support for enumerations, a set of symbolic names bound to unique, constant values. Introduced in PEP 435 and standardized in Python 3.4, enumerations are iterable, comparable, and immutable types that enhance code readability by offering a way to define named constants. Each enumeration member is an instance of the `Enum` class or its subclasses, ensuring they behave like singletons with a distinct name and value.\n\nUnderlying Mechanism: Enums leverage metaclasses (`_EnumMeta`) to ensure each member is unique and immutable. The `__new__` method enforces uniqueness based on either names or values, preventing duplicate entries. The enum members are stored as class attributes, making them accessible through the enumeration itself (e.g., `Color.RED`). This design ensures that enums maintain a consistent interface while providing additional methods like `name`, `value`, and comparison operations.\n\nPerformance Implications: Enums can enhance performance by reducing errors related to using arbitrary constants. Since they are immutable and hashable, they can be used as keys in dictionaries or elements of sets without modification risk. However, excessive use of large enumerations may slightly increase memory usage due to the storage of each member's metadata.\n\nAdvanced Use Cases: Enums are particularly useful in scenarios requiring fixed sets of constants, such as state machines, configuration settings, and protocol specifications. They can be extended with methods for additional functionality or overridden to customize behavior (e.g., defining custom `__new__` or `__init__`). Additionally, they support reverse lookup by value using the `_value2member_map_` attribute.\n\nPEPs: Enumerations are defined in PEP 435 and further refined in PEP 526 for type hints. They also integrate with Python's typing module to provide more robust type checking through `EnumMeta`.\n\nInternals and Iterators: Enums implement the iterator protocol, allowing iteration over members using loops or comprehensions. The `__iter__` method yields enum members, making them compatible with iterable contexts. The `@unique` decorator from the `enum` module can be used to enforce uniqueness of either names or values across all members.\n\nSpecial Methods: Enums provide several special methods for advanced manipulation and introspection, such as `_missing_` for handling undefined attributes and `_generate_next_value_` for custom value generation strategies.\n", "difficulty": "advanced", "common_pitfalls": ["Forgetting to import the Enum class from the enum module can lead to errors when defining enumerations.", "Attempting to modify an enumeration member's value will raise a TypeError due to immutability.", "Using non-unique values or names for enum members without applying the @unique decorator can result in unexpected behavior.", "Overlooking reverse lookup capabilities of enums by value, which can simplify certain tasks."], "related_concepts": ["Metaclasses", "Immutability", "Singleton Pattern", "Hashable Objects", "Iterable Protocol", "PEP 435", "Type Hints"], "tags": []}, {"id": "a75e1a54-29d3-420b-ac3d-452d70f3abbb", "name": "Exceptions", "value": [{"id": "c9a05874-97ba-4435-94f6-d7bccaa7fab8", "type": "block_code", "value": "try:\n    <code>\nexcept <exception>:\n    <code>"}], "sub_concepts": [{"id": "2f8becfa-11b7-432d-b200-7e5bc8b7c802", "name": "User-defined Exceptions", "value": [{"id": "10447ffb-3da8-41ff-9c89-7e5b169deb57", "type": "block_code", "value": "class MyError(Exception): pass\nclass MyInputError(MyError): pass"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "Exceptions in Python are objects used for signaling errors or unexpected events, enabling sophisticated error-handing strategies through inheritance and custom exception classes.", "description": "In Python, exceptions are a key component of its error-handling model. They enable the creation of robust applications by facilitating the management of errors in a controlled manner. At their core, exceptions are objects representing an error or unexpected event that disrupts the normal flow of execution. Python uses a built-in hierarchy for exception classes, inheriting from the base class `BaseException`. The most common subclasses used are `Exception`, which serves as a base for most user-defined and standard library exceptions, and its direct subclass `RuntimeError`, among others like `IOError` (now `OSError`) or `ValueError`. Python's philosophy is to encourage catching specific exceptions rather than general ones. This specificity enhances error handling precision, allowing developers to respond differently based on the type of exception encountered.\n\nThe mechanism for raising and catching exceptions is fundamental to advanced Python programming. The `raise` statement allows programmers to throw an exception explicitly, while the `try-except` block enables them to catch and handle these exceptions. Advanced use cases might involve creating custom exception classes by subclassing from `Exception`, which can include additional attributes or methods relevant to specific error conditions. Furthermore, Python 3 introduced more sophisticated features such as exception chaining with the `from` keyword, allowing developers to specify a direct cause of an exception, enhancing traceability and debugging capabilities.\n\nA notable aspect of exceptions is their impact on performance. While necessary for robustness, excessive use or unnecessary catching of exceptions can degrade application performance due to the overhead associated with raising them and creating exception objects. Best practices recommend using exceptions primarily for truly exceptional conditions rather than regular control flow. Additionally, Python's context managers (`with` statement) often utilize exception handling internally to ensure resources are properly managed (e.g., files or network connections), demonstrating a high-level application of this mechanism.\n\nFor advanced users, understanding the internal workings of exceptions involves recognizing how they interact with the interpreter's frame stack and how propagation through different layers of code works. This knowledge is crucial for debugging complex applications. Furthermore, Python 3.9+ introduced improvements like `Exception Group` in PEP 654, which allows grouping multiple exception instances together, enabling more granular handling of concurrent operations.\n\nThe iterator protocol and the coroutine's interaction with exceptions also provide depth to exception handling, allowing asynchronous code to manage error states effectively. This is particularly relevant when using coroutines with `asyncio`, where exceptions can be propagated through event loops, requiring careful management.", "difficulty": "advanced", "common_pitfalls": ["Overusing try-except blocks for control flow rather than exceptional conditions can lead to poor performance and unreadable code.", "Catching general exceptions like `Exception` or even broader, such as `BaseException`, without handling specific errors appropriately may mask bugs and make debugging difficult.", "Failing to propagate exceptions correctly in asynchronous code can result in unhandled exception states leading to subtle bugs."], "related_concepts": ["Custom Exception Classes", "Context Managers", "Coroutine Error Handling with asyncio", "Exception Chaining", "Iterator Protocol"], "tags": []}, {"id": "0680dc70-640d-4f2c-b7b6-5d9d9af72480", "name": "Exit", "value": [{"id": "9208e9e0-ca2e-4cbe-9969-f65af72826bf", "type": "paragraph", "value": "<strong>Exits the interpreter by raising SystemExit exception.</strong>"}, {"id": "af6ecfdf-4891-45d7-8148-d7bfa465b26b", "type": "block_code", "value": "import sys\nsys.exit()                        # Exits with exit code 0 (success).\nsys.exit(<int>)                   # Exits with the passed exit code.\nsys.exit(<obj>)                   # Prints to stderr and exits with 1."}], "sub_concepts": [], "short_description": "`sys.exit()` terminates a program immediately, raising `SystemExit`, which can be intercepted for cleanup, especially within asynchronous contexts post-PEP 475/479 adaptations.", "description": "The `sys.exit()` function in Python is a built-in method used to terminate the program execution. It is part of the `sys` module, which provides access to some variables used or maintained by the interpreter and to functions that interact strongly with the interpreter. The primary purpose of `sys.exit()` is to exit from Python without running any cleanup actions or executing any remaining code in the current stack. When invoked, it raises a `SystemExit` exception, which can be caught within the program if needed, allowing for custom cleanup operations before termination.\n\nFrom an advanced perspective, understanding how `sys.exit()` interacts with the event loop and signal handling is crucial, especially in applications that involve concurrency or asynchronous programming. In Python 3.7 and later, due to PEP 475 and PEP 479, calling `sys.exit()` within a running event loop will trigger the `asyncio.CancelledError` exception on all current tasks rather than raising `SystemExit`. This modification ensures that an asyncio program can be shut down gracefully when using `sys.exit()`, allowing ongoing asynchronous operations to complete or be cancelled properly.\n\nFor developers dealing with applications where cleanup and resource management are critical, such as web servers or long-running data processing scripts, knowing the implications of `sys.exit()` is essential. For instance, it does not call any cleanup handlers registered through `atexit.register()`, nor does it trigger the object finalizers (destructors) for garbage collection unless explicitly managed within a caught exception block.\n\nIn terms of performance and system resource management, using `sys.exit()` can be more efficient than other methods of termination that involve raising exceptions or relying on program flow control to exit. However, developers must ensure that any necessary cleanup code is executed before calling this function, as it will bypass the usual object lifecycle management in Python.\n\nAdvanced users often combine `sys.exit()` with signal handling (using the `signal` module) to allow for graceful termination upon receiving external signals like SIGINT or SIGTERM. This setup can be crucial in server applications where immediate shutdowns need to be handled without corrupting data or leaving resources locked.\n\nRelevant PEPs include PEP 475 ('sys.exit() should cause the interpreter to exit') and PEP 479 ('asyncio: make sys.exit() cancel running tasks'), which outline changes and behaviors related to `sys.exit()` in modern Python versions.", "difficulty": "advanced", "common_pitfalls": ["Forgetting to handle `SystemExit` properly in signal handlers or when using asyncio, leading to abrupt terminations without proper resource release.", "Assuming that `sys.exit()` will perform cleanup tasks automatically, such as calling atexit registered functions or finalizers, which it does not.", "Misunderstanding the interaction between `sys.exit()` and the event loop in asynchronous applications, potentially resulting in unhandled task cancellation."], "related_concepts": ["`SystemExit` exception", "`atexit.register()` for cleanup tasks", "Signal handling with the `signal` module", "Asynchronous programming and event loops (`asyncio`)", "Exception handling and propagation"], "tags": []}, {"id": "5d247949-a52a-460f-a1bd-bd18940d3eb7", "name": "Print", "value": [{"id": "b35b0a89-3671-4ca2-b1ed-7fb81c0b9eaa", "type": "block_code", "value": "print(<el_1>, ..., sep=' ', end='\\n', file=sys.stdout, flush=False)"}, {"id": "56702791-7436-4dd5-9a5e-adb53873001b", "type": "list", "value": "<li><strong>Use <code>'file=sys.stderr'</code> for messages about errors.</strong></li>\n<li><strong>Stdout and stderr streams hold output in a buffer until they receive a string containing '\\n' or '\\r', buffer reaches 4096 characters, <code>'flush=True'</code> is used, or program exits.</strong></li>"}], "sub_concepts": [{"id": "634513be-d21e-4985-9e81-fc48b219c863", "name": "Pretty Print", "value": [{"id": "580d154c-d4ab-4bac-9005-b7cf4b23f3b6", "type": "block_code", "value": "from pprint import pprint\npprint(<collection>, width=80, depth=None, compact=False, sort_dicts=True)"}, {"id": "3223eb60-6de0-48a1-92b8-9d813dd149bf", "type": "list", "value": "<li><strong>Each item is printed on its own line if collection exceeds 'width' characters.</strong></li>\n<li><strong>Nested collections that are 'depth' levels deep get printed as '...'.</strong></li>"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "`print()` outputs text to the console, providing flexible formatting options and direct control over output streams.", "description": "The `print()` function in Python is a built-in utility that outputs text or other objects to the console. It plays a fundamental role in debugging, logging, and displaying results during development. Underneath its simple interface lies a series of complex mechanisms tailored for flexibility and performance.\n\nAt a high level, when called with one or more arguments, `print()` converts these arguments into strings using the `str()` function, concatenates them using a separator (default is a space), and finally writes the result to a specified file-like object, typically `sys.stdout`. The function also allows for an optional end parameter that specifies what should be appended after the last value (defaulting to a newline character).\n\nThe flexibility of `print()` is further extended by its support for keyword arguments. Commonly used keywords include:\n- `sep`: A string inserted between values.\n- `end`: A string added at the end, default being '\\n'.\n- `file`: An object with a write() method where the output will be directed; typically this is `sys.stdout` but can be redirected to files or other streams.\n\nInternally, `print()` ensures efficient handling of I/O operations. It uses buffered I/O for performance optimization, especially significant when dealing with large volumes of text. When redirecting output (e.g., using file redirection in a terminal), Python handles the buffering transparently, ensuring data integrity and minimizing latency.\n\nAdvanced users might interact with `print()`'s underlying mechanisms by manipulating the standard streams (`sys.stdout`, `sys.stderr`) directly, or by customizing the behavior of I/O operations via context managers and hooks. The function's internal workings align closely with Python's philosophy of simplicity and readability while maintaining flexibility for more complex needs.\n\nIn terms of performance implications, although `print()` is efficient for most use cases due to its buffered nature, excessive logging or debugging in a production environment can lead to I/O bottlenecks. Thus, advanced users might prefer structured logging frameworks like `logging` module that provide more control and features tailored for high-performance environments.\n\nWhile not directly covered by PEPs, the evolution of `print()` reflects broader changes in Python's print handling philosophy as seen from Python 2 to 3, where explicit function calls replaced statements (e.g., `print \"Hello\"` becoming `print(\"Hello\")`). The emphasis on clearer syntax and enhanced functionality is a hallmark of Python's development trajectory.\n\nMoreover, advanced use cases involve using `print()` in conjunction with formatted string literals (`f-strings`) introduced in PEP 498 for more readable and efficient output formatting. This feature is particularly valuable when dealing with complex data structures or requiring dynamic content generation within the printed output.", "difficulty": "beginner", "common_pitfalls": ["Overusing `print()` for debugging in production code can lead to performance issues due to I/O overhead.", "Confusion between using commas or spaces as separators when multiple arguments are provided.", "Assuming that changes made via the `file` parameter reflect immediately without understanding buffered I/O behavior."], "related_concepts": ["`str()`: Converting objects into strings for representation in output.", "Formatted String Literals (f-strings): Enhanced string formatting capabilities introduced by PEP 498.", "`sys.stdout` and `sys.stderr`: Standard streams that can be redirected or manipulated directly.", "`logging`: Python's built-in logging module provides a more robust framework for managing output and debugging information."], "tags": []}, {"id": "a8d9d38e-20b1-4702-87cd-39ee497343b2", "name": "Input", "value": [{"id": "33f0f6bd-1d4d-42bb-9808-26822b6283b1", "type": "block_code", "value": "<str> = input()"}, {"id": "8ea49672-864f-4c07-988a-8a82027b7064", "type": "list", "value": "<li><strong>Reads a line from the user input or pipe if present (trailing newline gets stripped).</strong></li>\n<li><strong>If argument is passed, it gets printed to the standard output before input is read.</strong></li>\n<li><strong>EOFError is raised if user hits EOF (ctrl-d/ctrl-z\u23ce) or if stream is already exhausted.</strong></li>"}], "sub_concepts": [], "short_description": "`input()` reads a line from standard input, returning it as a string, primarily used for capturing user interaction in scripts or interactive sessions.", "description": "In Python, `input()` is a built-in function that reads a line from input (usually from the user), converts it into a string by removing the trailing newline, and returns it. While seemingly simple, understanding its implications in both synchronous I/O operations and interactive applications can be quite insightful for advanced users. Internally, `input()` uses the `sys.stdin.read(1)` to read one character at a time until it encounters an end-of-file condition or a newline character. This behavior is crucial in environments where input needs to be captured interactively, such as command-line interfaces.\n\nFrom a performance standpoint, using `input()` can introduce blocking operations in scripts designed for high-performance or asynchronous tasks. In such cases, alternatives like threading or asyncio's event loops are considered, allowing the program to remain responsive while waiting for user input. Furthermore, it is essential to handle exceptions like `EOFError`, which occur when an end-of-file condition is reached on standard input.\n\n`input()` also ties into Python's dynamic typing system. Since it returns a string, explicit type conversion is often necessary when the expected result should be of another data type (e.g., using `int(input())` to read an integer). This characteristic opens up discussions about safe parsing and error handling techniques in robust applications.\n\nAdvanced use cases include creating interactive command-line tools or educational programs where user input directly influences program behavior. Additionally, when used within scripts that are executed interactively versus those run from a file, `input()` may behave differently depending on whether the script is being debugged or executed as part of an automated pipeline (e.g., in CI/CD environments).\n\nRelevant PEPs include PEP 3116, which formalized Python's interactive input and output features. Understanding its nuances helps developers design more user-friendly interfaces and handle input more effectively across various execution contexts.", "difficulty": "intermediate", "common_pitfalls": ["Assuming `input()` returns the correct data type without explicit conversion, leading to potential runtime errors.", "Failing to handle EOFError when using `input()` in a context where input might be unavailable (e.g., redirected from a file or piped data).", "Using `input()` in multi-threaded applications without proper synchronization, which can lead to race conditions or inconsistent state."], "related_concepts": ["`sys.stdin` for more direct control over standard input operations.", "`EOFError` handling when dealing with end-of-file scenarios in input streams.", "`eval()` and `ast.literal_eval()` for safely evaluating strings into Python expressions.", "`argparse` module for command-line argument parsing as an alternative to interactive input."], "tags": []}, {"id": "99f616ea-d0ff-4f5d-92d8-dd0260cd4ace", "name": "Command Line Arguments", "value": [{"id": "e260b054-4578-4a85-9df1-2cd2b1911154", "type": "block_code", "value": "import sys\nscripts_path = sys.argv[0]\narguments    = sys.argv[1:]"}], "sub_concepts": [{"id": "0b51b136-a354-4fd6-bd98-35ca3a439841", "name": "Argument Parser", "value": [{"id": "daaa878b-9a86-49ee-98ce-5758becaa128", "type": "block_code", "value": "from argparse import ArgumentParser, FileType\np = ArgumentParser(description=<str>)                             # Returns a parser.\np.add_argument('-<short_name>', '--<name>', action='store_true')  # Flag (defaults to False).\np.add_argument('-<short_name>', '--<name>', type=<type>)          # Option (defaults to None).\np.add_argument('<name>', type=<type>, nargs=1)                    # Mandatory first argument.\np.add_argument('<name>', type=<type>, nargs='+')                  # Mandatory remaining args.\np.add_argument('<name>', type=<type>, nargs='?/*')                # Optional argument/s.\nargs  = p.parse_args()                                            # Exits on parsing error.\n<obj> = args.<name>                                               # Returns `<type>(<arg>)`."}, {"id": "1f4a3ac9-e90f-417c-8f21-5ddc5edd4db9", "type": "list", "value": "<li><strong>Use <code>'help=&lt;str&gt;'</code> to set argument description that will be displayed in help message.</strong></li>\n<li><strong>Use <code>'default=&lt;obj&gt;'</code> to set option's or optional argument's default value.</strong></li>\n<li><strong>Use <code>'type=FileType(&lt;mode&gt;)'</code> for files. Accepts 'encoding', but 'newline' is None.</strong></li>"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "Command line arguments in Python allow passing of inputs to scripts at runtime, enabling dynamic configuration through tools like `argparse` or `click`, which simplify argument parsing and validation.", "description": "Command line arguments in Python are a powerful feature that allows users to pass external inputs to scripts at runtime. The `sys` module provides access to the list of command-line arguments via `sys.argv`, which is a list where the first element is always the script name, and subsequent elements represent additional arguments passed by the user. This mechanism enables scripts to be highly flexible and adaptable to different use cases without modifying the codebase.\n\nAdvanced usage of command line arguments often involves leveraging libraries such as `argparse` or `click`, which provide robust tools for parsing and validating inputs. The `argparse` module, introduced in Python 2.7 and maintained since then, supports a wide range of argument types (e.g., strings, integers, flags) and features like default values, help messages, subcommands, and mutually exclusive groups. It is backed by PEP 380 which standardizes argument parsing across different applications.\n\n`argparse` works by creating an `ArgumentParser` object to which you add expected arguments using methods such as `add_argument()`. The parser then processes the command line input (`sys.argv`) and generates a namespace with attributes corresponding to each argument. This method is both efficient and user-friendly, as it automatically generates help messages and handles errors gracefully.\n\nPerformance-wise, parsing command-line arguments is lightweight but can become complex when dealing with numerous or optional arguments. Efficient handling involves setting sensible defaults and constraints to ensure the script behaves predictably under various inputs.\n\nAdvanced users often use command line arguments in combination with logging configurations, environment variables, or configuration files to create scripts that are both configurable and maintainable. This integration is crucial for building robust CLI applications or automation scripts. Furthermore, understanding how to manage unexpected or erroneous input gracefully is vital for maintaining script reliability and user experience.\n\nCommon advanced use cases include creating configurable data processing pipelines, automating deployments, and integrating Python scripts into larger systems where external control over behavior is necessary.", "difficulty": "intermediate", "common_pitfalls": ["Failing to handle default values properly can lead to unexpected behavior when arguments are omitted.", "Misunderstanding the difference between positional, optional, and flag arguments in `argparse`.", "Not validating command line inputs can result in runtime errors or crashes.", "Overlooking the need for help messages which aid users in understanding script usage."], "related_concepts": ["sys.argv", "argparse.ArgumentParser", "click.Command", "environment variables", "configuration files", "logging configurations"], "tags": []}, {"id": "fdcd7da2-26b4-4180-852a-f3cac520c62d", "name": "Open", "value": [{"id": "aafa9759-0fe5-4e55-8186-45cf9b67ce60", "type": "paragraph", "value": "<strong>Opens a file and returns the corresponding file object.</strong>"}, {"id": "36873d57-334b-4d03-8827-1fef7c793a87", "type": "block_code", "value": "<file> = open(<path>, mode='r', encoding=None, newline=None)"}, {"id": "4b1fac25-90b3-4665-b366-a7f25c418073", "type": "list", "value": "<li><strong><code>'encoding=None'</code> means that the default encoding is used, which is platform dependent. Best practice is to use <code>'encoding=&quot;utf-8&quot;'</code> whenever possible.</strong></li>\n<li><strong><code>'newline=None'</code> means all different end of line combinations are converted to '\\n' on read, while on write all '\\n' characters are converted to system's default line separator.</strong></li>\n<li><strong><code>'newline=&quot;&quot;'</code> means no conversions take place, but input is still broken into chunks by readline() and readlines() on every '\\n', '\\r' and '\\r\\n'.</strong></li>"}], "sub_concepts": [{"id": "f847676b-8746-46e4-95c2-95752228e0f9", "name": "Write Text to File", "value": [{"id": "9d6c2518-d028-43ff-b010-9deac050910e", "type": "block_code", "value": "def write_to_file(filename, text):\n    with open(filename, 'w', encoding='utf-8') as file:\n        file.write(text)"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "`open()` is a versatile built-in function for file manipulation, supporting various modes and ensuring safe resource management through context managers.", "description": "The `open()` function in Python is a built-in function used for opening files. It provides a versatile interface to work with file objects, supporting different modes like reading (`'r'`), writing (`'w'`), appending (`'a'`), and binary operations (`'b'`). The function returns a file object which can be iterated over or read from/written to in various ways. Under the hood, `open()` interacts with Python's low-level file handling API, providing an abstraction that supports different operating system-specific behaviors. This includes buffering strategies, which affect performance and memory usage. With the introduction of context managers (using the `with` statement), `open()` ensures proper resource management by automatically closing files after their block is executed, reducing the risk of resource leaks. Advanced use cases include using custom file-like objects that implement methods like `read()`, `write()`, or `close()` to integrate seamlessly with Python's I/O framework. This allows for sophisticated data processing pipelines where input/output operations are abstracted behind these interfaces. The `open()` function is also enhanced in newer versions of Python (3.9+) to support additional parameters like `encoding` and `errors`, which control text encoding and error handling strategies respectively, making it more robust for diverse applications involving different character sets. PEP 519 introduced the `text` and `bytes` modes to simplify text and binary file handling, addressing common pitfalls in cross-platform file I/O operations.", "difficulty": "intermediate", "common_pitfalls": ["Forgetting to close files leading to resource leaks or data corruption.", "Incorrectly specifying file paths or encodings causing runtime errors.", "Misunderstanding mode strings, especially when using binary and text modes together.", "Overlooking the importance of error handling in file operations."], "related_concepts": ["File I/O", "Context Managers", "Buffering", "Exception Handling", "Pathlib (for modern path manipulations)", "os module (for OS-level file operations)"], "tags": []}, {"id": "c66f3327-d611-4e11-a3eb-92fb38f6bbb7", "name": "Paths", "value": [{"id": "29fe61dc-f7b4-47a9-b39e-908fe9853a8f", "type": "block_code", "value": "import os, glob\nfrom pathlib import Path"}, {"id": "d45eb702-6ec7-4cf9-99c9-20814b25754e", "type": "block_code", "value": "<str>  = os.getcwd()                # Returns working dir. Starts as shell's $PWD.\n<str>  = os.path.join(<path>, ...)  # Joins two or more pathname components.\n<str>  = os.path.realpath(<path>)   # Resolves symlinks and calls path.abspath()."}, {"id": "5f0011d8-7012-42fa-809a-265713ca817d", "type": "block_code", "value": "<str>  = os.path.basename(<path>)   # Returns final component of the path.\n<str>  = os.path.dirname(<path>)    # Returns path without the final component.\n<tup.> = os.path.splitext(<path>)   # Splits on last period of the final component."}, {"id": "c935f13f-1db6-4c16-b171-b1fd28df4f38", "type": "block_code", "value": "<list> = os.listdir(path='.')       # Returns filenames located at the path.\n<list> = glob.glob('<pattern>')     # Returns paths matching the wildcard pattern."}, {"id": "c2f833d4-ba20-4b48-99de-e0a84e4fc64b", "type": "block_code", "value": "<bool> = os.path.exists(<path>)     # Or: <Path>.exists()\n<bool> = os.path.isfile(<path>)     # Or: <DirEntry/Path>.is_file()\n<bool> = os.path.isdir(<path>)      # Or: <DirEntry/Path>.is_dir()"}, {"id": "ec6988d9-d17e-48a4-80fb-2d864b7d1e5c", "type": "block_code", "value": "<stat> = os.stat(<path>)            # Or: <DirEntry/Path>.stat()\n<num>  = <stat>.st_mtime/st_size/\u2026  # Modification time, size in bytes, etc."}], "sub_concepts": [{"id": "13cfae17-dda1-433d-a9bf-67de3d9d24a7", "name": "Path Object", "value": [{"id": "23a666b4-bbf6-44f4-85e6-76bf9326bea5", "type": "block_code", "value": "<Path> = Path(<path> [, ...])       # Accepts strings, Paths, and DirEntry objects.\n<Path> = <path> / <path> [/ ...]    # First or second path must be a Path object.\n<Path> = <Path>.resolve()           # Returns absolute path with resolved symlinks."}, {"id": "ea48b10b-24d2-48e7-a85a-67a45c1ac9c3", "type": "block_code", "value": "<Path> = Path()                     # Returns relative CWD. Also Path('.').\n<Path> = Path.cwd()                 # Returns absolute CWD. Also Path().resolve().\n<Path> = Path.home()                # Returns user's home directory (absolute).\n<Path> = Path(__file__).resolve()   # Returns module's path if CWD wasn't changed."}, {"id": "ee335ba8-cef5-4b2f-80d0-20f6abb183f4", "type": "block_code", "value": "<Path> = <Path>.parent              # Returns Path without the final component.\n<str>  = <Path>.name                # Returns final component as a string.\n<str>  = <Path>.suffix              # Returns name's last extension, e.g. '.py'.\n<str>  = <Path>.stem                # Returns name without the last extension.\n<tup.> = <Path>.parts               # Returns all components as strings."}, {"id": "de462872-e4bd-4d13-9cde-f22e6b76df66", "type": "block_code", "value": "<iter> = <Path>.iterdir()           # Returns directory contents as Path objects.\n<iter> = <Path>.glob('<pattern>')   # Returns Paths matching the wildcard pattern."}, {"id": "908d0108-3d99-437d-8896-11de0e56cc94", "type": "block_code", "value": "<str>  = str(<Path>)                # Returns path as str. Also <Path>.as_uri().\n<file> = open(<Path>)               # Also <Path>.read/write_text/bytes(<args>)."}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "`Pathlib` provides an object-oriented approach to handle filesystem paths, enhancing readability and cross-platform compatibility over traditional string-based methods like `os.path`.", "description": "In Python, 'path' is a fundamental concept used to navigate and manipulate file system paths across different operating systems. With the introduction of the `pathlib` module in Python 3.4 (PEP 428), handling file system paths became more intuitive and object-oriented compared to traditional string-based path manipulations using modules like `os.path`. `pathlib.Path` objects represent filesystem paths in an abstract, unified way that automatically adapts to different operating systems' conventions.\n\nThe `Path` class offers a host of methods for performing common path operations, such as joining components with `/`, accessing parent and child components, checking file properties (exists, is_dir, is_file), reading, writing files, and iterating over directory contents. The object-oriented nature allows chaining operations in a fluent manner. For instance, `Path('/foo').joinpath('bar').with_suffix('.txt')` constructs the path `/foo/bar.txt`.\n\nPerformance-wise, using `pathlib` can lead to cleaner and more readable code as opposed to string concatenations and manipulations required by `os.path`. However, since each operation returns a new `Path` object, there's a slight overhead compared to manipulating strings directly. This trade-off is usually outweighed by the benefits of clearer syntax and reduced error rates.\n\nCommon advanced use cases include building file navigation utilities or automating file operations across different environments. For instance, one might leverage `Path.glob()` for pattern-based file searches within directories, akin to shell globbing but with a higher-level interface. Another example is using `Path` objects in conjunction with context managers (e.g., `with open(path) as f`) for safer resource management.\n\nIn addition to its ease of use, the module's support for various path operations ensures compatibility across diverse filesystem environments, crucial for cross-platform applications and scripts. With Python 3.9, further enhancements such as `Path.resolve(strict=False)` provide more control over resolving paths that might not exist, enabling robust handling of symbolic links and relative paths.\n\nOverall, the `pathlib` module encapsulates complex path manipulation logic behind a simple, object-oriented interface, promoting better practices in modern Python codebases.", "difficulty": "intermediate", "common_pitfalls": ["Not accounting for platform-specific path separators when working with strings outside of `pathlib`.", "Failing to use absolute paths where necessary, leading to unexpected results in relative path manipulations.", "Overlooking the immutability of `Path` objects; new instances must be created for altered paths.", "Misunderstanding `resolve()` method behavior when dealing with symbolic links or nonexistent paths."], "related_concepts": ["`os.path`", "`shutil`", "Context managers", "File I/O operations", "Glob patterns"], "tags": []}, {"id": "9f592db6-e1b5-48c6-9303-ccdba6afa2df", "name": "OS Commands", "value": [{"id": "5df18f71-491b-4853-9783-d0ecb1894045", "type": "block_code", "value": "import os, shutil, subprocess"}, {"id": "36c0abc7-3daf-426c-b3d0-42fdcf95f731", "type": "block_code", "value": "os.chdir(<path>)                    # Changes the current working directory (CWD).\nos.mkdir(<path>, mode=0o777)        # Creates a directory. Permissions are in octal.\nos.makedirs(<path>, mode=0o777)     # Creates all path's dirs. Also `exist_ok=False`."}, {"id": "bef76dae-3546-4cf6-bc9f-ec9cd537e7c5", "type": "block_code", "value": "shutil.copy(from, to)               # Copies the file. 'to' can exist or be a dir.\nshutil.copy2(from, to)              # Also copies creation and modification time.\nshutil.copytree(from, to)           # Copies the directory. 'to' must not exist."}, {"id": "0556c9cc-f496-47ca-9792-8001e84a2a9e", "type": "block_code", "value": "os.rename(from, to)                 # Renames/moves the file or directory.\nos.replace(from, to)                # Same, but overwrites file 'to' even on Windows.\nshutil.move(from, to)               # Rename() that moves into 'to' if it's a dir."}, {"id": "2b291577-90af-491f-aa71-86bd41f637b7", "type": "block_code", "value": "os.remove(<path>)                   # Deletes the file.\nos.rmdir(<path>)                    # Deletes the empty directory.\nshutil.rmtree(<path>)               # Deletes the directory."}, {"id": "0bc43840-9856-4ecd-9043-905c21ba909d", "type": "list", "value": "<li><strong>Paths can be either strings, Path objects, or DirEntry objects.</strong></li>\n<li><strong>Functions report OS related errors by raising OSError or one of its <a href=\"#exceptions-1\">subclasses</a>.</strong></li>"}], "sub_concepts": [{"id": "d7faa349-761e-4a23-af3a-fe228de9bbe2", "name": "Shell Commands", "value": [{"id": "53f5e1a5-64b8-46ee-9719-252e67949485", "type": "block_code", "value": "<pipe> = os.popen('<commands>')     # Executes commands in sh/cmd. Returns combined stdout.\n<str>  = <pipe>.read(size=-1)       # Reads 'size' chars or until EOF. Also readline/s().\n<int>  = <pipe>.close()             # Returns None if last command exited with returncode 0."}, {"id": "dc5c4654-bd9b-4ec3-9522-09a7e097c328", "type": "heading", "value": "Sends &quot;1 + 1&quot; to the basic calculator and captures its output:"}, {"id": "b7152225-4049-41ea-b5df-389e8c3fb114", "type": "block_code", "value": ">>> subprocess.run('bc', input='1 + 1\\n', capture_output=True, text=True)\nCompletedProcess(args='bc', returncode=0, stdout='2\\n', stderr='')"}, {"id": "82445ae3-0fa1-41c6-8172-c8ce17856f6e", "type": "heading", "value": "Sends test.in to the basic calculator running in standard mode and saves its output to test.out:"}, {"id": "7f35643e-b5ab-4aa1-ab09-87763c678bc0", "type": "block_code", "value": ">>> from shlex import split\n>>> os.popen('echo 1 + 1 > test.in')\n>>> subprocess.run(split('bc -s'), stdin=open('test.in'), stdout=open('test.out', 'w'))\nCompletedProcess(args=['bc', '-s'], returncode=0)\n>>> open('test.out').read()\n'2\\n'"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "The subprocess module allows advanced execution control over OS commands with robust process management features.", "description": "In Python, executing operating system (OS) commands is a powerful feature that allows developers to interface directly with the underlying OS. This capability is primarily provided through the `subprocess` module introduced in PEP 344. The `subprocess` module supersedes older modules like `os.system` and `commands.getstatusoutput`, offering more robust facilities for spawning new processes, connecting to their input/output/error pipes, and obtaining their return codes.\n\nThe `subprocess.run()` function is a high-level API for running subprocesses. It captures the output by default unless configured otherwise using parameters such as `stdout` and `stderr`. This approach ensures that the command execution does not block program flow unnecessarily and allows developers to handle process outputs more flexibly, including capturing stdout/stderr or passing input to the process.\n\nFor concurrent use cases, Python's `subprocess.Popen()` method provides a way to spawn processes asynchronously. It is useful when fine-grained control over subprocesses is required, such as when managing multiple simultaneous commands or interacting with them in real time through pipes and streams.\n\nOne of the major implications for performance and security in using OS commands from Python is the risk of shell injection attacks if user inputs are not properly sanitized. Therefore, it's recommended to avoid using `shell=True` unless absolutely necessary. Instead, pass command arguments as a list to ensure that they're correctly interpreted by the subprocess API.\n\nCommon advanced use cases include managing system-level tasks like file operations (copying, moving), executing shell scripts, and handling network services. The module is also crucial in automation scripts where batch processing of OS commands can be executed programmatically with conditional logic based on their outputs or exit statuses.\n\nThe `subprocess` module is continuously optimized for better performance across Python versions 3.9+ through enhancements such as improvements in the way it handles text and binary data, which are crucial for handling a wide range of character encodings seamlessly.", "difficulty": "advanced", "common_pitfalls": ["Using shell=True can lead to security vulnerabilities like shell injection if not handled properly.", "Forgetting to handle errors or exceptions raised by subprocess calls, leading to unhandled crashes.", "Blocking program flow due to improper handling of synchronous process execution.", "Inefficient use of I/O operations when capturing large outputs from processes."], "related_concepts": ["subprocess.run", "subprocess.Popen", "concurrency with asyncio.subprocess", "os.system", "shell scripting", "security practices in subprocess management"], "tags": []}, {"id": "094eb50d-8ad4-4048-b9cd-9fef16e8615d", "name": "JSON", "value": [{"id": "582c7f9b-7b94-45a4-9a29-a46728c74247", "type": "paragraph", "value": "<strong>Text file format for storing collections of strings and numbers.</strong>"}, {"id": "13595f6e-6296-40a6-8ac9-c9c03898ce19", "type": "block_code", "value": "import json\n<str>  = json.dumps(<list/dict>)    # Converts collection to JSON string.\n<coll> = json.loads(<str>)          # Converts JSON string to collection."}], "sub_concepts": [{"id": "c2495af6-3168-461b-a635-d91c54a3b589", "name": "Write Collection to JSON File", "value": [{"id": "4989da8c-b4e4-4089-878e-e81d3fb90564", "type": "block_code", "value": "def write_to_json_file(filename, collection):\n    with open(filename, 'w', encoding='utf-8') as file:\n        json.dump(collection, file, ensure_ascii=False, indent=2)"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "The `json` module in Python facilitates encoding and decoding of JSON data, allowing for seamless interchange between Python objects and JSON strings with customizable behaviors.", "description": "In Python, JSON (JavaScript Object Notation) is a lightweight data interchange format that is easy for humans to read and write and easy for machines to parse and generate. The `json` module in Python provides an API for encoding and decoding JSON data. Encoding refers to converting a Python object into a JSON string using the `json.dumps()` or `json.dump()` functions, while decoding involves parsing a JSON string back into a Python object with `json.loads()` or `json.load()`. This functionality is essential for web development, APIs, configuration files, and data storage.\n\nInternally, the `json` module uses the `str` and `unicode` types to represent strings in the JSON format. It supports encoding of basic Python types such as dictionaries, lists, tuples, strings, numbers, Booleans, and None (which corresponds to null in JSON). The encoder handles complex data structures through recursive conversion, ensuring that nested objects are correctly transformed.\n\nAdvanced use cases include customizing serialization with custom encoders by subclassing `json.JSONEncoder` or providing a `default` method. This is useful for handling types not natively supported by the module, such as datetime objects or instances of user-defined classes. Additionally, the decoder can be customized to modify the behavior when converting JSON keys and values back into Python objects.\n\nPerformance implications are noteworthy; while JSON is generally efficient, large data structures can lead to significant memory usage during encoding/decoding processes. Efficient handling can involve streaming large files using `json.load()` with file objects or optimizing custom encoder implementations.\n\nJSON processing in Python adheres to PEP 3333 (Python Web Services) and PEP 462 (JSON Encoder for datetimes), which standardize the JSON module's behavior across various applications. Understanding these PEPs provides insight into the design rationale behind the module's implementation, particularly its focus on compatibility and extensibility.", "difficulty": "intermediate", "common_pitfalls": ["Forgetting to handle complex or custom object types during serialization; using default encoders without considering edge cases.", "Incorrectly managing file I/O operations when working with large JSON files, leading to memory inefficiency.", "Neglecting to set the `ensure_ascii` parameter in `json.dumps()` which can affect character encoding of non-ASCII characters.", "Misunderstanding the difference between `dumps()` (returns a string) and `dump()` (writes to a file-like object).", "Assuming that JSON's representation of floating-point numbers is always precise, leading to potential numerical inaccuracies."], "related_concepts": ["`json` module functions (`loads`, `dumps`, `load`, `dump`)", "Custom serialization with `JSONEncoder`", "Working with file objects in Python for I/O operations", "PEP 3333 and PEP 462 for JSON standardization", "Encoding issues and character handling in strings"], "tags": []}, {"id": "2d2d7c02-7c05-47b2-8b83-61998147afdf", "name": "Pickle", "value": [{"id": "0e099394-c445-4643-8208-862d89ec9e42", "type": "paragraph", "value": "<strong>Binary file format for storing Python objects.</strong>"}, {"id": "2767c7b0-d5a9-418a-bfae-c04142358902", "type": "block_code", "value": "import pickle\n<bytes>  = pickle.dumps(<object>)   # Converts object to bytes object.\n<object> = pickle.loads(<bytes>)    # Converts bytes object to object."}], "sub_concepts": [{"id": "923635e8-b444-4685-8c5d-c015d3703aaf", "name": "Write Object to Pickle File", "value": [{"id": "2d03360d-7835-4754-815c-4eb3ff99a3f3", "type": "block_code", "value": "def write_to_pickle_file(filename, an_object):\n    with open(filename, 'wb') as file:\n        pickle.dump(an_object, file)"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "The `pickle` module serializes and deserializes Python objects to/from byte streams, enabling persistence and transmission across executions.", "description": "The `pickle` module in Python is a powerful tool for serializing and deserializing Python objects. Serialization, often called pickling, involves converting an object into a byte stream that can be stored or transmitted, while deserialization (unpickling) reconstructs the object from this byte stream. This process enables complex data structures to be saved to files, sent over networks, or otherwise persisted across program executions.\n\n`pickle` operates by traversing the object graph of the input Python object and producing a byte representation that encodes both the object's structure and its contents. The module uses the `dumps()` function for serialization into bytes and the `dump()` function to serialize directly to a file-like object. Conversely, `loads()` and `load()` are used for deserialization from bytes and files respectively.\n\nInternally, pickle employs different protocol versions, which define how objects are serialized. Newer protocols (introduced in later Python versions) offer improved performance, larger capacity, and additional features such as out-of-band data handling. For instance, Protocol 4 introduced in Python 3.4 uses binary format for all pickled data, while Protocol 5, available from Python 3.8 onwards, supports large object optimization and provides a more efficient way to handle objects with slots.\n\nOne must be cautious when unpickling data, especially if the byte stream originates from an untrusted source, as it can lead to arbitrary code execution vulnerabilities. This is due to `pickle`'s ability to reconstruct any Python object, including those that execute code on instantiation (e.g., via a lambda function). For safer alternatives in certain contexts, consider modules like `json`, `marshal`, or third-party libraries such as `dill`.\n\nAdvanced use cases of `pickle` include persisting complex configurations for machine learning models, caching data structures for efficient retrieval in high-performance applications, and state management in distributed systems. However, it's crucial to manage the version compatibility of pickled files since changes in object structure or module imports across Python versions can break deserialization.\n\nRelevant PEPs include PEP 3154, which introduced Protocol 3, providing support for out-of-band data, and PEP 554 that proposed the introduction of the new `pickletools` module.", "difficulty": "advanced", "common_pitfalls": ["Using `pickle` with untrusted data sources can lead to security vulnerabilities due to arbitrary code execution during unpickling.", "Pickle files are not cross-version compatible; changes in Python or object structures may cause failures when unpickling.", "Over-reliance on pickling for object persistence without considering schema evolution strategies can lead to maintenance challenges."], "related_concepts": ["Serialization", "Deserialization", "JSON", "Marshal", "Dill", "Object Persistence", "Data Persistence"], "tags": []}, {"id": "b8046242-bed2-4457-af8a-12ac42550cd8", "name": "CSV", "value": [{"id": "99d36538-4030-4821-849b-c267befc9944", "type": "paragraph", "value": "<strong>Text file format for storing spreadsheets.</strong>"}, {"id": "6bfcbf95-2a20-4d9e-877c-05257dac077c", "type": "block_code", "value": "import csv"}], "sub_concepts": [{"id": "60c52b7f-2509-42ba-8699-9193fb7225e9", "name": "Write Rows to CSV File", "value": [{"id": "265d2083-3f56-4820-8153-f754cc96949b", "type": "block_code", "value": "def write_to_csv_file(filename, rows, mode='w', **csv_params):\n    with open(filename, mode, encoding='utf-8', newline='') as file:\n        writer = csv.writer(file, **csv_params)\n        writer.writerows(rows)"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "The `csv` module facilitates efficient reading and writing of CSV files, providing tools for memory-efficient iteration and advanced data mapping with dictionaries.", "description": "The `csv` module in Python provides functionality to read from and write to Comma Separated Values (CSV) files. As an advanced user, understanding the intricacies of this module is essential for handling tabular data efficiently within Python scripts or applications. The module uses classes such as `reader`, `writer`, `DictReader`, and `DictWriter` to abstract file operations into a more manageable API. Underneath, it implements the iterator protocol, enabling users to iterate over rows in a CSV file line by line using a memory-efficient approach. This is particularly useful for processing large datasets that would be impractical to load entirely into memory. \n\nThe `csv.reader` and `csv.writer` classes allow customization of delimiter characters, quote handling, and escape mechanisms via their constructor parameters, offering flexibility in dealing with various CSV dialects. The `DictReader` and `DictWriter` classes provide a more advanced abstraction by mapping the data to dictionaries using headers as keys, facilitating manipulation and access patterns common in database-like environments.\n\nFor performance considerations, it's essential to choose the appropriate delimiter character based on the dataset's nature; for example, semicolons can be used where commas might appear in the data. Moreover, understanding the use of `quoting` options (`csv.QUOTE_ALL`, `csv.QUOTE_MINIMAL`, etc.) helps control how special characters are treated.\n\nAdditionally, PEP 305 introduced more comprehensive handling for dialects and encodings, emphasizing the importance of considering regional differences or specific file format requirements in data exchange scenarios. When dealing with larger files, it's advantageous to pair CSV operations with Python\u2019s `with` statement to ensure files are properly closed after their use, preventing potential resource leaks.\n\nAdvanced use cases include dynamically generating complex datasets for testing purposes, real-time data feed processing, or integrating CSV capabilities into a web application backend. Users should also be aware of the module's limitations in handling non-standard file encodings and consider additional libraries like `openpyxl` or `pandas` for more sophisticated data manipulation needs.", "difficulty": "intermediate", "common_pitfalls": ["Forgetting to specify the correct delimiter when handling non-standard CSV formats.", "Using `csv.reader`/`writer` without properly understanding how quoting is handled, leading to incorrect parsing or writing of special characters.", "Attempting to load large CSV files entirely into memory, which can lead to performance issues and high memory usage.", "Neglecting file encoding specifications, resulting in potential data corruption during read/write operations."], "related_concepts": ["`open` function", "Iterator protocol", "Context managers", "String manipulation", "Data structures (lists, dictionaries)", "`pandas` library"], "tags": []}, {"id": "3953e06d-a45c-4de9-908f-de0b08a6138e", "name": "SQLite", "value": [{"id": "e0fe1f02-951c-4e59-9e96-4877e4e56962", "type": "paragraph", "value": "<strong>A server-less database engine that stores each database into its own file.</strong>"}, {"id": "435825af-2379-4d7a-aacf-60451b136c66", "type": "block_code", "value": "import sqlite3\n<conn> = sqlite3.connect(<path>)               # Opens existing or new file. Also ':memory:'.\n<conn>.close()                                 # Closes connection. Discards uncommitted data."}], "sub_concepts": [{"id": "cf884508-ad33-4a32-8468-79e3756ff90b", "name": "SQLAlchemy", "value": [{"id": "084d918a-3a27-40e2-8670-879c6f838281", "type": "paragraph", "value": "<strong>Library for interacting with various DB systems via SQL, method chaining, or ORM.</strong>"}, {"id": "6e8e4bc8-a013-4966-b9b0-2b8e08bc7e09", "type": "block_code", "value": "# $ pip3 install sqlalchemy\nfrom sqlalchemy import create_engine, text\n<engine> = create_engine('<url>')              # Url: 'dialect://user:password@host/dbname'.\n<conn>   = <engine>.connect()                  # Creates a connection. Also <conn>.close().\n<cursor> = <conn>.execute(text('<query>'), \u2026)  # `<dict>`. Replaces every :<key> with value.\nwith <conn>.begin(): ...                       # Exits the block with commit or rollback."}, {"id": "1778abab-6c20-4638-a2a3-edb34d0de9ee", "type": "block_code", "value": "+-----------------+--------------+----------------------------------+\n| Dialect         | pip3 install |           Dependencies           |\n+-----------------+--------------+----------------------------------+\n| mysql           | mysqlclient  | www.pypi.org/project/mysqlclient |\n| postgresql      | psycopg2     | www.pypi.org/project/psycopg2    |\n| mssql           | pyodbc       | www.pypi.org/project/pyodbc      |\n| oracle+oracledb | oracledb     | www.pypi.org/project/oracledb    |\n+-----------------+--------------+----------------------------------+"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "SQLite is a lightweight disk-based database accessed through Python's sqlite3 module, supporting ACID-compliant transactions with minimal setup.", "description": "SQLite in Python is accessed through the sqlite3 module, which provides a lightweight disk-based database that doesn't require a separate server process. It uses an embedded relational database engine to execute SQL queries and manage data persistence. The sqlite3 module adheres closely to the DB-API 2.0 specification for Python Database API v2.0.\n\nInternally, SQLite operates by loading the entire database into memory as one large object or file on disk, making it highly efficient for read-heavy operations with small datasets but potentially less performant with extremely large datasets due to limited concurrency capabilities (write lock). However, its transactional nature ensures ACID-compliance even in single-user applications.\n\nFor advanced use, the sqlite3 module supports custom collations, custom functions, and a variety of pragmas that can optimize performance. You can create complex transactions using context managers for atomic operations, allowing nested savepoints to manage partial rollbacks. The `PRAGMA` statements enable fine-tuning of SQLite\u2019s behavior at runtime.\n\nThe module also allows asynchronous interaction through the use of threads, but careful management is required as SQLite uses a global connection state within each thread. Advanced users often employ connection pooling or manage connections in separate threads to enhance performance.\n\nSQLite is ideal for prototyping, embedded applications, and scenarios where simplicity and minimal setup are priorities. It's less suitable for high-concurrency environments due to its locking mechanism during write operations. \n\nPython 3.7 introduced the `sqlite3.Connection.row_factory` attribute allowing custom row factories (e.g., dictionaries), which can be crucial for more complex data handling needs in applications.\n\nPEPs relevant here include PEP 249, defining DB-API, and PEP 342, introducing the sqlite3 module.", "difficulty": "Intermediate", "common_pitfalls": ["Forgetting to manage connection lifecycles can lead to resource leaks.", "Misunderstanding the impact of SQLite\u2019s default PRAGMAs and not tuning them for specific use cases.", "Assuming that SQLite can handle high-concurrency write operations as effectively as other RDBMS systems."], "related_concepts": ["Database API (PEP 249)", "Transaction Management", "Thread Safety in Python", "Context Managers", "Custom Row Factories"], "tags": []}, {"id": "dbc05bf8-228f-4081-94e0-9b53e5428471", "name": "Bytes", "value": [{"id": "acf778e2-5216-496b-9f17-24180814370f", "type": "paragraph", "value": "<strong>A bytes object is an immutable sequence of single bytes. Mutable version is called bytearray.</strong>"}, {"id": "cd2b3289-eea0-4e4b-8d27-38069dd3483f", "type": "block_code", "value": "<bytes> = b'<str>'                       # Only accepts ASCII characters and \\x00-\\xff.\n<int>   = <bytes>[index]                 # Returns an integer in range from 0 to 255.\n<bytes> = <bytes>[<slice>]               # Returns bytes even if it has only one element.\n<bytes> = <bytes>.join(<coll_of_bytes>)  # Joins elements by using bytes as a separator."}], "sub_concepts": [{"id": "6bb183b8-12d9-4422-8491-72deb4cf1d63", "name": "Write Bytes to File", "value": [{"id": "80028644-968f-4f98-a867-cb02f264f354", "type": "block_code", "value": "def write_bytes(filename, bytes_obj):\n    with open(filename, 'wb') as file:\n        file.write(bytes_obj)"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "`bytes` is an immutable sequence of integers (0-255) used for handling raw binary data efficiently in Python.", "description": "In Python, `bytes` is a built-in immutable sequence of integers in the range 0 to 255. Introduced as part of Python\u2019s approach to handling binary data, it provides an efficient way to store and manipulate raw byte sequences. This immutability ensures that `bytes` objects are hashable and can be used as keys in dictionaries, unlike mutable `bytearray` objects.\n\nUnder the hood, `bytes` is implemented using a contiguous block of memory, which makes accessing elements quick and predictable with O(1) time complexity for index access. Memory usage efficiency is achieved by storing each byte directly without any additional overhead from object attributes or methods.\n\nFrom an advanced perspective, understanding how `bytes` interacts with file I/O operations, networking, and data serialization/deserialization (e.g., with formats like JSON, XML, or protocol buffers) is crucial. When working with `open()` in binary mode (`'rb'` or `'wb'`), you'll often deal with `bytes`, as the file contents are returned as a sequence of bytes rather than a string.\n\nThe transition between `str` and `bytes` in Python 3 involves explicit encoding and decoding using codecs, which is critical for handling text data that includes non-ASCII characters. PEP 393 introduced flexible integer sizes based on system architecture (32-bit vs 64-bit), impacting how memory is allocated for byte objects.\n\nIn terms of performance implications, `bytes` objects are ideal when you need a fixed sequence of bytes because they avoid the overhead associated with mutable types like `bytearray`. However, if you need to modify the content, converting to and from a `bytearray`, which allows in-place modifications, might introduce some computational overhead due to copying.\n\nAdvanced use cases include handling binary protocols (like HTTP or FTP), image processing where raw pixel data is accessed, cryptography where precise byte-level manipulation is required, and interfacing with C libraries via Python\u2019s ctypes or cffi modules. When dealing with `bytes`, it's essential to handle encoding explicitly using codecs like 'utf-8', 'ascii', etc., when necessary.\n\nPEP 3113 introduced the `bytes` type in Python 2.6 as a distinct immutable type, separate from the `str` type. It was further refined in Python 3, where `str` became a sequence of Unicode characters, and `bytes` took over handling sequences of bytes, which reflects a more clear separation between text and binary data.\n\nOverall, understanding when and how to use `bytes`, alongside related types like `bytearray`, is essential for efficient memory management and performance optimization in Python applications involving binary data.", "difficulty": "intermediate", "common_pitfalls": ["Confusing `bytes` with `str`, leading to encoding/decoding errors when working with text data.", "Forgetting that `bytes` are immutable, resulting in unnecessary conversions to and from `bytearray` for modifications.", "Assuming automatic conversion between strings and bytes without explicit encoding or decoding."], "related_concepts": ["`bytearray`", "`str`", "encoding/decoding with codecs", "file I/O operations (binary mode)", "PEP 393", "data serialization/deserialization"], "tags": []}, {"id": "a35e3b94-85e7-4940-bf48-5a11971cfe35", "name": "Struct", "value": [{"id": "75f6feb9-67fd-4c12-af71-11a17f0d824d", "type": "list", "value": "<li><strong>Module that performs conversions between a sequence of numbers and a bytes object.</strong></li>\n<li><strong>System\u2019s type sizes, byte order, and alignment rules are used by default.</strong></li>"}, {"id": "7aa94fd3-5d70-47d5-af7d-d3dc989e25a6", "type": "block_code", "value": "from struct import pack, unpack\n\n<bytes> = pack('<format>', <el_1> [, ...])  # Packs numbers according to format string.\n<tuple> = unpack('<format>', <bytes>)       # Use iter_unpack() to get iterator of tuples."}, {"id": "097a59f2-d221-45c5-b337-8489e5e8fa90", "type": "block_code", "value": ">>> pack('>hhl', 1, 2, 3)\nb'\\x00\\x01\\x00\\x02\\x00\\x00\\x00\\x03'\n>>> unpack('>hhl', b'\\x00\\x01\\x00\\x02\\x00\\x00\\x00\\x03')\n(1, 2, 3)"}], "sub_concepts": [{"id": "304bd83f-adeb-4061-b528-9e2fd009a287", "name": "Format", "value": [{"id": "943da0d4-585f-48de-b0d0-b4c2fe0a55ba", "type": "heading", "value": "For standard type sizes and manual alignment (padding) start format string with:"}, {"id": "df6ec1f8-2c8e-4ae1-acc2-c853ae0549b2", "type": "list", "value": "<li><strong><code>'='</code> - System's byte order (usually little-endian).</strong></li>\n<li><strong><code>'&lt;'</code> - Little-endian (i.e. least significant byte first).</strong></li>\n<li><strong><code>'&gt;'</code> - Big-endian (also <code>'!'</code>).</strong></li>"}, {"id": "21f39681-adb2-4ab1-8071-02344d4ede03", "type": "heading", "value": "Besides numbers, pack() and unpack() also support bytes objects as a part of the sequence:"}, {"id": "38f7bbf0-2333-44f5-a3c2-ea226736d66a", "type": "list", "value": "<li><strong><code>'c'</code> - A bytes object with a single element. For pad byte use <code>'x'</code>.</strong></li>\n<li><strong><code>'&lt;n&gt;s'</code> - A bytes object with n elements (not effected by byte order).</strong></li>"}, {"id": "2ec51244-7d9d-45f1-86de-6d551a4bbfd5", "type": "heading", "value": "Integer types. Use a capital letter for unsigned type. Minimum and standard sizes are in brackets:"}, {"id": "1ff76622-e65e-4159-ab63-933cac2892fc", "type": "list", "value": "<li><strong><code>'b'</code> - char (1/1)</strong></li>\n<li><strong><code>'h'</code> - short (2/2)</strong></li>\n<li><strong><code>'i'</code> - int (2/4)</strong></li>\n<li><strong><code>'l'</code> - long (4/4)</strong></li>\n<li><strong><code>'q'</code> - long long (8/8)</strong></li>"}, {"id": "25c41e16-1451-466d-b931-6f0c00a53aa6", "type": "heading", "value": "Floating point types (struct always uses standard sizes):"}, {"id": "4d085c49-2366-43fc-834b-4d841104223b", "type": "list", "value": "<li><strong><code>'f'</code> - float (4/4)</strong></li>\n<li><strong><code>'d'</code> - double (8/8)</strong></li>"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "`struct` allows efficient packing and unpacking of primitive data types into bytes objects using format strings.", "description": "The `struct` module in Python provides a way to interpret bytes as packed binary data. It is particularly useful for working with C structs or other binary formats, allowing developers to convert between Python values and C structs represented as Python bytes objects. The `struct` module uses format strings that are similar to those used by the `printf` and `scanf` functions in C.\n\nAt its core, the `struct` module operates through two main methods: `pack()` and `unpack()`. The `pack()` method takes a format string and an arbitrary number of values, then returns a bytes object representing packed binary data. Conversely, `unpack()` takes a format string and a bytes object, returning a tuple with unpacked Python values.\n\nFormat strings in the `struct` module define the layout and types of the binary data. They start with one or more optional endianness characters (`@`, `<`, `>`, `!`, `=`), which specify byte order. This is followed by format characters that dictate how each subsequent value should be interpreted (e.g., 'I' for unsigned int, 'f' for float). For instance, the string `'>2H'` specifies big-endian order and unpacks two unsigned shorts.\n\nPerformance-wise, operations with the `struct` module are efficient due to their low-level nature, though they may not match raw C speed. It's crucial to ensure that data is packed/unpacked in accordance with the correct format string to prevent errors like buffer overflows or incorrect data interpretation.\n\nCommon advanced use cases include serializing and deserializing data for network communication, file I/O operations involving binary files, or interfacing with hardware where low-level byte manipulation is required. The module also supports alignment with padding bytes using `x` in format strings.\n\nWhile there are no specific PEPs directly associated with the `struct` module, its functionality complements Python's capabilities for systems programming and applications requiring precise control over data representation at a binary level.", "difficulty": "intermediate", "common_pitfalls": ["Using incorrect endianness or format characters leading to misinterpretation of data.", "Overlooking the need for padding when strict alignment is required, causing potential data corruption.", "Ignoring size discrepancies between Python's integers and C types (e.g., using 'I' for an integer that exceeds typical 32-bit limits).", "Assuming `struct` handles all aspects of binary file I/O without additional file management."], "related_concepts": ["Bytes and Bytearray objects", "File handling with binary mode (`rb`, `wb`)", "Memoryview for efficient memory access", "Endianess in data serialization", "Pickle module for object serialization"], "tags": []}, {"id": "23df387c-def1-4e2c-a82d-c3640d0d40cb", "name": "Array", "value": [{"id": "75839b2a-d38e-4871-b860-300c4162e143", "type": "paragraph", "value": "<strong>List that can only hold numbers of a predefined type. Available types and their minimum sizes in bytes are listed above. Type sizes and byte order are always determined by the system, however bytes of each element can be reversed with byteswap() method.</strong>"}, {"id": "d17dd869-d025-4c9f-82cd-46a59d08b934", "type": "block_code", "value": "from array import array"}, {"id": "abebb654-adb7-464c-bdc3-be30dec8291a", "type": "block_code", "value": "<array> = array('<typecode>', <coll_of_nums>)  # Creates array from collection of numbers.\n<array> = array('<typecode>', <bytes>)         # Writes passed bytes to array's memory.\n<array> = array('<typecode>', <array>)         # Treats passed array as a sequence of numbers.\n<array>.fromfile(<file>, n_items)              # Appends file's contents to array's memory."}, {"id": "6e469ea7-3b78-4097-a910-ef981af88811", "type": "block_code", "value": "<bytes> = bytes(<array>)                       # Returns a copy of array's memory.\n<file>.write(<array>)                          # Writes array's memory to the binary file."}], "sub_concepts": [], "short_description": "Python arrays provide memory-efficient storage for elements of a single data type, offering performance benefits for operations over lists in certain scenarios.", "description": "In Python, the term 'array' typically refers to a structure from the `array` module that provides space-efficient storage of basic C-style arrays. Unlike lists, which can hold elements of different types, arrays in this context are constrained to elements of a single data type, specified by a type code (such as 'i' for signed integers or 'f' for floating point). This restriction allows arrays to be more memory efficient and faster for certain operations than generic lists. Arrays support basic operations like indexing, slicing, iteration, and appending new items.\n\nArrays in Python are particularly useful when dealing with large datasets where memory efficiency is crucial. They can store data in contiguous blocks of memory, leading to performance benefits due to better cache locality compared to lists. Moreover, the `array` module provides methods for efficient arithmetic operations on arrays, such as element-wise addition and multiplication.\n\nFor advanced users, understanding how Python's array module interacts with NumPy is beneficial. While Python's native arrays are useful for basic tasks, NumPy extends these capabilities significantly by providing multi-dimensional arrays and a wide range of mathematical functions optimized for performance. Unlike the `array` module, NumPy arrays can store elements of different types in a single object using structured data types.\n\nThe array module in Python does not support all operations that lists do, such as comprehensions or arbitrary mutability, which makes it less flexible but more suited to specific high-performance use cases. Additionally, the underlying implementation in C provides an interface closely aligned with C arrays, offering a familiar environment for developers coming from C/C++ backgrounds.\n\nFor those interested in performance optimization and low-level data manipulation, Python's array module remains relevant despite the prevalence of libraries like NumPy. However, when working within scientific computing or data analysis domains, leveraging NumPy is usually preferable due to its extensive functionality and integration with other scientific computing tools. The use of `array` types can also be seen in conjunction with Cython or C extensions for performance-critical applications where Python's dynamic typing becomes a bottleneck.\n\nRelevant PEPs: While there isn't a specific PEP dedicated solely to the array module, PEP 3118 discusses numeric tower, which provides context on why arrays are part of Python\u2019s type system.", "difficulty": "advanced", "common_pitfalls": ["Confusing Python's `array` module with the NumPy library; they serve different purposes and have different capabilities.", "Overlooking the memory efficiency benefit when choosing between arrays and lists, especially for large datasets where uniform data types are sufficient.", "Attempting to use list-like operations such as comprehensions on arrays without realizing that these operations are not supported by the `array` module."], "related_concepts": ["List", "NumPy Array", "Memory Management in Python", "C Extensions for Performance Optimization", "Iterators and Iterables"], "tags": []}, {"id": "82564623-af7d-4508-af1f-d22a6fb66fc1", "name": "Memory View", "value": [{"id": "8af91404-892f-47b3-8850-c3db27f076d8", "type": "paragraph", "value": "<strong>A sequence object that points to the memory of another bytes-like object. Each element can reference a single or multiple consecutive bytes, depending on format. Order and number of elements can be changed with slicing.</strong>"}, {"id": "416d5563-f2bd-4a8b-a4af-11166da8f4cb", "type": "block_code", "value": "<mview> = memoryview(<bytes/bytearray/array>)  # Immutable if bytes is passed, else mutable.\n<obj>   = <mview>[index]                       # Returns int/float. Bytes if format is 'c'.\n<mview> = <mview>[<slice>]                     # Returns memoryview with rearranged elements.\n<mview> = <mview>.cast('<typecode>')           # Only works between B/b/c and other types.\n<mview>.release()                              # Releases memory buffer of the base object."}, {"id": "df4d35b6-dd5f-4580-a246-68fe4eaad46d", "type": "block_code", "value": "<bytes> = bytes(<mview>)                       # Returns a new bytes object. Also bytearray().\n<bytes> = <bytes>.join(<coll_of_mviews>)       # Joins memoryviews using bytes as a separator.\n<array> = array('<typecode>', <mview>)         # Treats memoryview as a sequence of numbers.\n<file>.write(<mview>)                          # Writes `bytes(<mview>)` to the binary file."}, {"id": "ccbd4ea8-376e-4328-8cd0-88b54339867c", "type": "block_code", "value": "<list>  = list(<mview>)                        # Returns a list of ints, floats or bytes.\n<str>   = str(<mview>, 'utf-8')                # Treats memoryview as a bytes object.\n<str>   = <mview>.hex()                        # Returns hex pairs. Accepts `sep=<str>`."}], "sub_concepts": [], "short_description": "`memoryview` provides zero-copy access and manipulation of byte-oriented data in Python through the buffer protocol.", "description": "A `memoryview` object in Python provides direct read and write access to an object\u2019s byte-oriented data without copying it. This capability makes `memoryview` a powerful tool for memory optimization, particularly when handling large datasets or binary files. Introduced in Python 2.7 and refined further in subsequent versions, `memoryview` supports the buffer protocol, which allows different objects to expose their internal data buffers as arrays of bytes.\n\nThe primary advantage of using `memoryview` is its ability to manipulate slices of data without creating a new copy, thus saving both memory and processing time. This efficiency stems from the fact that operations on `memoryview` objects do not involve copying the underlying data; instead, they create views or references to existing segments of data. When you slice a `memoryview`, it returns another `memoryview` object pointing to the same buffer but restricted to the specified range.\n\nUnderlying the functionality of `memoryview` is Python\u2019s buffer protocol, which allows objects like arrays and bytes to share memory efficiently. This interoperability means that `memoryview` can be used with a variety of data types that support this protocol, including bytearrays and array.array instances from the `array` module.\n\nIn advanced use cases, `memoryview` is particularly useful in scenarios requiring high-performance data manipulation, such as image processing or network programming. For example, when working with large numpy arrays, converting them to a memory view allows efficient slicing and dicing without unnecessary copying. Moreover, `memoryview` can facilitate the implementation of zero-copy protocols between processes using shared memory.\n\nThe PEP 3118 introduced the buffer protocol in Python, which underpins the functionality of `memoryview`. By allowing direct access to an object's internal data representation, this protocol enhances the ability to write high-performance and low-level system interfaces in Python. When dealing with binary data from file I/O operations or network sockets, `memoryview` can be instrumental in optimizing read/write efficiency by minimizing buffer copies.\n\nDespite its benefits, `memoryview` requires a solid understanding of both memory management and Python\u2019s object model to avoid pitfalls such as inadvertently modifying data that should remain immutable. Additionally, since the performance gains depend heavily on the underlying data structure's ability to support the buffer protocol efficiently, it is crucial to choose compatible types for optimal results.", "difficulty": "advanced", "common_pitfalls": ["Assuming `memoryview` can be used with any object, not just those supporting the buffer protocol.", "Overlooking that modifying a mutable object via `memoryview` changes the original data.", "Misunderstanding slicing of memoryviews as copying when it merely creates another view on the same data."], "related_concepts": ["Buffer Protocol", "Bytes and Bytearray", "Array Module (array.array)", "Numpy Arrays", "Slicing", "File I/O Operations", "Network Sockets"], "tags": []}, {"id": "48adac4e-33af-405f-b249-b1f0e7641228", "name": "Deque", "value": [{"id": "99d7e6e2-0969-4ffb-bb6c-ad83fad43c53", "type": "paragraph", "value": "<strong>List with efficient appends and pops from either side.</strong>"}, {"id": "45d335eb-7b22-4802-80ec-d492f8e732ef", "type": "block_code", "value": "from collections import deque"}, {"id": "fa91092e-55ae-4e6c-b1aa-f82ffeafdc0e", "type": "block_code", "value": "<deque> = deque(<collection>)                  # Use `maxlen=<int>` to set size limit.\n<deque>.appendleft(<el>)                       # Opposite element is dropped if full.\n<deque>.extendleft(<collection>)               # Passed collection gets reversed.\n<deque>.rotate(n=1)                            # Last element becomes first.\n<el> = <deque>.popleft()                       # Raises IndexError if deque is empty."}], "sub_concepts": [], "short_description": "`collections.deque` provides a thread-safe double-ended queue with efficient append and pop operations on both ends.", "description": "The `collections.deque` (double-ended queue) is a thread-safe implementation of a double-ended queue in Python. It provides an efficient way to append or pop elements from both ends with approximately O(1) time complexity, which makes it suitable for tasks requiring frequent insertions and deletions at either end of a sequence. Internally, `deque` maintains a doubly linked list under the hood, allowing for constant-time complexity operations on both ends. This contrasts with Python's built-in lists, which are optimized for fast access to elements but incur O(n) time complexity when inserting or removing elements from the beginning.\n\nAdvanced use cases of `deque` include implementing breadth-first search algorithms, managing buffers in streaming data applications, and maintaining a sliding window over sequences. The thread-safe nature of `deque` is particularly beneficial in concurrent programming where multiple threads might need to append or pop items concurrently. A noteworthy feature is its ability to specify a maximum length upon initialization (`maxlen`). When the deque exceeds this size, it automatically discards elements from the opposite end.\n\nThe deque's efficiency and thread-safe properties are due to underlying lock mechanisms that ensure safe concurrent access without significant performance degradation compared to single-threaded scenarios. It adheres to the iterator protocol but cannot be sliced like a list, which stems from its non-contiguous memory allocation strategy necessary for maintaining the doubly linked list.\n\nPEP 306 proposed `deque` as part of the Python standard library enhancements for collections, reflecting its utility in handling more complex data structures than those natively supported by basic lists. Its design considers both performance and memory efficiency, making it an indispensable tool in scenarios where high-speed operations at both ends are critical.", "difficulty": "intermediate", "common_pitfalls": ["Assuming `deque` can be sliced like a list, which results in errors as it does not support slicing due to its underlying linked-list structure.", "Overlooking the thread-safety of `deque`, leading to potential race conditions if used improperly in multi-threaded environments without external synchronization mechanisms when needed.", "Not specifying `maxlen` can lead to excessive memory usage if large amounts of data are appended, as there is no automatic truncation of elements.", "Misunderstanding the behavior of thread-safe operations; while `deque` handles concurrent appends and pops safely, it does not handle complex atomic transactions involving other types of manipulations."], "related_concepts": ["`list`: Built-in list type with different performance characteristics for append/pop operations.", "`threading`: Python's threading module which interacts well with thread-safe collections like `deque`.", "`queue.Queue`: Another thread-safe queue implementation in Python, often used in producer-consumer scenarios.", "Linked List: Understanding its principles aids comprehension of the internal workings of deque."], "tags": []}, {"id": "054fe8e0-799d-4817-92fe-bd6ce29a8795", "name": "Operator", "value": [{"id": "da1f664f-75d5-4483-8f14-5af085115fa0", "type": "paragraph", "value": "<strong>Module of functions that provide the functionality of operators. Functions are grouped by operator precedence, from least to most binding. Functions and operators in lines 1, 3 and 5 are also ordered by precedence within a group.</strong>"}, {"id": "4fe26ca9-965e-44d1-ac8b-4f0dbaf215a0", "type": "block_code", "value": "import operator as op"}, {"id": "be7a150d-d682-49c7-a072-5f60cf142c44", "type": "block_code", "value": "<bool> = op.not_(<obj>)                                        # or, and, not (or/and missing)\n<bool> = op.eq/ne/lt/ge/is_/is_not/contains(<obj>, <obj>)      # ==, !=, <, >=, is, is not, in\n<obj>  = op.or_/xor/and_(<int/set>, <int/set>)                 # |, ^, &\n<int>  = op.lshift/rshift(<int>, <int>)                        # <<, >>\n<obj>  = op.add/sub/mul/truediv/floordiv/mod(<obj>, <obj>)     # +, -, *, /, //, %\n<num>  = op.neg/invert(<num>)                                  # -, ~\n<num>  = op.pow(<num>, <num>)                                  # **\n<func> = op.itemgetter/attrgetter/methodcaller(<obj> [, ...])  # [index/key], .name, .name([\u2026])"}, {"id": "64574627-144d-40de-a06d-1961cf03fbe6", "type": "block_code", "value": "elementwise_sum  = map(op.add, list_a, list_b)\nsorted_by_second = sorted(<coll>, key=op.itemgetter(1))\nsorted_by_both   = sorted(<coll>, key=op.itemgetter(1, 0))\nfirst_element    = op.methodcaller('pop', 0)(<list>)"}, {"id": "271487b5-0fc7-4243-9665-96d60ab13980", "type": "list", "value": "<li><strong>Most operators call the object's special method that is named after them (second object is passed as an argument), while logical operators call their own code that relies on bool().</strong></li>\n<li><strong>Comparisons can be chained: <code>'x &lt; y &lt; z'</code> gets converted to <code>'(x &lt; y) and (y &lt; z)</code>'.</strong></li>"}], "sub_concepts": [], "short_description": "Operators in Python are symbols that perform operations on variables; advanced usage involves operator overloading, custom behavior via dunder methods, and optimizing performance.", "description": "In Python, operators are special symbols or functions that perform operations on variables and values. They include arithmetic operators, comparison operators, logical operators, assignment operators, bitwise operators, membership operators, and identity operators. Advanced usage of operators often involves understanding operator overloading via special methods (dunder methods) in classes, which allows customization of the behavior of standard operators when they are used with instances of user-defined classes.\n\nOperator overloading is a key feature for implementing intuitive interactions between objects by defining methods like `__add__`, `__sub__`, `__mul__`, and their reverse counterparts (`__radd__`, etc.), which correspond to the respective arithmetic operations. This can significantly enhance code readability and maintainability in object-oriented programming by allowing custom classes to interact with operators in a way that mirrors built-in types.\n\nAdditionally, understanding how Python implements operator precedence and associativity is crucial for writing complex expressions without unintended results. For example, knowing that multiplication has higher precedence than addition helps prevent logic errors in mathematical computations.\n\nIn the context of performance optimization, it's important to consider that certain operators can be more efficient than their equivalent function calls due to lower-level implementation optimizations. For instance, using `+` for string concatenation inside a loop is less efficient than using `''.join()` because strings are immutable, leading to repeated memory allocations and copies.\n\nAdvanced use cases also include the creation of custom iterators and context managers by defining dunder methods like `__iter__`, `__next__`, `__enter__`, and `__exit__`. These allow developers to define how objects behave with for-loops and in `with` statements, respectively. This is particularly useful when building libraries that require a specific iteration or resource management behavior.\n\nRelevant PEPs include PEP 3134, which introduced the concept of extended slicing, and PEP 484, which formalized type hints, indirectly affecting how operators can be used in conjunction with type-checked code.", "difficulty": "advanced", "common_pitfalls": ["Misunderstanding operator precedence leading to incorrect expression evaluation.", "Overlooking the immutability of strings and lists when using `+` for concatenation or extension in loops.", "Improperly implementing dunder methods for operator overloading, resulting in unexpected behavior.", "Forgetting that operators can be overloaded with custom classes, missing opportunities for intuitive syntax."], "related_concepts": ["Dunder Methods", "Iterator Protocol", "Context Managers", "Type Hints", "Expression Evaluation"], "tags": []}, {"id": "a508e286-74fc-426d-b703-0ba500fb7825", "name": "Match Statement", "value": [{"id": "98db45da-dec7-4021-821e-cbf84e3f9764", "type": "paragraph", "value": "<strong>Executes the first block with matching pattern.</strong>"}, {"id": "5afe2c01-3b4c-435c-b7a8-49f674b7d1f5", "type": "block_code", "value": "match <object/expression>:\n    case <pattern> [if <condition>]:\n        <code>\n    ..."}], "sub_concepts": [{"id": "9a5619c8-543e-4155-94dd-5918846becf6", "name": "Example", "value": [{"id": "7fb5d976-3cd4-4b38-95e0-a2bd31c8b6d5", "type": "block_code", "value": ">>> from pathlib import Path\n>>> match Path('/home/gto/python-cheatsheet/README.md'):\n...     case Path(\n...         parts=['/', 'home', user, *_]\n...     ) as p if p.name.lower().startswith('readme') and p.is_file():\n...         print(f'{p.name} is a readme file that belongs to user {user}.')\nREADME.md is a readme file that belongs to user gto."}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "A structural pattern matching construct introduced in Python 3.10 that allows complex conditional logic based on data structure patterns.", "description": "The `match` statement, introduced in Python 3.10 as part of PEP 634, provides a more powerful alternative to the traditional `if-elif-else` chains for pattern matching. This feature allows developers to match values against patterns and execute code based on these matches. Underlying this construct is the concept of structural pattern matching, which can destructure data structures and bind variables within them.\n\nAt its core, the `match` statement compares an expression with a series of patterns. Each pattern consists of an 'arm', followed by a colon, where the body code associated with that arm gets executed if the pattern matches. It supports exact value matching, variable bindings (including destructuring), and guards\u2014conditional checks applied to patterns for more granular control.\n\nInternally, the `match` statement relies on a visitor pattern for each case of an arm. The patterns are matched against the subject using various strategies: direct comparisons for simple types, structural unpacking for compound data structures (like tuples or lists), and attribute access for object instances. The matching process can involve complex logic, such as recursively checking nested data.\n\nThe implications for performance are nuanced; while the `match` statement provides a clear syntactic advantage, its performance is comparable to that of an optimized series of `if-elif-else` blocks due to Python's dynamic nature and the need for runtime type checking. Nonetheless, it enhances code readability and maintainability, especially when dealing with complex decision trees or state machines.\n\nCommon advanced use cases include parsing nested data structures, implementing state machines in a more declarative style, and simplifying conditional logic that would otherwise involve cumbersome `if-elif` chains. Its ability to handle complex data types makes it particularly useful for tasks involving JSON or XML processing where the structure may be deeply nested.\n\nThe introduction of pattern matching is part of Python's ongoing evolution towards supporting functional programming paradigms, adding expressive power while maintaining readability and ease of use.", "difficulty": "advanced", "common_pitfalls": ["Misunderstanding the precedence between patterns can lead to unexpected matches; remember patterns are checked top-down and match the first compatible one.", "Neglecting to use guards for more intricate conditions, leading to overly complex or insufficiently precise pattern cases.", "Using mutable objects in patterns inadvertently can cause side effects if not handled correctly.", "Expecting `match` statements to have immediate performance benefits over `if-elif-else` chains; they're similar but offer better readability and maintainability."], "related_concepts": ["Conditional Expressions", "Destructuring Assignment (e.g., Tuple Unpacking)", "Guard Clauses", "Visitor Pattern", "Python's Type System"], "tags": []}, {"id": "f74ccb3c-2218-40c3-b3e5-adf31b952411", "name": "Logging", "value": [{"id": "c4548705-8681-4068-9b07-bfab43b27529", "type": "block_code", "value": "import logging as log"}, {"id": "6ac51522-4ba9-4c96-83e2-ecaa44c8910f", "type": "block_code", "value": "log.basicConfig(filename=<path>, level='DEBUG')   # Configures the root logger (see Setup).\nlog.debug/info/warning/error/critical(<str>)      # Sends message to the root logger.\n<Logger> = log.getLogger(__name__)                # Returns logger named after the module.\n<Logger>.<level>(<str>)                           # Sends message to the logger.\n<Logger>.exception(<str>)                         # Error() that appends caught exception."}], "sub_concepts": [{"id": "a5db96cd-1740-443e-bc4c-90b458c7226a", "name": "Setup", "value": [{"id": "f26fa0c9-2228-4a6c-9a32-fd3e1d400e65", "type": "block_code", "value": "log.basicConfig(\n    filename=None,                                # Logs to stderr or appends to file.\n    format='%(levelname)s:%(name)s:%(message)s',  # Add '%(asctime)s' for local datetime.\n    level=log.WARNING,                            # Drops messages with lower priority.\n    handlers=[log.StreamHandler(sys.stderr)]      # Uses FileHandler if filename is set.\n)"}, {"id": "333d7b78-471e-4621-b38a-d9746364655f", "type": "block_code", "value": "<Formatter> = log.Formatter('<format>')           # Creates a Formatter.\n<Handler> = log.FileHandler(<path>, mode='a')     # Creates a Handler. Also `encoding=None`.\n<Handler>.setFormatter(<Formatter>)               # Adds Formatter to the Handler.\n<Handler>.setLevel(<int/str>)                     # Processes all messages by default.\n<Logger>.addHandler(<Handler>)                    # Adds Handler to the Logger.\n<Logger>.setLevel(<int/str>)                      # What is sent to its/ancestors' handlers.\n<Logger>.propagate = <bool>                       # Cuts off ancestors' handlers if False."}, {"id": "04027e35-17eb-44a9-b774-8e7085e3fb89", "type": "list", "value": "<li><strong>Parent logger can be specified by naming the child logger <code>'&lt;parent&gt;.&lt;name&gt;'</code>.</strong></li>\n<li><strong>If logger doesn't have a set level, it inherits it from the first ancestor that does.</strong></li>\n<li><strong>Formatter also accepts: pathname, filename, funcName, lineno, thread and process.</strong></li>\n<li><strong>RotatingFileHandler creates and deletes files based on 'maxBytes', 'backupCount' args.</strong></li>\n<li><strong>An object with <code>'filter(&lt;LogRecord&gt;)'</code> method (or the method itself) can be added to loggers and handlers via addFilter(). Message is dropped if filter() returns a false value.</strong></li>"}, {"id": "0c8a5515-2e14-4841-aa8f-4503b64b124e", "type": "heading", "value": "Creates a logger that writes all messages to a file and sends them to the root's handler that prints warnings or higher:"}, {"id": "28cfaa04-0900-4d88-bbe0-222a6f24d5a6", "type": "block_code", "value": ">>> logger = log.getLogger('my_module')\n>>> handler = log.FileHandler('test.log', encoding='utf-8')\n>>> handler.setFormatter(log.Formatter('%(asctime)s %(levelname)s:%(name)s:%(message)s'))\n>>> logger.addHandler(handler)\n>>> logger.setLevel('DEBUG')\n>>> log.basicConfig()\n>>> log.root.handlers[0].setLevel('WARNING')\n>>> logger.critical('Running out of disk space.')\nCRITICAL:my_module:Running out of disk space.\n>>> print(open('test.log').read())\n2023-02-07 23:21:01,430 CRITICAL:my_module:Running out of disk space."}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "A flexible framework for emitting and managing log records from Python programs, customizable with various handlers, formatters, and filters.", "description": "The `logging` module in Python is a powerful tool for tracking events that occur during program execution. It provides a flexible framework for emitting log messages from Python programs, which can be customized and configured to handle different logging levels such as DEBUG, INFO, WARNING, ERROR, and CRITICAL. Underlying the module is an architecture based on loggers, handlers, filters, and formatters, allowing developers to route log records to various outputs (console, files, network, etc.) and format them in diverse styles.\n\nAt its core, logging operates through a hierarchy of loggers, with each logger having a unique name. The root logger serves as the base for all other loggers. Messages can be directed from child loggers up to their parent until they reach a handler that processes or outputs them. Handlers determine where log records go (e.g., standard output, files), and filters provide additional conditions under which messages are processed.\n\nThe `logging` module supports asynchronous logging through mechanisms like `QueueHandler`, allowing developers to decouple logging activities from the main execution flow for performance gains in high-throughput scenarios. This is particularly useful in applications where logging could otherwise become a bottleneck. The logging system can also be extended with custom handlers, formatters, and filters.\n\nPEP 282 introduced structured logging as an advanced use case, enabling developers to include contextual information such as user IDs or transaction IDs within log records. This feature facilitates easier tracking of logs in distributed systems. The module supports various formats for outputting logs, including plain text, JSON, and custom templates, making it adaptable for diverse logging requirements.\n\nFor performance-sensitive applications, careful configuration of the `logging` module is crucial to avoid unnecessary overhead. Using appropriate log levels helps filter out unneeded messages during production runs, while setting up asynchronous handlers ensures minimal impact on application throughput.", "difficulty": "intermediate", "common_pitfalls": ["Misconfiguring log levels leading to either excessive logging (performance hit) or inadequate logging (lack of useful information).", "Forgetting to configure the root logger or mismanaging logger hierarchies can lead to unexpected behavior in message propagation.", "Not using thread-safe mechanisms like `QueueHandler` in multi-threaded applications, resulting in potential loss of log messages.", "Overlooking the need for custom formatters when integrating with external logging systems that require specific formats."], "related_concepts": ["Logger", "Handler", "Formatter", "Filter", "PEP 282", "QueueHandler", "Structured Logging"], "tags": []}, {"id": "f832b3f4-b60e-4aba-aa5e-d958c352840a", "name": "Introspection", "value": [{"id": "45605b62-d675-4dee-ae74-e574789ebc52", "type": "block_code", "value": "<list> = dir()                      # Local names of variables, functions, classes and modules.\n<dict> = vars()                     # Dict of local names and their objects. Also locals().\n<dict> = globals()                  # Dict of global names and their objects, e.g. __builtin__."}, {"id": "ff1e8193-f161-4fb4-a580-0983b83b1aa3", "type": "block_code", "value": "<list> = dir(<obj>)                 # Returns names of object's attributes (including methods).\n<dict> = vars(<obj>)                # Returns dict of writable attributes. Also <obj>.__dict__.\n<bool> = hasattr(<obj>, '<name>')   # Checks if object possesses attribute with passed name.\nvalue  = getattr(<obj>, '<name>')   # Returns object's attribute or raises AttributeError.\nsetattr(<obj>, '<name>', value)     # Sets attribute. Only works on objects with __dict__ attr.\ndelattr(<obj>, '<name>')            # Deletes attribute from __dict__. Also `del <obj>.<name>`."}, {"id": "19cd2cb0-1520-4516-a3df-55ff60fe0d23", "type": "block_code", "value": "<Sig>  = inspect.signature(<func>)  # Returns a Signature object of the passed function.\n<dict> = <Sig>.parameters           # Returns dict of Parameters. Also <Sig>.return_annotation.\n<memb> = <Param>.kind               # Returns ParameterKind member (Parameter.KEYWORD_ONLY, \u2026).\n<type> = <Param>.annotation         # Returns Parameter.empty if missing. Also <Param>.default."}], "sub_concepts": [], "short_description": "Introspection allows Python programs to examine and modify their own structure and behavior at runtime using built-in functions and attributes.", "description": "Introspection in Python refers to the ability of a program to examine the types or properties of objects at runtime. This capability is deeply embedded in Python, thanks to its dynamic nature and extensive reflection capabilities. At its core, introspection allows developers to write code that can inspect itself and modify behavior accordingly, which is pivotal for advanced programming paradigms like metaprogramming.\n\nPython provides several built-in functions and attributes to facilitate introspection, such as `dir()`, `type()`, `isinstance()`, `getattr()`, `setattr()`, and `hasattr()`. These tools allow users to dynamically retrieve an object's methods, properties, and even its type hierarchy. For instance, `dir()` lists the names in the current local scope or all attributes of an object, while `type()` returns the type of an object.\n\nThe introspection capabilities of Python are rooted in its dynamic typing system and the fact that everything is an object, including classes themselves. This allows for metaclasses, a class of classes, which can be used to customize class creation. The PEP 3115 introduced descriptors as another introspective feature allowing more fine-grained attribute access management.\n\nAdvanced use cases of introspection include building frameworks and libraries that require dynamic adaptation based on user input or configuration files. It is also essential in debugging and logging utilities, which leverage introspection to provide detailed insights into the state of a running program.\n\nFor performance-critical applications, developers must be cautious with introspection since it can introduce overhead if overused. Python's Global Interpreter Lock (GIL) ensures that even concurrent programs maintain thread safety at the cost of some performance in multi-threaded environments. Introspective operations bypass normal execution paths and often involve more CPU cycles.\n\nIntrospection is also closely linked with reflection, where a program not only inspects its components but can also modify them at runtime. The `inspect` module provides functions like `getmembers()`, which returns all members of an object in a list form, and `signature()`, which retrieves the signature of callable objects.\n\nIn summary, introspection is a powerful tool within Python's toolbox that empowers developers to write highly dynamic and adaptable code. It underpins many advanced features in Python and is essential for creating flexible APIs or frameworks.", "difficulty": "advanced", "common_pitfalls": ["Overusing introspective methods can lead to performance bottlenecks due to additional overhead.", "Relying too heavily on introspection can result in less readable and maintainable code if not documented properly.", "Misunderstanding the scope of certain introspective tools, leading to incorrect assumptions about object properties or hierarchy.", "Neglecting thread safety when using introspection in multi-threaded environments."], "related_concepts": ["Reflection", "Metaprogramming", "Descriptors (PEP 3115)", "Dynamic Typing", "Global Interpreter Lock (GIL)"], "tags": []}, {"id": "91913544-a091-4c7a-8ef7-5a809a44584e", "name": "Threading", "value": [{"id": "5a73da72-0388-4bb9-b5e9-2754655b73bc", "type": "paragraph", "value": "<strong>CPython interpreter can only run a single thread at a time. Using multiple threads won't result in a faster execution, unless at least one of the threads contains an I/O operation.</strong>"}, {"id": "d166c52b-9195-4a3b-9874-9c9594c9d0fe", "type": "block_code", "value": "from threading import Thread, Lock, RLock, Semaphore, Event, Barrier\nfrom concurrent.futures import ThreadPoolExecutor, as_completed"}], "sub_concepts": [{"id": "20f85ca5-b1a1-4b92-a0d3-8075247e653c", "name": "Thread Pool Executor", "value": [{"id": "d3ace222-2a2a-47a8-a2be-fdc9c8ef9fff", "type": "block_code", "value": "<Exec> = ThreadPoolExecutor(max_workers=None)  # Or: `with ThreadPoolExecutor() as <name>: ...`\n<iter> = <Exec>.map(<func>, <args_1>, ...)     # Multithreaded and non-lazy map(). Keeps order.\n<Futr> = <Exec>.submit(<func>, <arg_1>, ...)   # Creates a thread and returns its Future obj.\n<Exec>.shutdown()                              # Waits for all submitted threads to finish."}, {"id": "1e99a44c-62f8-468a-9fff-1634a84f2266", "type": "block_code", "value": "<bool> = <Future>.done()                       # Checks if the thread has finished executing.\n<obj>  = <Future>.result(timeout=None)         # Waits for thread to finish and returns result.\n<bool> = <Future>.cancel()                     # Cancels or returns False if running/finished.\n<iter> = as_completed(<coll_of_Futures>)       # `next(<iter>)` returns next completed Future."}, {"id": "ae87a09e-3486-434b-b94c-768093d90b7a", "type": "list", "value": "<li><strong>Map() and as_completed() also accept 'timeout'. It causes futures.TimeoutError when next() is called/blocking. Map() times from original call and as_completed() from first call to next(). As_completed() fails if next() is called too late, even if all threads are done.</strong></li>\n<li><strong>Exceptions that happen inside threads are raised when map iterator's next() or Future's result() are called. Future's exception() method returns exception object or None.</strong></li>\n<li><strong>ProcessPoolExecutor provides true parallelism but: everything sent to/from workers must be <a href=\"#pickle\">pickable</a>, queues must be sent using executor's 'initargs' and 'initializer' parameters, and executor should only be reachable via <code>'if __name__ == &quot;__main__&quot;: ...'</code>.</strong></li>"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "Threading allows concurrent execution of code within the same memory space, useful for I/O-bound tasks despite limitations imposed by the GIL.", "description": "Threading in Python is a way to achieve concurrent execution of code. It involves creating multiple threads (lightweight processes) that share the same memory space, which allows for parallel tasks without the overhead associated with traditional process-based concurrency. Each thread operates independently but shares resources like variables and data structures with other threads in the same program.\n\nInternally, Python's threading model is built on top of native OS threads using a Global Interpreter Lock (GIL). The GIL ensures that only one thread executes Python bytecode at a time per interpreter process, which simplifies memory management but limits true parallel execution for CPU-bound tasks. However, I/O-bound operations benefit significantly from threading as they spend much of their time waiting for external events, allowing other threads to run during these wait periods.\n\nAdvanced use cases include implementing asynchronous tasks like handling multiple client connections in a network server or performing concurrent data fetching and processing in data pipelines. For instance, the `concurrent.futures.ThreadPoolExecutor` provides an easy-to-use interface for asynchronously executing callables using a pool of threads.\n\nWhile threading is useful for I/O-bound operations, it's crucial to handle thread safety and synchronization properly, especially when accessing shared resources. Python provides synchronization primitives such as Locks, Semaphores, Conditions, and Events from the `threading` module, which help manage access to shared data. For example, using a `Lock`, you can ensure that only one thread modifies a shared variable at any given time.\n\nPerformance implications include the need to minimize context switching overhead and efficiently manage CPU-bound tasks by offloading them to separate processes (using multiprocessing) or employing asynchronous programming techniques via libraries like asyncio for better scalability in I/O operations. Understanding these nuances is vital when designing systems that require efficient concurrency management in Python.", "difficulty": "advanced", "common_pitfalls": ["Overlooking the impact of the Global Interpreter Lock (GIL) on CPU-bound tasks, leading to underperformance in multithreaded applications.", "Forgetting to synchronize access to shared resources, resulting in race conditions or data corruption.", "Misusing threading primitives like locks and semaphores, causing deadlocks or excessive blocking.", "Assuming that adding more threads will always lead to better performance due to oversights in task characteristics (CPU-bound vs I/O-bound)."], "related_concepts": ["Multiprocessing", "Asyncio", "Global Interpreter Lock (GIL)", "Concurrency", "Synchronization Primitives", "ThreadPoolExecutor", "Locks and Semaphores", "Event-driven Programming"], "tags": []}, {"id": "811aa70e-caf8-4876-8a3b-f53024d94423", "name": "Coroutines", "value": [{"id": "c43a2737-73b8-4852-8169-e03306ae7a1c", "type": "list", "value": "<li><strong>Coroutines have a lot in common with threads, but unlike threads, they only give up control when they call another coroutine and they don\u2019t use as much memory.</strong></li>\n<li><strong>Coroutine definition starts with <code>'async'</code> and its call with <code>'await'</code>.</strong></li>\n<li><strong>Use <code>'asyncio.run(&lt;coroutine&gt;)'</code> to start the first/main coroutine.</strong></li>"}, {"id": "ec51c50a-a1c6-457d-912a-6dc06303b572", "type": "block_code", "value": "import asyncio as aio"}, {"id": "02cf03ec-6b4e-4295-93bd-7a085be29faa", "type": "block_code", "value": "<coro> = <async_function>(<args>)          # Creates a coroutine by calling async def function.\n<obj>  = await <coroutine>                 # Starts the coroutine and returns its result.\n<task> = aio.create_task(<coroutine>)      # Schedules the coroutine for execution.\n<obj>  = await <task>                      # Returns coroutine's result. Also <task>.cancel()."}, {"id": "6d382695-35f2-4bcb-9c61-95690038c516", "type": "block_code", "value": "<coro> = aio.gather(<coro/task>, ...)      # Schedules coros. Returns list of results on await.\n<coro> = aio.wait(<tasks>, return_when=\u2026)  # `'ALL/FIRST_COMPLETED'`. Returns (done, pending).\n<iter> = aio.as_completed(<coros/tasks>)   # Iter of coros that return next result on await."}, {"id": "62662815-c124-4938-a7c8-32fe4cd1c40a", "type": "heading", "value": "Runs a terminal game where you control an asterisk that must avoid numbers:"}, {"id": "36a82a10-433c-4d83-b652-cfee80ba83dc", "type": "block_code", "value": "import asyncio, collections, curses, curses.textpad, enum, random\n\nP = collections.namedtuple('P', 'x y')     # Position\nD = enum.Enum('D', 'n e s w')              # Direction\nW, H = 15, 7                               # Width, Height\n\ndef main(screen):\n    curses.curs_set(0)                     # Makes cursor invisible.\n    screen.nodelay(True)                   # Makes getch() non-blocking.\n    asyncio.run(main_coroutine(screen))    # Starts running asyncio code.\n\nasync def main_coroutine(screen):\n    moves = asyncio.Queue()\n    state = {'*': P(0, 0)} | {id_: P(W//2, H//2) for id_ in range(10)}\n    ai    = [random_controller(id_, moves) for id_ in range(10)]\n    mvc   = [human_controller(screen, moves), model(moves, state), view(state, screen)]\n    tasks = [asyncio.create_task(coro) for coro in ai + mvc]\n    await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n\nasync def random_controller(id_, moves):\n    while True:\n        d = random.choice(list(D))\n        moves.put_nowait((id_, d))\n        await asyncio.sleep(random.triangular(0.01, 0.65))\n\nasync def human_controller(screen, moves):\n    while True:\n        key_mappings = {258: D.s, 259: D.n, 260: D.w, 261: D.e}\n        if d := key_mappings.get(screen.getch()):\n            moves.put_nowait(('*', d))\n        await asyncio.sleep(0.005)\n\nasync def model(moves, state):\n    while state['*'] not in (state[id_] for id_ in range(10)):\n        id_, d = await moves.get()\n        deltas = {D.n: P(0, -1), D.e: P(1, 0), D.s: P(0, 1), D.w: P(-1, 0)}\n        state[id_] = P((state[id_].x + deltas[d].x) % W, (state[id_].y + deltas[d].y) % H)\n\nasync def view(state, screen):\n    offset = P(curses.COLS//2 - W//2, curses.LINES//2 - H//2)\n    while True:\n        screen.erase()\n        curses.textpad.rectangle(screen, offset.y-1, offset.x-1, offset.y+H, offset.x+W)\n        for id_, p in state.items():\n            screen.addstr(offset.y + (p.y - state['*'].y + H//2) % H,\n                          offset.x + (p.x - state['*'].x + W//2) % W, str(id_))\n        screen.refresh()\n        await asyncio.sleep(0.005)\n\nif __name__ == '__main__':\n    curses.wrapper(main)"}, {"id": "f7ea95e0-57cf-4ba6-8107-a5d6c2956de5", "type": "block_html", "value": "<br>"}, {"id": "7a4f228c-b3d2-402f-84fe-48056be01e8b", "type": "heading", "value": "Libraries"}], "sub_concepts": [], "short_description": "Coroutines are functions that facilitate asynchronous programming by allowing suspension and resumption of execution, enabling efficient I/O-bound task management within a single thread using the `async def` and `await` syntax.", "description": "Coroutines in Python are a type of function that allow suspension and resumption of their execution at certain points. Introduced as part of Python\u2019s asynchronous programming paradigm, coroutines provide a way to perform cooperative multitasking within a single thread by allowing tasks to yield control back to the event loop while waiting for external operations or data. The core mechanism behind coroutines is based on the `yield` keyword, but they are extended with additional capabilities using the `async def` syntax introduced in PEP 492 and further enhanced in later versions. An asynchronous function defined with `async def` returns a coroutine object which can be awaited using the `await` keyword.\n\nCoroutines are central to async/await syntax, enabling developers to write non-blocking code that mimics synchronous programming models while being highly efficient for I/O-bound tasks. When an `await` expression is encountered in an asynchronous function, control is passed back to the event loop, which manages other coroutines until the awaited operation completes. Upon completion, the coroutine resumes execution right after where it was suspended.\n\nCoroutines support advanced features like delegation with `yield from`, allowing one coroutine to delegate part of its operations to another using `await`. This not only simplifies writing nested asynchronous calls but also enhances readability and maintainability of async codebases. Performance-wise, coroutines are lightweight compared to threads as they don't involve context switching or kernel-level scheduling. The event loop manages the state transitions and execution of coroutines efficiently.\n\nCommon advanced use cases include implementing non-blocking network servers, client applications that handle numerous simultaneous I/O-bound tasks (e.g., web scraping), and integrating with frameworks like `asyncio`, which provides tools for working with asynchronous code including running an event loop, managing lifecycle, and creating asynchronous versions of standard library functions.\n\nWhile the coroutine model has transformed how Python handles concurrency, it can introduce complexity especially when combined with synchronous code. It's crucial to understand execution contexts and ensure proper exception handling as exceptions in awaited coroutines do not propagate automatically.\n\nRelevant PEPs include PEP 492 for introducing `async` and `await`, and other enhancements like async generators and context managers.", "difficulty": "advanced", "common_pitfalls": ["Mixing synchronous and asynchronous code without proper context switching can lead to deadlocks or unexpected behavior.", "Forgetting to await coroutine functions, causing them not to execute properly.", "Mismanaging exception handling in async code since exceptions do not propagate automatically from awaited coroutines.", "Overusing `await` on non-I/O-bound operations which can negate the performance benefits by making the code unnecessarily asynchronous."], "related_concepts": ["Asyncio", "Event loop", "Futures and tasks", "Async generators", "Await expression", "Concurrent.futures module"], "tags": []}, {"id": "dbda7876-7ce7-4ec3-8c1f-3d146c202796", "name": "Progress Bar", "value": [{"id": "0a543851-57e5-49b5-87c1-c900a559168e", "type": "block_code", "value": "# $ pip3 install tqdm\n>>> import tqdm, time\n>>> for el in tqdm.tqdm([1, 2, 3], desc='Processing'):\n...     time.sleep(1)\nProcessing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:03<00:00,  1.00s/it]"}], "sub_concepts": [], "short_description": "A visual feedback mechanism in Python applications, typically implemented using libraries like `tqdm`, that provides real-time updates on task completion status.", "description": "A progress bar in Python is a visual representation of the completion status of a task or loop. It provides users with feedback on how much work has been completed relative to what remains, often enhancing user experience by making waiting periods more informative and less tedious. While not part of Python's core libraries, progress bars are implemented using third-party packages like `tqdm`, `progressbar2`, or through custom implementations in GUI frameworks such as Tkinter or PyQt.\n\nThe `tqdm` library is one of the most popular choices for creating console-based progress bars due to its simplicity and flexibility. Underneath, `tqdm` utilizes Python's context management and iterator protocol to wrap around any iterable object (like lists, generators) or loops, providing real-time updates as each item is processed. When used with a loop, it counts iterations and calculates an estimated time of arrival (ETA) using the elapsed time and progress rate. This involves leveraging Python's `time` module for performance timing and handling the stdout stream to dynamically update the terminal display.\n\nIn terms of internal workings, `tqdm` takes advantage of Python\u2019s rich set of built-in features such as decorators and context managers. The library can be wrapped around iterables using a context manager or applied directly over loops with minimal syntax changes. For instance:\n\n```python\nfrom tqdm import tqdm\nimport time\nfor i in tqdm(range(1000), desc='Processing'): \n    # Simulate work\n    time.sleep(0.01)\n```\nThis code snippet will display a progress bar in the console, updating every 0.01 seconds with each loop iteration.\n\n`tqdm` is also designed to handle multiprocessing environments using its `multiprocessing_lock` feature and can integrate with Jupyter notebooks for inline updates via its `tqdm.notebook` module.\n\nFrom a performance standpoint, progress bars can introduce minimal overhead, but this is usually negligible compared to the benefits of user feedback. However, when used in tight loops or critical paths, developers should be mindful of potential impacts on timing precision due to frequent I/O operations involved in updating console output.\n\nWhen creating custom progress bars using GUI libraries, Python's signal handling and event-driven programming come into play. For example, using Tkinter, one might create a window with a label that updates its text or graphical elements based on the task\u2019s progress state, leveraging threading to prevent UI blocking during long operations.\n\nFor advanced users, integrating progress bars in asynchronous code involves careful design around Python's `asyncio` event loop and coroutine management. By ensuring that the progress bar updates are non-blocking, one can maintain application responsiveness.\n\nRelevant PEPs related to this concept include those addressing Python\u2019s I/O handling (PEP 3101) and async features (PEP 492), which provide the foundational capabilities needed for developing robust and performant progress visualization tools.", "difficulty": "intermediate", "common_pitfalls": ["Overhead from frequent I/O operations if used excessively within performance-critical loops.", "Incorrectly estimating total iterations or not properly handling dynamic iterables, leading to inaccurate progress reporting.", "Ignoring the impact of multiprocessing on progress tracking without using appropriate synchronization mechanisms provided by libraries like `tqdm`."], "related_concepts": ["Iterator Protocol", "Context Managers", "Multiprocessing and Threading in Python", "Asynchronous Programming with asyncio", "GUI Frameworks (Tkinter, PyQt)"], "tags": []}, {"id": "b479ccb8-bdae-4168-a00c-b8493a1878ff", "name": "Plot", "value": [{"id": "07a3fc91-49c4-4655-adfd-6806450dc43c", "type": "block_code", "value": "# $ pip3 install matplotlib\nimport matplotlib.pyplot as plt\n\nplt.plot/bar/scatter(x_data, y_data [, label=<str>])  # Also plt.plot(y_data).\nplt.legend()                                          # Adds a legend.\nplt.title/xlabel/ylabel(<str>)                        # Adds a title or label.\nplt.show()                                            # Also plt.savefig(<path>).\nplt.clf()                                             # Clears the plot."}], "sub_concepts": [], "short_description": "`plot` is a versatile function used to create line graphs in Python libraries like Matplotlib, offering extensive customization options for data visualization.", "description": "The `plot` function in Python is primarily associated with libraries like Matplotlib, Pandas, or Seaborn, which are used for creating visualizations. In the context of Matplotlib, the `plot` function is a fundamental method for generating line plots by connecting data points. It's versatile and can handle various types of input formats such as arrays, lists, tuples, or DataFrame objects from Pandas. The function signature typically includes parameters for x and y coordinates, which determine the plot's axes values, and optional arguments to customize the appearance like `color`, `linewidth`, `linestyle`, etc.\n\nMatplotlib's `plot` method operates using an object-oriented approach where it leverages Matplotlib's state machine environment. This design allows users to create multiple figures and axes objects, each with its configuration settings, enhancing modularity and reusability of the code. The internal workings involve creating a line artist object that can be further manipulated or customized.\n\nFor performance implications, when dealing with large datasets, Matplotlib's `plot` function might not be the most efficient choice due to its rendering nature which could lead to high memory usage and slower execution times compared to vectorized operations in libraries like NumPy or data visualization methods using GPU acceleration found in libraries such as Plotly.\n\nAdvanced use cases of the `plot` method include creating multi-line plots, adding multiple plot elements (like markers, annotations), adjusting subplot arrangements within a figure canvas, and integrating with interactive backends. Matplotlib allows for customization at nearly every level from low-level control over line styles to high-level functionalities like adding legends, labels, and titles.\n\nRelevant PEPs concerning data visualization in Python include PEP 561 which introduces namespace packages, indirectly benefiting package management for visualization libraries.\n\nThe `plot` function's adaptability is further enhanced when combined with other advanced features such as animations (via Matplotlib\u2019s animation module) or interactivity using widgets (with the help of mpld3 or interactive backends like Plotly). Furthermore, it can be integrated into larger data processing pipelines that include data cleaning and analysis phases typically handled by Pandas.\n\nIn summary, while `plot` is a basic function for generating visualizations, its depth lies in customization, performance considerations, and integration with more complex plotting functionalities offered by Matplotlib's ecosystem.", "difficulty": "intermediate", "common_pitfalls": ["Overlooking the necessity of using subplots for complex multi-chart arrangements leading to improper axis configurations.", "Neglecting performance considerations when dealing with large datasets, resulting in slow render times or excessive memory use.", "Ignoring the potential conflicts between interactive backends and non-interactive backends leading to unexpected behavior during visualization.", "Not fully utilizing available customization parameters which can limit the expressiveness of the visualizations produced."], "related_concepts": ["Matplotlib", "Pandas plotting", "Seaborn", "Subplots", "DataFrames", "Line objects", "Interactive backends"], "tags": []}, {"id": "3a179c93-e5bb-46d9-8adb-c3ba9ef5af59", "name": "Table", "value": [{"id": "06a49bcb-11ce-48f3-960e-0dc7359249e7", "type": "heading", "value": "Prints a CSV spreadsheet to the console:"}, {"id": "44931170-1fd2-43a6-9605-12f672e60ff9", "type": "block_code", "value": "# $ pip3 install tabulate\nimport csv, tabulate\nwith open('test.csv', encoding='utf-8', newline='') as file:\n    rows = list(csv.reader(file))\nprint(tabulate.tabulate(rows, headers='firstrow'))"}], "sub_concepts": [], "short_description": "`tabulate` is a Python library that converts 2D lists or arrays into formatted tables with support for various output styles.", "description": "In Python, tables are typically represented using data structures such as lists of dictionaries or specialized libraries like `pandas` for more advanced operations. However, when discussing 'table' in a broader sense within Python programming, we often refer to the tabulate library, which provides an interface for pretty-printing tabular data in various formats.\n\nThe `tabulate` module allows users to easily convert 2D lists or arrays into nicely formatted tables, supporting multiple output formats such as plain text, HTML, LaTeX, and more. The core functionality relies on Python's ability to handle nested lists (representing rows and columns) and dictionaries (for labeled data), making it highly flexible for a variety of use cases.\n\nInternally, `tabulate` operates by taking input data and calculating the necessary column widths based on content or specified parameters. It can align text within columns, add headers, and apply different styles to enhance readability. The library uses Python's string manipulation capabilities extensively to format output correctly according to the chosen table style.\n\nAdvanced use cases involve integrating `tabulate` with other data processing libraries such as `pandas`, where DataFrame objects can be directly converted into tabular strings for reporting or exporting purposes. This is particularly useful in data analysis and scientific computing, where clear presentation of results is crucial.\n\nFor performance considerations, while `tabulate` is efficient for small to medium-sized datasets, handling very large tables might require optimization strategies such as chunking the output or using more performant libraries like `pandas`. Additionally, understanding how `tabulate` interacts with Python's memory management and string operations can help in optimizing its use in resource-constrained environments.\n\nCommonly associated PEPs include those related to Unicode handling and string formatting (e.g., PEP 263 for encoding declarations), as these impact how text is rendered across different output formats. While `tabulate` itself does not directly introduce new language features, it leverages existing Python capabilities to deliver a powerful tool for table representation.\n\nOverall, the `tabulate` library exemplifies advanced usage of Python's data handling and string manipulation features to provide a robust solution for tabular data presentation.", "difficulty": "intermediate", "common_pitfalls": ["Misunderstanding the input format required by `tabulate`, leading to incorrect table rendering.", "Overlooking the impact of Unicode characters on table formatting, especially in non-ASCII environments.", "Failing to handle very large datasets efficiently within `tabulate` due to its design primarily for smaller data sets."], "related_concepts": ["`pandas.DataFrame`: A powerful library for data manipulation and analysis which integrates well with `tabulate` for displaying tabular data.", "String formatting in Python: Essential for understanding how text alignment and styling work within tables.", "Memory management in Python: Important when dealing with large datasets to avoid performance bottlenecks."], "tags": []}, {"id": "da0d72f5-ae42-4e6e-a7b9-a350a28378fe", "name": "Console App", "value": [{"id": "8336dcb6-3341-4653-b3a6-39d6d2aa4a82", "type": "heading", "value": "Runs a basic file explorer in the console:"}, {"id": "c05e078e-3f3b-4d1c-a26f-93e60521eacb", "type": "block_code", "value": "# $ pip3 install windows-curses\nimport curses, os\nfrom curses import A_REVERSE, KEY_UP, KEY_DOWN, KEY_LEFT, KEY_RIGHT\n\ndef main(screen):\n    ch, first, selected, paths = 0, 0, 0, os.listdir()\n    while ch != ord('q'):\n        height, width = screen.getmaxyx()\n        screen.erase()\n        for y, filename in enumerate(paths[first : first+height]):\n            color = A_REVERSE if filename == paths[selected] else 0\n            screen.addnstr(y, 0, filename, width-1, color)\n        ch = screen.getch()\n        selected -= (ch == KEY_UP) and (selected > 0)\n        selected += (ch == KEY_DOWN) and (selected < len(paths)-1)\n        first -= (first > selected)\n        first += (first < selected-(height-1))\n        if ch in [KEY_LEFT, KEY_RIGHT, ord('\\n')]:\n            new_dir = '..' if ch == KEY_LEFT else paths[selected]\n            if os.path.isdir(new_dir):\n                os.chdir(new_dir)\n                first, selected, paths = 0, 0, os.listdir()\n\nif __name__ == '__main__':\n    curses.wrapper(main)"}], "sub_concepts": [], "short_description": "A script running in the CLI without a GUI, utilizing input/output streams and supporting libraries like argparse for argument parsing.", "description": "A console application in Python is a script that runs from the command line interface (CLI) without any graphical user interface (GUI). This paradigm leverages Python\u2019s ability to interact with the operating system's shell, enabling developers to build tools and scripts for automation, data processing, or system management tasks. Console applications are inherently text-based, relying on input and output through standard streams (`stdin`, `stdout`, and `stderr`), making them lightweight and highly efficient for specific use cases.\n\nAdvanced console applications in Python often utilize modules like `argparse` to handle command-line arguments, providing a robust mechanism for parsing options and flags. This module supports complex argument types, defaults, help messages, and custom validation, which are essential for building sophisticated command-line tools. Another popular choice is the `click` library, known for its simplicity and ease of use in creating user-friendly CLI applications.\n\nPerformance implications of console apps arise from their direct interaction with system resources via the shell. They can execute system commands using modules like `subprocess`, which provides powerful capabilities to spawn new processes, connect to their input/output/error pipes, and obtain their return codes. This is critical for tasks that require integration with other software or system utilities.\n\nFrom a concurrency perspective, console applications can leverage Python's `asyncio` library to handle asynchronous operations. This allows the script to perform I/O-bound tasks concurrently without blocking execution, improving responsiveness and throughput in scenarios involving network requests or file I/O.\n\nPython\u2019s rich standard library also facilitates logging and debugging via modules like `logging`, which is instrumental for monitoring application behavior in production environments. Furthermore, console applications can integrate with version control systems (e.g., Git) through subprocess calls to automate tasks like code reviews, continuous integration pipelines, or deployment scripts.\n\nOverall, console applications exemplify Python\u2019s philosophy of simplicity and readability while providing a powerful platform for building cross-platform command-line tools that interact seamlessly with the system environment.", "difficulty": "intermediate", "common_pitfalls": ["Incorrectly handling command-line arguments leading to errors or unexpected behavior.", "Failing to validate user inputs thoroughly can lead to security vulnerabilities.", "Overlooking proper error handling, which can result in poor user experience and debugging challenges.", "Ignoring cross-platform compatibility issues, especially with file paths and system commands.", "Misusing subprocesses that may cause deadlocks or resource leaks if not managed correctly."], "related_concepts": ["argparse", "subprocess", "logging", "asyncio", "click", "stdin/stdout/stderr", "shell scripting"], "tags": []}, {"id": "ea68fc28-e4ba-4d47-a044-bed89a0182ac", "name": "GUI App", "value": [{"id": "f092210a-ec1f-4afe-83e3-bd68b2c181df", "type": "heading", "value": "A weight converter GUI application:"}, {"id": "ad2480eb-aa91-4774-9bc4-b9c395481a50", "type": "block_code", "value": "# $ pip3 install PySimpleGUI\nimport PySimpleGUI as sg\n\ntext_box = sg.Input(default_text='100', enable_events=True, key='QUANTITY')\ndropdown = sg.InputCombo(['g', 'kg', 't'], 'kg', readonly=True, enable_events=True, k='UNIT')\nlabel    = sg.Text('100 kg is 220.462 lbs.', key='OUTPUT')\nbutton   = sg.Button('Close')\nwindow   = sg.Window('Weight Converter', [[text_box, dropdown], [label], [button]])\n\nwhile True:\n    event, values = window.read()\n    if event in [sg.WIN_CLOSED, 'Close']:\n        break\n    try:\n        quantity = float(values['QUANTITY'])\n    except ValueError:\n        continue\n    unit = values['UNIT']\n    factors = {'g': 0.001, 'kg': 1, 't': 1000}\n    lbs = quantity * factors[unit] / 0.45359237\n    window['OUTPUT'].update(value=f'{quantity} {unit} is {lbs:g} lbs.')\nwindow.close()"}], "sub_concepts": [], "short_description": "PyQt allows the creation of sophisticated GUI applications by leveraging the Qt framework, offering advanced features like signals/slots for event-driven programming and support for custom widgets.", "description": "Creating graphical user interfaces (GUI) in Python can be accomplished through various libraries, such as Tkinter, PyQt, Kivy, and others. Among these, PyQt stands out for its robust feature set, leveraging the power of the Qt framework to create sophisticated applications with complex UIs. PyQt is particularly suitable for advanced users due to its extensive functionality, including support for custom widgets, drag-and-drop features, graphics views, and model-view programming.\n\nPyQt integrates with Python's object-oriented nature through signals and slots mechanism, enabling event-driven programming. Signals are emitted by objects when they change state or need attention, while slots are functions that respond to these signals. This decouples the logic from UI components, enhancing maintainability and scalability of applications. PyQt also supports internationalization, accessibility features, and database integration via Qt's SQL module.\n\nPerformance-wise, PyQt benefits from its C++ backend, offering efficient rendering and event handling. Advanced users can optimize GUI performance by employing QThreads for concurrency, ensuring the main thread remains responsive. PyQt5 introduces new features like the QML support, providing a modern way to design UIs declaratively.\n\nCommon advanced use cases include developing cross-platform desktop applications that require rich multimedia content or complex data visualization. Relevant PEPs focus on Python's GUI development paradigms and interoperability with C/C++ libraries for performance-critical applications (e.g., PEP 463 discusses embedding the Qt framework).\n\nUnderstanding PyQt requires familiarity with its event loop, resource management using QObjects, and leveraging the Model-View-Controller (MVC) or Model-View-ViewModel (MVVM) patterns to separate application logic from UI code. This separation is crucial for developing scalable applications.\n\nInternally, PyQt provides a binding layer that translates Python calls into Qt's C++ API, allowing seamless integration of Python with Qt features. For instance, creating custom widgets involves subclassing QWidget and overriding event handlers to manage user interactions effectively.", "difficulty": "advanced", "common_pitfalls": ["Overloading slots with too many responsibilities can lead to tightly coupled code that's difficult to maintain.", "Failing to properly manage QObject memory using parent-child relationships, leading to memory leaks.", "Not understanding the event loop's role in PyQt can cause performance bottlenecks and unresponsive UIs.", "Inadequate separation of application logic from UI components by not adhering to MVC or MVVM patterns.", "Ignoring thread safety when updating GUI elements from QThreads."], "related_concepts": ["Qt Framework", "Signals and Slots", "QObjects and Resource Management", "Event Loop in PyQt", "Model-View-Controller (MVC)", "Multithreading with QThread", "Custom Widgets Development"], "tags": []}, {"id": "358fca14-c997-42e8-ad10-6c9f8459e58d", "name": "Scraping", "value": [{"id": "74cc749b-64b1-4e99-ac65-a38c15a13731", "type": "heading", "value": "Scrapes Python's URL and logo from its Wikipedia page:"}, {"id": "760e254a-506d-4f14-9f28-a76ec6b8e6e2", "type": "block_code", "value": "# $ pip3 install requests beautifulsoup4\nimport requests, bs4, os\n\nresponse   = requests.get('https://en.wikipedia.org/wiki/Python_(programming_language)')\ndocument   = bs4.BeautifulSoup(response.text, 'html.parser')\ntable      = document.find('table', class_='infobox vevent')\npython_url = table.find('th', text='Website').next_sibling.a['href']\nlogo_url   = table.find('img')['src']\nfilename   = os.path.basename(logo_url)\nwith open(filename, 'wb') as file:\n    file.write(requests.get(f'https:{logo_url}').content)\nprint(f'{python_url}, file://{os.path.abspath(filename)}')"}], "sub_concepts": [{"id": "f12ea09c-d564-4e19-89c5-a18a6bc9b639", "name": "Selenium", "value": [{"id": "1d25df11-cc3a-4221-a963-26267c30ce07", "type": "paragraph", "value": "<strong>Library for scraping websites with dynamic content.</strong>"}, {"id": "7d9d7a20-4191-40aa-940e-ea3b3605db82", "type": "block_code", "value": "# $ pip3 install selenium\nfrom selenium import webdriver\n\n<WebDrv> = webdriver.Chrome/Firefox/Safari/Edge()     # Opens a browser. Also <WebDrv>.quit().\n<WebDrv>.get('<url>')                                 # Also <WebDrv>.implicitly_wait(seconds).\n<str>  = <WebDrv>.page_source                         # Returns HTML of fully rendered page.\n<El>   = <WebDrv/El>.find_element('css selector', \u2026)  # '<tag>#<id>.<class>[<attr>=\"<val>\"]\u2026'.\n<list> = <WebDrv/El>.find_elements('xpath', \u2026)        # '//<tag>[@<attr>=\"<val>\"]\u2026'. See XPath.\n<str>  = <El>.get_attribute(<str>)                    # Property if exists. Also <El>.text.\n<El>.click/clear()                                    # Also <El>.send_keys(<str>)."}, {"id": "ccfcb6c6-cb00-4b0c-83b0-9f53d5b9619b", "type": "heading", "value": "XPath \u2014 also available in lxml, Scrapy, and browser's console via <code>'$x(&quot;&lt;xpath&gt;&quot;)'</code>:"}, {"id": "8e4d24d8-00e1-43dc-a769-6652e5a1ecb1", "type": "block_code", "value": "<xpath>     = //<element>[/ or // <element>]          # /<child>, //<descendant>, /../<sibling>\n<xpath>     = //<element>/following::<element>        # Next element. Also preceding/parent/\u2026\n<element>   = <tag><conditions><index>                # `<tag> = */a/\u2026`, `<index> = [1/2/\u2026]`.\n<condition> = [<sub_cond> [and/or <sub_cond>]]        # For negation use `not(<sub_cond>)`.\n<sub_cond>  = @<attr>[=\"<val>\"]                       # `text()=`, `.=` match (complete) text.\n<sub_cond>  = contains(@<attr>, \"<val>\")              # Is <val> a substring of attr's value?\n<sub_cond>  = [//]<element>                           # Has matching child? Descendant if //."}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "Advanced web scraping in Python utilizes libraries like `requests`, `BeautifulSoup`, `Selenium` for static/dynamic content extraction, emphasizing performance with async capabilities and ethical compliance.", "description": "Web scraping in Python involves extracting data from websites programmatically. Advanced web scraping leverages Python libraries like `requests`, `BeautifulSoup`, `lxml`, and more recently, `Scrapy` and `Selenium`. The process typically involves fetching a webpage using HTTP requests (`requests` library), parsing the HTML content to locate specific elements or data patterns (using `BeautifulSoup` for its ease of use with Python's native string handling capabilities and `lxml` for its speed and efficiency), and then manipulating or storing that data. For dynamic web pages, which rely on JavaScript for rendering content, tools like `Selenium` can automate a browser to interact with the page as needed, executing scripts and simulating user actions.\n\nAdvanced use cases of web scraping include automated testing of web applications by checking if specific elements are present or correct values are displayed. Another is real-time data extraction from e-commerce sites for price comparison tools, where efficiency and speed of execution matter greatly due to the competitive nature of such applications. The introduction of asynchronous capabilities in Python 3.9+ with libraries like `httpx` for making HTTP requests and `trio-asyncio` or `asyncio` for managing async tasks further pushes the performance boundaries, allowing handling multiple scraping jobs concurrently.\n\nWeb scraping also intersects with ethical considerations; it's crucial to respect a website's `robots.txt` file, which specifies what paths are allowed to be accessed by bots. Ignoring these can lead to legal implications and IP bans. Furthermore, Python's standard library includes modules like `urllib.robotparser`, aiding in parsing and adhering to these rules programmatically.\n\nThe evolution of web scraping tools reflects a broader shift towards handling more complex data extraction scenarios, including those involving APIs returning JSON or XML instead of HTML. Libraries such as `aiohttp` enable asynchronous API calls, thus enhancing the capability to efficiently process vast amounts of data from RESTful services in real-time applications.\n\nPython Enhancement Proposals (PEPs) relevant to web scraping include PEP 498 for introducing `async/await`, which forms the backbone of writing asynchronous code that's crucial for non-blocking I/O operations in network programming and web scraping tasks. The advancement in handling concurrency with Python\u2019s asyncio library and its integration into web scraping frameworks significantly optimizes performance by allowing simultaneous HTTP requests, a common requirement in large-scale data extraction tasks.\n\nOverall, the advanced aspect of web scraping in Python not only involves leveraging sophisticated libraries and tools but also understanding and implementing asynchronous programming models to maximize efficiency and respect website usage policies.", "difficulty": "advanced", "common_pitfalls": ["Not handling exceptions properly, especially HTTP errors or parsing issues can lead to incomplete data collection.", "Overlooking the impact of dynamic JavaScript-rendered content on scraping strategies.", "Ignoring `robots.txt` guidelines, leading to potential legal and access issues.", "Underestimating the complexity and necessity of asynchronous programming in large-scale scraping tasks."], "related_concepts": ["requests", "BeautifulSoup", "lxml", "Scrapy", "Selenium", "asyncio", "httpx", "aiohttp", "robots.txt parsing", "APIs and JSON/XML handling"], "tags": []}, {"id": "23661b20-736b-4c52-a0db-9171b4b98c4c", "name": "Web App", "value": [{"id": "3db43d92-add0-41bb-b666-c667fe726806", "type": "paragraph", "value": "<strong>Flask is a micro web framework/server. If you just want to open a html file in a web browser use <code>'webbrowser.open(&lt;path&gt;)'</code> instead.</strong>"}, {"id": "4b48cff5-8415-48c2-995f-5a4eaead5375", "type": "block_code", "value": "# $ pip3 install flask\nimport flask as fl"}, {"id": "8e0b2f0f-15ae-4a2c-8042-f0998d900f59", "type": "block_code", "value": "app = fl.Flask(__name__)                   # Returns the app object. Put at the top.\napp.run(host=None, port=None, debug=None)  # Or: $ flask --app FILE run [--ARG[=VAL]]\u2026"}, {"id": "8d70c2f5-4281-48db-9494-0035f2b30299", "type": "list", "value": "<li><strong>Starts the app at <code>'http://localhost:5000'</code>. Use <code>'host=&quot;0.0.0.0&quot;'</code> to run externally.</strong></li>\n<li><strong>Install a WSGI server like <a href=\"https://flask.palletsprojects.com/en/latest/deploying/waitress/\">Waitress</a> and a HTTP server such as <a href=\"https://flask.palletsprojects.com/en/latest/deploying/nginx/\">Nginx</a> for better security.</strong></li>\n<li><strong>Debug mode restarts the app whenever script changes and displays errors in the browser.</strong></li>"}], "sub_concepts": [{"id": "5d50051d-bc5f-4cc3-ae1e-f209404740eb", "name": "Serving JSON", "value": [{"id": "bafaf469-e4db-46d2-9ebd-99091abde6ff", "type": "block_code", "value": "@app.post('/<sport>/odds')\ndef serve_json(sport):\n    team = fl.request.form['team']\n    return {'team': team, 'odds': [2.09, 3.74, 3.68]}"}, {"id": "2a022f08-0b7f-4d66-b5c9-6925f42720ae", "type": "heading", "value": "Starts the app in its own thread and queries its REST API:"}, {"id": "a6ef199b-8b95-48ce-b35e-0bf3172b4ce1", "type": "block_code", "value": "# $ pip3 install requests\n>>> import threading, requests\n>>> threading.Thread(target=app.run, daemon=True).start()\n>>> url = 'http://localhost:5000/football/odds'\n>>> response = requests.post(url, data={'team': 'arsenal f.c.'})\n>>> response.json()\n{'team': 'arsenal f.c.', 'odds': [2.09, 3.74, 3.68]}"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "Web apps in Python leverage frameworks like Flask and Django with async capabilities, middleware, ORM, and templating engines to handle HTTP requests efficiently.", "description": "Web applications in Python are typically built using frameworks like Flask, Django, or FastAPI. These frameworks provide the tools needed to handle HTTP requests, manage application state, interact with databases, and render responses. A core component of building web apps is understanding how these frameworks leverage Python's asynchronous capabilities, middleware architecture, ORM (Object-Relational Mapping), and templating engines.\n\nAsynchronous programming in Python, particularly with `asyncio`, allows web applications to handle multiple requests simultaneously without the need for multi-threading. This is crucial for I/O-bound operations such as database queries or API calls. Modern frameworks like FastAPI utilize async/await syntax extensively to improve performance and scalability.\n\nMiddleware components serve as a layer of logic that processes requests before they reach your view functions (or route handlers) and responses before they are sent back to the client. Middleware can be used for authentication, logging, or even modifying request/response objects dynamically. Django, for instance, has an extensive middleware system that allows developers to plug in various functionalities at different stages of request handling.\n\nORMs abstract database interactions by allowing developers to work with high-level entities like classes and objects rather than raw SQL queries. This promotes code reusability and security through parameterized queries. Both Django's ORM and SQLAlchemy (often used with Flask) provide powerful query interfaces, migrations, and model definitions that simplify complex database operations.\n\nTemplating engines such as Jinja2 in Flask or the built-in templating system in Django allow for dynamic content generation by combining templates with context data. This decouples presentation logic from business logic, enabling cleaner, more maintainable code.\n\nFor advanced use cases, Python web apps can integrate with microservices architectures using APIs (often RESTful), WebSockets for real-time communication, and message brokers like RabbitMQ or Kafka for distributed systems communication. Performance optimization techniques might include caching mechanisms (e.g., Redis), load balancing, and horizontal scaling strategies.\n\nRelevant PEPs include PEP 498 which introduces asynchronous generators and coroutines to Python's syntax (`async`/`await`), crucial for developing high-performance web services.", "difficulty": "advanced", "common_pitfalls": ["Overloading views with business logic instead of using controllers or service layers for better maintainability.", "Misunderstanding asynchronous programming constructs leading to inefficient use of async/await.", "Neglecting middleware security implications, such as CSRF tokens or session management.", "Inefficient database queries due to improper ORM usage.", "Failing to properly manage configuration settings across different environments (development, testing, production)."], "related_concepts": ["Flask", "Django", "FastAPI", "Asyncio", "ORM (SQLAlchemy, Django ORM)", "Middleware", "Jinja2 Templating", "Asynchronous Generators", "Microservices", "WebSockets"], "tags": []}, {"id": "c6b1a32d-782a-460e-bd80-2f38e7b970f0", "name": "Profiling", "value": [{"id": "46f35798-c7a9-43f3-a3b0-2dbb5ae4d101", "type": "block_code", "value": "from time import perf_counter\nstart_time = perf_counter()\n...\nduration_in_seconds = perf_counter() - start_time"}], "sub_concepts": [{"id": "3e6a2c1c-ea5e-4564-a47f-6e8b56aafe0e", "name": "Sampling and Memory Profilers", "value": [{"id": "0d40f511-8ab3-48de-a248-28eeeb372d19", "type": "block_code", "value": "+--------------+------------+-------------------------------+-------+------+\n| pip3 install |   Target   |          How to run           | Lines | Live |\n+--------------+------------+-------------------------------+-------+------+\n| pyinstrument |    CPU     | pyinstrument test.py          |  No   | No   |\n| py-spy       |    CPU     | py-spy top -- python3 test.py |  No   | Yes  |\n| scalene      | CPU+Memory | scalene test.py               |  Yes  | No   |\n| memray       |   Memory   | memray run --live test.py     |  Yes  | Yes  |\n+--------------+------------+-------------------------------+-------+------+"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "Profiling measures program performance metrics to identify bottlenecks and optimize code efficiency.", "description": "Profiling in Python is a critical process for optimizing code performance by identifying bottlenecks or inefficient sections of the program. It involves measuring various aspects such as execution time, memory usage, and frequency of function calls. Python offers several built-in and third-party tools to facilitate profiling at different granularities. The `cProfile` module, part of Python's standard library since version 2.5, provides deterministic profiling by sampling the call stack and generating statistics about the number of function calls and their execution times. It outputs detailed reports that can be visualized with modules like `pstats` or external tools such as SnakeViz for more intuitive representations.\n\nAdvanced use cases include performance tuning in large-scale applications where profiling is integrated into continuous integration pipelines to catch regressions early. Python 3.9 introduced optimizations and new features, but core profilers remain largely unchanged, focusing on CPU time rather than wall-clock time, which can differ when dealing with asynchronous code or I/O-bound tasks.\n\nFor more granular insights, memory profiling tools such as `memory_profiler` or `tracemalloc` are used to track memory allocation and identify leaks. `Line-by-line` profilers like `line_profiler` offer finer control by measuring the execution time of individual lines within a function, which is essential for optimizing critical code paths.\n\nProfiling is closely tied with Python's introspection capabilities, leveraging decorators or context managers to minimize manual instrumentation overhead. Understanding profiling results requires familiarity with Python's call stack and execution model, as well as an awareness of how different optimization techniques (e.g., JIT compilation using PyPy) might affect the profiled metrics.\n\nRelevant PEPs include PEP 3147 for `cProfile`, which outlines its API, and PEP 597 introducing the `tracemalloc` module. Developers often use these tools in conjunction with asynchronous profiling frameworks like `async-profiler` to handle Python's async IO capabilities effectively.", "difficulty": "advanced", "common_pitfalls": ["Misinterpreting CPU time versus wall-clock time, leading to incorrect assumptions about performance issues.", "Overlooking the impact of Python's GIL on multi-threaded applications when profiling.", "Neglecting memory-related bottlenecks while focusing solely on execution speed.", "Failing to account for I/O-bound operations in performance analysis."], "related_concepts": ["cProfile", "pstats", "memory_profiler", "tracemalloc", "line_profiler", "asynchronous programming", "decorators", "context managers", "PyPy JIT"], "tags": []}, {"id": "25d58163-0a0c-47bf-a7e2-8a7cf1a8955c", "name": "NumPy", "value": [{"id": "c70d0b22-c6f4-4fb0-90b8-e73b889dcae2", "type": "paragraph", "value": "<strong>Array manipulation mini-language. It can run up to one hundred times faster than the equivalent Python code. An even faster alternative that runs on a GPU is called CuPy.</strong>"}, {"id": "466d82cb-7175-45d4-9c00-6352b601cf57", "type": "block_code", "value": "# $ pip3 install numpy\nimport numpy as np"}, {"id": "01d08b4b-aa10-45c7-89a7-20cb4dc51551", "type": "block_code", "value": "<array> = np.array(<list/list_of_lists/\u2026>)              # Returns a 1d/2d/\u2026 NumPy array.\n<array> = np.zeros/ones/empty(<shape>)                  # Also np.full(<shape>, <el>).\n<array> = np.arange(from_inc, to_exc, \u00b1step)            # Also np.linspace(start, stop, len).\n<array> = np.random.randint(from_inc, to_exc, <shape>)  # Also np.random.random(<shape>)."}, {"id": "fa0f4c79-0aaa-4781-8290-0780c2cc659d", "type": "block_code", "value": "<view>  = <array>.reshape(<shape>)                      # Also `<array>.shape = <shape>`.\n<array> = <array>.flatten()                             # Also `<view> = <array>.ravel()`.\n<view>  = <array>.transpose()                           # Or: <array>.T"}, {"id": "342594dd-1e31-48eb-9254-5da6a1915392", "type": "block_code", "value": "<array> = np.copy/abs/sqrt/log/int64(<array>)           # Returns new array of the same shape.\n<array> = <array>.sum/max/mean/argmax/all(axis)         # Aggregates specified dimension.\n<array> = np.apply_along_axis(<func>, axis, <array>)    # Func can return a scalar or array."}, {"id": "10a7751b-398e-4ae6-ac8d-bb4c75e55d0c", "type": "block_code", "value": "<array> = np.concatenate(<list_of_arrays>, axis=0)      # Links arrays along first axis (rows).\n<array> = np.vstack/column_stack(<list_of_arrays>)      # Treats 1d arrays as rows or columns.\n<array> = np.tile/repeat(<array>, <int/list> [, axis])  # Tiles array or repeats its elements."}, {"id": "add8cc81-924f-4bdd-b3e5-7996dbf51050", "type": "list", "value": "<li><strong>Shape is a tuple of dimension sizes. A 100x50 RGB image has shape (50, 100, 3).</strong></li>\n<li><strong>Axis is an index of a dimension. Leftmost dimension has index 0. Summing the RGB image along axis 2 will return a greyscale image with shape (50, 100).</strong></li>"}], "sub_concepts": [{"id": "cb01e97e-0a26-4bc6-9970-e0b1f3c34742", "name": "Example", "value": [{"id": "de225f6a-af3f-485b-8962-e2f88c7f7823", "type": "heading", "value": "For each point returns index of its nearest point (<code>[0.1, 0.6, 0.8] =&gt; [1, 2, 1]</code>):"}, {"id": "de9ff4e0-3f93-42cf-9e7e-eae723c6e649", "type": "block_code", "value": ">>> print(points := np.array([0.1, 0.6, 0.8]))\n[0.1  0.6  0.8]\n>>> print(wrapped_points := points.reshape(3, 1))\n[[0.1]\n [0.6]\n [0.8]]\n>>> print(deltas := points - wrapped_points)\n[[ 0.   0.5  0.7]\n [-0.5  0.   0.2]\n [-0.7 -0.2  0. ]]\n>>> deltas[range(3), range(3)] = np.inf\n>>> print(distances := np.abs(deltas))\n[[inf  0.5  0.7]\n [0.5  inf  0.2]\n [0.7  0.2  inf]]\n>>> print(distances.argmin(axis=1))\n[1 2 1]"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "NumPy provides efficient storage and manipulation of large numerical datasets through its ndarray object and optimized mathematical operations.", "description": "NumPy is a foundational library for numerical computing in Python. It provides support for large, multi-dimensional arrays and matrices, along with a collection of high-level mathematical functions to operate on these arrays. At its core, NumPy introduces the ndarray (n-dimensional array) object which allows efficient storage and manipulation of homogeneous data types using vectorized operations. This efficiency stems from NumPy's use of contiguous memory blocks and optimized C-based implementations.\n\nNumPy's performance benefits are largely due to its underlying memory model that avoids Python-level loops, reducing overhead significantly. It achieves this by implementing a buffer protocol which allows for seamless interfacing with other libraries (like SciPy and pandas) and the ability to pass data directly to compiled code.\n\nAdvanced users leverage NumPy for tasks such as linear algebra operations, Fourier transforms, and random number generation through submodules like `numpy.linalg` and `numpy.fft`. Its broadcasting mechanism is particularly powerful, allowing arithmetic operations on arrays of different shapes in a manner that mimics element-wise behavior without explicitly reshaping data.\n\nNumPy also supports universal functions (ufuncs) which are key to its efficiency. Ufuncs perform element-by-element operations and are implemented in C for performance reasons. They facilitate array broadcasting, type casting, and several other standard features. Additionally, NumPy integrates well with the Python ecosystem through its compatibility with Cython, allowing parts of code to be compiled into C extensions for further optimization.\n\nThe library is governed by PEP 20 (The Zen of Python) principles, ensuring simplicity and readability while maintaining high performance. Its design encourages clear and expressive code, promoting the use of functions that apply to arrays as a whole rather than iterating over elements individually.", "difficulty": "advanced", "common_pitfalls": ["Assuming NumPy arrays are mutable in the same way as Python lists, leading to unexpected behavior when changing array contents.", "Misunderstanding broadcasting rules, causing shape mismatch errors during arithmetic operations.", "Overlooking memory layout (C vs. Fortran order) which can affect performance and interoperability with other libraries.", "Failing to utilize vectorized operations, resulting in slower code due to Python-level loops.", "Not using `np.copy()` when needed, leading to unintentional modification of original arrays due to NumPy's default pass-by-reference behavior."], "related_concepts": ["Pandas (for data manipulation and analysis)", "SciPy (for scientific computing tasks like integration, optimization, and statistics)", "Jupyter Notebooks (for interactive development with NumPy)", "Matplotlib (for data visualization based on NumPy arrays)", "Cython (for performance optimization by compiling Python code to C)"], "tags": []}, {"id": "0a81e4c1-2383-4955-91d6-3b39dd5894de", "name": "Image", "value": [{"id": "67d81b05-b638-4ced-8293-a29c64177372", "type": "block_code", "value": "# $ pip3 install pillow\nfrom PIL import Image"}, {"id": "f86ddd4f-8ce9-44d7-aeb7-0473478278af", "type": "block_code", "value": "<Image> = Image.new('<mode>', (width, height))  # Creates new image. Also `color=<int/tuple>`.\n<Image> = Image.open(<path>)                    # Identifies format based on file's contents.\n<Image> = <Image>.convert('<mode>')             # Converts image to the new mode (see Modes).\n<Image>.save(<path>)                            # Selects format based on extension (PNG/JPG\u2026).\n<Image>.show()                                  # Displays image in default preview app."}, {"id": "af68d419-ad5e-4952-b27a-232bae52a88a", "type": "block_code", "value": "<int/tup> = <Image>.getpixel((x, y))            # Returns pixel's value (its color).\n<ImgCore> = <Image>.getdata()                   # Returns a flattened view of pixel values.\n<Image>.putpixel((x, y), <int/tuple>)           # Updates pixel's value. Clips passed int/s.\n<Image>.putdata(<list/ImgCore>)                 # Updates pixels with a copy of the sequence.\n<Image>.paste(<Image>, (x, y))                  # Draws passed image at the specified location."}, {"id": "c1549b33-3cce-4d70-8161-0059876c091b", "type": "block_code", "value": "<Image> = <Image>.filter(<Filter>)              # Use ImageFilter.<name>(<args>) for Filter.\n<Image> = <Enhance>.enhance(<float>)            # Use ImageEnhance.<name>(<Image>) for Enhance."}, {"id": "3c92352d-6085-4af1-affd-612bb71ba5ca", "type": "block_code", "value": "<array> = np.array(<Image>)                     # Creates a 2d/3d NumPy array from the image.\n<Image> = Image.fromarray(np.uint8(<array>))    # Use <array>.clip(0, 255) to clip the values."}], "sub_concepts": [{"id": "eda53e78-34cb-4821-b92b-aa990a952ae0", "name": "Image Draw", "value": [{"id": "9f288071-482e-4db5-a119-471556516cf7", "type": "block_code", "value": "from PIL import ImageDraw\n<Draw> = ImageDraw.Draw(<Image>)                # Object for adding 2D graphics to the image.\n<Draw>.point((x, y))                            # Draws a point. Also `fill=<int/tuple/str>`.\n<Draw>.line((x1, y1, x2, y2 [, ...]))           # For anti-aliasing use <Image>.resize((w, h)).\n<Draw>.arc((x1, y1, x2, y2), deg1, deg2)        # Draws in clockwise dir. Also pieslice().\n<Draw>.rectangle((x1, y1, x2, y2))              # Also rounded_rectangle(), regular_polygon().\n<Draw>.polygon((x1, y1, x2, y2, ...))           # Last point gets connected to the first one.\n<Draw>.ellipse((x1, y1, x2, y2))                # To rotate use <Image>.rotate(anticlock_deg).\n<Draw>.text((x, y), <str>, font=<Font>)         # `<Font> = ImageFont.truetype(<path>, size)`."}, {"id": "39f78de4-a323-40cb-8e87-3f907c247f7b", "type": "list", "value": "<li><strong>Use <code>'fill=&lt;color&gt;'</code> to set the primary color.</strong></li>\n<li><strong>Use <code>'width=&lt;int&gt;'</code> to set the width of lines or contours.</strong></li>\n<li><strong>Use <code>'outline=&lt;color&gt;'</code> to set the color of the contours.</strong></li>\n<li><strong>Color can be an int, tuple, <code>'#rrggbb[aa]'</code> or a color name.</strong></li>"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": "The Image class in Pillow provides advanced image processing capabilities with efficient memory management and integration with NumPy for complex manipulations.", "description": "The `Image` module is part of the Python Imaging Library (PIL), which is maintained under the name Pillow. It provides extensive file format support, an efficient internal representation, and powerful image processing capabilities. The `Image` class acts as a container for pixel data and supports operations such as resizing, cropping, rotating, and transforming images. Underneath, Pillow uses a variety of underlying libraries to manage different image formats like JPEG, PNG, BMP, etc.\n\nFrom an advanced perspective, the internal workings of the `Image` module involve efficient memory management through NumPy integration, allowing for fast pixel-level manipulation without excessive copying. The module supports lazy loading and deferred operations, meaning transformations can be queued up and applied in a single pass when the image is finally rendered or saved. This approach minimizes resource usage and speeds up processing.\n\nAdvanced users leverage the `Image` class's ability to interface with NumPy arrays directly, enabling more complex mathematical manipulations on images using existing scientific libraries like SciPy or OpenCV. The module also supports custom filters through the use of callable objects that can be passed as parameters to transformation methods, allowing for highly specialized image processing tasks.\n\nPerformance implications are significant; efficient memory management and lazy evaluation ensure minimal overhead when working with large datasets or performing batch operations. Common advanced use cases include automated data augmentation pipelines in machine learning workflows, high-performance web applications requiring dynamic image manipulation, and scientific imaging projects where precise control over pixel data is crucial.\n\nRelevant PEPs: While the `Image` module itself doesn't have direct PEPs, it aligns with broader community standards for Python's I/O capabilities (PEP 3151 - The pickle protocol) and efficient numerical computing (NumPy-related improvements).\n\n", "difficulty": "advanced", "common_pitfalls": ["Assuming all operations are eager when they are actually lazy.", "Misunderstanding the difference between PIL and Pillow, particularly regarding compatibility and feature sets in newer Python versions.", "Forgetting that direct NumPy integration can lead to unintended side effects if arrays are modified without creating copies.", "Not optimizing image file formats for specific use cases (e.g., using PNG for lossless compression when JPEG might be sufficient).", "Overlooking the implications of deferred operations on large datasets, which can consume significant memory if not managed properly."], "related_concepts": ["NumPy", "Pillow/PIL", "File I/O", "Concurrency", "Data Augmentation", "Scientific Computing Libraries (e.g., SciPy)", "Web Frameworks for dynamic image processing"], "tags": []}, {"id": "f9d26591-69e3-49a2-a6a8-dfa7a7f76669", "name": "Animation", "value": [{"id": "a9434321-f26a-4f8e-afeb-9cfeb62eb1b2", "type": "heading", "value": "Creates a GIF of a bouncing ball:"}, {"id": "9695370b-d73b-4758-bfa7-816daf80e1da", "type": "block_code", "value": "# $ pip3 install imageio\nfrom PIL import Image, ImageDraw\nimport imageio\n\nWIDTH, HEIGHT, R = 126, 126, 10\nframes = []\nfor velocity in range(1, 16):\n    y = sum(range(velocity))\n    frame = Image.new('L', (WIDTH, HEIGHT))\n    draw = ImageDraw.Draw(frame)\n    draw.ellipse((WIDTH/2-R, y, WIDTH/2+R, y+R*2), fill='white')\n    frames.append(frame)\nframes += reversed(frames[1:-1])\nimageio.mimsave('test.gif', frames, duration=0.03)"}], "sub_concepts": [], "short_description": "Animation in Python involves using libraries such as matplotlib, pygame, PyQt5/6, and manim to create dynamic visualizations or simulations, each tailored for specific use cases and performance considerations.", "description": "In Python, animation is not a built-in concept but rather involves using various libraries to create animated visualizations or simulations. Advanced Python users often leverage libraries such as `matplotlib`, `pygame`, `PyQt5/6`, and `manim` for different types of animations, each catering to specific needs and offering unique features.\n\n1. **Matplotlib**: Primarily used for plotting static 2D graphs, it includes functionalities like `FuncAnimation` which allows for the creation of animations by updating figures over a series of frames. It leverages Matplotlib's `ArtistAnimation`, where artists (e.g., lines, patches) are updated at each frame to create an animation sequence. This approach is ideal for data visualization tasks.\n\n2. **Pygame**: A set of Python modules designed for writing video games. Pygame provides tools for rendering graphics and sounds, managing events, and handling user input, making it a suitable choice for creating real-time 2D animations. It operates by updating the game screen at fixed intervals (frames), utilizing event loops to handle inputs and render frames accordingly.\n\n3. **PyQt5/6**: These are set of Python bindings for The Qt Company's Qt application framework, which is used for developing graphical user interfaces (GUIs). They support animations through `QPropertyAnimation`, `QSequentialAnimationGroup`, `QParallelAnimationGroup`, etc., allowing for smooth transitions and transformations of GUI elements. PyQt\u2019s robustness makes it suitable for creating complex applications with rich animations.\n\n4. **Manim**: A mathematical animation engine that emphasizes ease of use in rendering mathematical concepts as animations. It abstracts the complexity involved in setting up scenes, frames, and renders them into high-quality videos. Manim is particularly noted for its declarative style, enabling users to define transformations and sequences using a Pythonic syntax.\n\nAnimations in these libraries often involve the iteration over time or data points, updating graphics at each step, and managing rendering contexts efficiently. For performance optimization, advanced users might delve into techniques such as double buffering (to reduce flicker), optimizing frame rates, and leveraging hardware acceleration when available.\n\nRelevant PEPs include PEP 3149 which introduces `matplotlib`'s animation API enhancements, emphasizing better integration with the overall plotting framework for improved usability and performance. While not all libraries have specific associated PEPs, their development is often influenced by broader discussions in Python\u2019s evolving graphical capabilities and performance considerations.\n\nUnderstanding the underlying mechanisms of these libraries requires familiarity with concepts like event loops, double buffering, rendering pipelines, and asynchronous programming (in cases where real-time updates are necessary). Additionally, managing state across frames, efficient memory usage, and ensuring smooth frame transitions are crucial for high-performance animations.", "difficulty": "advanced", "common_pitfalls": ["Ignoring frame rate management leading to choppy animations.", "Overloading the rendering loop with excessive computations causing performance bottlenecks.", "Failing to handle event-driven updates properly in real-time applications like games.", "Mismanaging state across animation frames, resulting in inconsistent or erroneous displays.", "Underestimating the importance of efficient memory management when handling large datasets in animations."], "related_concepts": ["Event Loop", "Double Buffering", "Rendering Pipeline", "Asynchronous Programming", "GUI Frameworks (Qt)", "Data Visualization", "Real-time Systems"], "tags": []}, {"id": "b82e7660-6f4b-4252-a96c-cddef75fde6a", "name": "Audio", "value": [{"id": "5598f90e-dd78-404c-8a9a-1f36022d364b", "type": "block_code", "value": "import wave"}, {"id": "eaa6479d-7953-4dba-a305-266bd4563c54", "type": "block_code", "value": "<Wave>  = wave.open('<path>')         # Opens the WAV file for reading.\n<int>   = <Wave>.getframerate()       # Returns number of frames per second.\n<int>   = <Wave>.getnchannels()       # Returns number of samples per frame.\n<int>   = <Wave>.getsampwidth()       # Returns number of bytes per sample.\n<tuple> = <Wave>.getparams()          # Returns namedtuple of all parameters.\n<bytes> = <Wave>.readframes(nframes)  # Returns all frames if -1 is passed."}, {"id": "d56b12a4-c358-4af3-9473-a726e08687df", "type": "block_code", "value": "<Wave> = wave.open('<path>', 'wb')    # Creates/truncates a file for writing.\n<Wave>.setframerate(<int>)            # Pass 44100 for CD, 48000 for video.\n<Wave>.setnchannels(<int>)            # Pass 1 for mono, 2 for stereo.\n<Wave>.setsampwidth(<int>)            # Pass 2 for CD, 3 for hi-res sound.\n<Wave>.setparams(<tuple>)             # Tuple must contain all parameters.\n<Wave>.writeframes(<bytes>)           # Appends frames to the file."}, {"id": "9d0e6610-832f-41e9-8947-342f7e20b7d7", "type": "list", "value": "<li><strong>Bytes object contains a sequence of frames, each consisting of one or more samples.</strong></li>\n<li><strong>In a stereo signal, the first sample of a frame belongs to the left channel.</strong></li>\n<li><strong>Each sample consists of one or more bytes that, when converted to an integer, indicate the displacement of a speaker membrane at a given moment.</strong></li>\n<li><strong>If sample width is one byte, then the integer should be encoded unsigned. For all other sizes, the integer should be encoded signed with little-endian byte order.</strong></li>"}], "sub_concepts": [{"id": "ae1dced7-e809-4bf6-b24a-6d6f0528c915", "name": "Text to Speech", "value": [{"id": "1f60ea69-0362-43c7-ad73-67de6bfa1418", "type": "block_code", "value": "# $ pip3 install pyttsx3\nimport pyttsx3\nengine = pyttsx3.init()\nengine.say('Sally sells seashells by the seashore.')\nengine.runAndWait()"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": null, "description": null, "difficulty": null, "common_pitfalls": [], "related_concepts": [], "tags": []}, {"id": "4cc66e5a-eddf-48b3-a765-d896bf8d751d", "name": "Synthesizer", "value": [{"id": "46abdac9-f701-47d6-8494-6e4d56d89d79", "type": "heading", "value": "Plays Popcorn by Gershon Kingsley:"}, {"id": "a74927f8-79c9-44e4-87a0-3645b5013646", "type": "block_code", "value": "# $ pip3 install simpleaudio\nimport itertools as it, math, array, simpleaudio\n\ndef play_notes(notes, bpm=132, f=44100):\n    get_pause   = lambda n_beats: it.repeat(0, int(n_beats * 60/bpm * f))\n    sin_f       = lambda i, hz: math.sin(i * 2 * math.pi * hz / f)\n    get_wave    = lambda hz, n_beats: (sin_f(i, hz) for i in range(int(n_beats * 60/bpm * f)))\n    get_hz      = lambda note: 440 * 2 ** ((int(note[:2]) - 69) / 12)\n    get_nbeats  = lambda note: 1/2 if '\u2669' in note else 1/4 if '\u266a' in note else 1\n    get_samples = lambda n: get_wave(get_hz(n), get_nbeats(n)) if n else get_pause(1/4)\n    samples_f   = it.chain.from_iterable(get_samples(n) for n in notes.split(','))\n    samples_i   = array.array('h', (int(fl * 5000) for fl in samples_f))\n    simpleaudio.play_buffer(samples_i, 1, 2, f).wait_done()\n\nplay_notes('83\u2669,81\u266a,,83\u266a,,78\u266a,,74\u266a,,78\u266a,,71\u266a,,,,83\u266a,,81\u266a,,83\u266a,,78\u266a,,74\u266a,,78\u266a,,71\u266a,,,,'\n           '83\u2669,85\u266a,,86\u266a,,85\u266a,,86\u266a,,83\u266a,,85\u2669,83\u266a,,85\u266a,,81\u266a,,83\u266a,,81\u266a,,83\u266a,,79\u266a,,83\u266a,,,,')"}], "sub_concepts": [], "short_description": null, "description": null, "difficulty": null, "common_pitfalls": [], "related_concepts": [], "tags": []}, {"id": "945dff06-9053-49a4-a226-af2c9e2b7532", "name": "Pygame", "value": [{"id": "f1407487-06cd-4175-a6e7-0c7ceaecd114", "type": "heading", "value": "Opes a window and draws a square that can be moved with arrow keys:"}, {"id": "5acf8863-687a-4551-a079-1c0d773f8bf2", "type": "block_code", "value": "# $ pip3 install pygame\nimport pygame as pg\n\npg.init()\nscreen = pg.display.set_mode((500, 500))\nrect = pg.Rect(240, 240, 20, 20)\nwhile not pg.event.get(pg.QUIT):\n    deltas = {pg.K_UP: (0, -1), pg.K_RIGHT: (1, 0), pg.K_DOWN: (0, 1), pg.K_LEFT: (-1, 0)}\n    for event in pg.event.get(pg.KEYDOWN):\n        x, y = deltas.get(event.key, (0, 0))\n        rect = rect.move((x*20, y*20))\n    screen.fill(pg.Color('black'))\n    pg.draw.rect(screen, pg.Color('white'), rect)\n    pg.display.flip()\npg.quit()"}], "sub_concepts": [{"id": "b6f84634-5c50-48f4-8889-ea749ae8a147", "name": "Basic Mario Brothers Example", "value": [{"id": "3b7f7c59-556d-4d35-bcf7-34578a21d610", "type": "block_code", "value": "import collections, dataclasses, enum, io, itertools as it, pygame as pg, urllib.request\nfrom random import randint\n\nP = collections.namedtuple('P', 'x y')          # Position\nD = enum.Enum('D', 'n e s w')                   # Direction\nW, H, MAX_S = 50, 50, P(5, 10)                  # Width, Height, Max speed\n\ndef main():\n    def get_screen():\n        pg.init()\n        return pg.display.set_mode((W*16, H*16))\n    def get_images():\n        url = 'https://gto76.github.io/python-cheatsheet/web/mario_bros.png'\n        img = pg.image.load(io.BytesIO(urllib.request.urlopen(url).read()))\n        return [img.subsurface(get_rect(x, 0)) for x in range(img.get_width() // 16)]\n    def get_mario():\n        Mario = dataclasses.make_dataclass('Mario', 'rect spd facing_left frame_cycle'.split())\n        return Mario(get_rect(1, 1), P(0, 0), False, it.cycle(range(3)))\n    def get_tiles():\n        border = [(x, y) for x in range(W) for y in range(H) if x in [0, W-1] or y in [0, H-1]]\n        platforms = [(randint(1, W-2), randint(2, H-2)) for _ in range(W*H // 10)]\n        return [get_rect(x, y) for x, y in border + platforms]\n    def get_rect(x, y):\n        return pg.Rect(x*16, y*16, 16, 16)\n    run(get_screen(), get_images(), get_mario(), get_tiles())\n\ndef run(screen, images, mario, tiles):\n    clock = pg.time.Clock()\n    pressed = set()\n    while not pg.event.get(pg.QUIT):\n        clock.tick(28)\n        pressed |= {e.key for e in pg.event.get(pg.KEYDOWN)}\n        pressed -= {e.key for e in pg.event.get(pg.KEYUP)}\n        update_speed(mario, tiles, pressed)\n        update_position(mario, tiles)\n        draw(screen, images, mario, tiles)\n\ndef update_speed(mario, tiles, pressed):\n    x, y = mario.spd\n    x += 2 * ((pg.K_RIGHT in pressed) - (pg.K_LEFT in pressed))\n    x += (x < 0) - (x > 0)\n    y += 1 if D.s not in get_boundaries(mario.rect, tiles) else (pg.K_UP in pressed) * -10\n    mario.spd = P(x=max(-MAX_S.x, min(MAX_S.x, x)), y=max(-MAX_S.y, min(MAX_S.y, y)))\n\ndef update_position(mario, tiles):\n    x, y = mario.rect.topleft\n    n_steps = max(abs(s) for s in mario.spd)\n    for _ in range(n_steps):\n        mario.spd = stop_on_collision(mario.spd, get_boundaries(mario.rect, tiles))\n        x, y = x + (mario.spd.x / n_steps), y + (mario.spd.y / n_steps)\n        mario.rect.topleft = x, y\n\ndef get_boundaries(rect, tiles):\n    deltas = {D.n: P(0, -1), D.e: P(1, 0), D.s: P(0, 1), D.w: P(-1, 0)}\n    return {d for d, delta in deltas.items() if rect.move(delta).collidelist(tiles) != -1}\n\ndef stop_on_collision(spd, bounds):\n    return P(x=0 if (D.w in bounds and spd.x < 0) or (D.e in bounds and spd.x > 0) else spd.x,\n             y=0 if (D.n in bounds and spd.y < 0) or (D.s in bounds and spd.y > 0) else spd.y)\n\ndef draw(screen, images, mario, tiles):\n    screen.fill((85, 168, 255))\n    mario.facing_left = mario.spd.x < 0 if mario.spd.x else mario.facing_left\n    is_airborne = D.s not in get_boundaries(mario.rect, tiles)\n    image_index = 4 if is_airborne else next(mario.frame_cycle) if mario.spd.x else 6\n    screen.blit(images[image_index + (mario.facing_left * 9)], mario.rect)\n    for t in tiles:\n        is_border = t.x in [0, (W-1)*16] or t.y in [0, (H-1)*16]\n        screen.blit(images[18 if is_border else 19], t)\n    pg.display.flip()\n\nif __name__ == '__main__':\n    main()"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": null, "description": null, "difficulty": null, "common_pitfalls": [], "related_concepts": [], "tags": []}, {"id": "f50ca23e-19e6-4a62-ba71-bb5630b3d9ee", "name": "Pandas", "value": [{"id": "75cb8a11-8e90-4cd7-87fc-c7827cc700b6", "type": "paragraph", "value": "<strong>Data analysis library. For examples see <a href=\"#plotly\">Plotly</a>.</strong>"}, {"id": "4568c99d-e852-459e-b5e4-5a7ed16d54b2", "type": "block_code", "value": "# $ pip3 install pandas matplotlib\nimport pandas as pd, matplotlib.pyplot as plt"}], "sub_concepts": [{"id": "f8344698-e72e-420f-950a-815e1cf69612", "name": "Rolling", "value": [{"id": "470ecd9c-26ae-4c96-ae89-28173b2aad85", "type": "paragraph", "value": "<strong>Object for rolling window calculations.</strong>"}, {"id": "f674f868-b64b-4bf5-a01a-5ab9c8a061ca", "type": "block_code", "value": "<RS/RDF/RGB> = <S/DF/GB>.rolling(win_size)     # Also: `min_periods=None, center=False`.\n<RS/RDF/RGB> = <RDF/RGB>[col_key/s]            # Or: <RDF/RGB>.<col_key>\n<S/DF>       = <R>.mean/sum/max()              # Or: <R>.apply/agg(<agg_func/str>)"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": null, "description": null, "difficulty": null, "common_pitfalls": [], "related_concepts": [], "tags": []}, {"id": "3056945f-2ddd-475a-8846-abdd43bf9c66", "name": "Plotly", "value": [{"id": "b5c49c7b-eac3-49e8-9305-1d5ed85b7b74", "type": "block_code", "value": "# $ pip3 install plotly kaleido pandas\nimport plotly.express as px, pandas as pd"}, {"id": "c5f5ebd0-786c-4a11-be86-44f9ee907644", "type": "block_code", "value": "<Fig> = px.line(<DF>, x=col_key, y=col_key)           # Or: px.line(x=<list>, y=<list>)\n<Fig>.update_layout(margin=dict(t=0, r=0, b=0, l=0))  # Also `paper_bgcolor='rgb(0, 0, 0)'`.\n<Fig>.write_html/json/image('<path>')                 # `<Fig>.show()` displays the plot."}, {"id": "766280d8-7cf2-4147-b729-570e72c0f542", "type": "block_code", "value": "<Fig> = px.area/bar/box(<DF>, x=col_key, y=col_key)   # Also `color=col_key`.\n<Fig> = px.scatter(<DF>, x=col_key, y=col_key)        # Also `color/size/symbol=col_key`.\n<Fig> = px.scatter_3d(<DF>, x=col_key, y=col_key, \u2026)  # `z=col_key`. Also color/size/symbol.\n<Fig> = px.histogram(<DF>, x=col_key)                 # Also `nbins=<int>`."}, {"id": "5903a02a-3bbe-4468-9f16-d3ebce4e706e", "type": "heading", "value": "Displays a line chart of total coronavirus deaths per million grouped by continent:"}, {"id": "19987bf8-06f4-4144-91bc-b1def3bb2a55", "type": "paragraph", "value": "<img src=\"web/covid_deaths.png\" alt=\"Covid Deaths\" />"}, {"id": "79daec31-e56a-4cf9-9d4f-a1783c56ddac", "type": "block_html", "value": "<div id=\"2a950764-39fc-416d-97fe-0a6226a3095f\" class=\"plotly-graph-div\" style=\"height:312px; width:914px;\"></div>"}, {"id": "6df9cf75-ffd1-4ed7-a78d-2abe3eefed3b", "type": "block_code", "value": "covid = pd.read_csv('https://raw.githubusercontent.com/owid/covid-19-data/8dde8ca49b'\n                    '6e648c17dd420b2726ca0779402651/public/data/owid-covid-data.csv',\n                    usecols=['iso_code', 'date', 'population', 'total_deaths'])\ncontinents = pd.read_csv('https://gto76.github.io/python-cheatsheet/web/continents.csv',\n                         usecols=['Three_Letter_Country_Code', 'Continent_Name'])\ndf = pd.merge(covid, continents, left_on='iso_code', right_on='Three_Letter_Country_Code')\ndf = df.groupby(['Continent_Name', 'date']).sum().reset_index()\ndf['Total Deaths per Million'] = df.total_deaths * 1e6 / df.population\ndf = df[df.date > '2020-03-14']\ndf = df.rename({'date': 'Date', 'Continent_Name': 'Continent'}, axis='columns')\npx.line(df, x='Date', y='Total Deaths per Million', color='Continent').show()"}, {"id": "dd36bb35-0757-43d9-807f-bed23d9d5ddb", "type": "heading", "value": "Displays a multi-axis line chart of total coronavirus cases and changes in prices of Bitcoin, Dow Jones and gold:"}, {"id": "b9a700e4-2af2-4441-8840-67869d56edcc", "type": "paragraph", "value": "<img src=\"web/covid_cases.png\" alt=\"Covid Cases\" />"}, {"id": "c21fc22f-d331-4226-bfab-4d1ecee0a229", "type": "block_html", "value": "<div id=\"e23ccacc-a456-478b-b467-7282a2165921\" class=\"plotly-graph-div\" style=\"height:285px; width:935px;\"></div>"}, {"id": "79266c79-7007-468d-8914-5bf3494aae6d", "type": "block_code", "value": "# $ pip3 install pandas lxml selenium plotly\nimport pandas as pd, selenium.webdriver, io, plotly.graph_objects as go\n\ndef main():\n    covid, (bitcoin, gold, dow) = get_covid_cases(), get_tickers()\n    df = wrangle_data(covid, bitcoin, gold, dow)\n    display_data(df)\n\ndef get_covid_cases():\n    url = 'https://covid.ourworldindata.org/data/owid-covid-data.csv'\n    df = pd.read_csv(url, parse_dates=['date'])\n    df = df[df.location == 'World']\n    s = df.set_index('date').total_cases\n    return s.rename('Total Cases')\n\ndef get_tickers():\n    with selenium.webdriver.Chrome() as driver:\n        symbols = {'Bitcoin': 'BTC-USD', 'Gold': 'GC=F', 'Dow Jones': '%5EDJI'}\n        for name, symbol in symbols.items():\n            yield get_ticker(driver, name, symbol)\n\ndef get_ticker(driver, name, symbol):\n    url = f'https://finance.yahoo.com/quote/{symbol}/history/'\n    driver.get(url + '?period1=1579651200&period2=9999999999')\n    if buttons := driver.find_elements('xpath', '//button[@name=\"reject\"]'):\n        buttons[0].click()\n    html = io.StringIO(driver.page_source)\n    dataframes = pd.read_html(html, parse_dates=['Date'])\n    s = dataframes[0].set_index('Date').Open\n    return s.rename(name)\n\ndef wrangle_data(covid, bitcoin, gold, dow):\n    df = pd.concat([bitcoin, gold, dow], axis=1)  # Creates table by joining columns on dates.\n    df = df.sort_index().interpolate()            # Sorts rows by date and interpolates NaN-s.\n    df = df.loc['2020-02-23':'2021-12-20']        # Keeps rows between specified dates.\n    df = (df / df.iloc[0]) * 100                  # Calculates percentages relative to day 1.\n    df = df.join(covid)                           # Adds column with covid cases.\n    return df.sort_values(df.index[-1], axis=1)   # Sorts columns by last day's value.\n\ndef display_data(df):\n    figure = go.Figure()\n    for col_name in reversed(df.columns):\n        yaxis = 'y1' if col_name == 'Total Cases' else 'y2'\n        trace = go.Scatter(x=df.index, y=df[col_name], yaxis=yaxis, name=col_name)\n        figure.add_trace(trace)\n    figure.update_layout(\n        width=944,\n        height=423,\n        yaxis1=dict(title='Total Cases', rangemode='tozero'),\n        yaxis2=dict(title='%', rangemode='tozero', overlaying='y', side='right'),\n        colorway=['#EF553B', '#636EFA', '#00CC96', '#FFA152'],\n        legend=dict(x=1.08)\n    )\n    figure.show()\n\nif __name__ == '__main__':\n    main()"}], "sub_concepts": [], "short_description": null, "description": null, "difficulty": null, "common_pitfalls": [], "related_concepts": [], "tags": []}, {"id": "8d1b53ab-58ed-4875-9181-b4b9a7bb3515", "name": "Appendix", "value": [], "sub_concepts": [{"id": "74668af1-6f30-43e5-8e7c-81a9887035a0", "name": "Basic Script Template", "value": [{"id": "7ded773c-1f5d-40d4-b029-52c2eddacdac", "type": "paragraph", "value": "<strong>Run the script with <code>'$ python3 FILE'</code> or <code>'$ chmod u+x FILE; ./FILE'</code>. To automatically start the debugger when uncaught exception occurs run <code>'$ python3 -m pdb -cc FILE'</code>.</strong>"}, {"id": "5bae2b21-448c-4b62-ba2f-861b66b843bf", "type": "block_code", "value": "#!/usr/bin/env python3\n#\n# Usage: .py\n#\n\nfrom sys import argv, exit\nfrom collections import defaultdict, namedtuple\nfrom dataclasses import make_dataclass\nfrom enum import Enum\nimport functools as ft, itertools as it, operator as op, re\n\n\ndef main():\n    pass\n\n\n###\n##  UTIL\n#\n\ndef read_file(filename):\n    with open(filename, encoding='utf-8') as file:\n        return file.readlines()\n\n\nif __name__ == '__main__':\n    main()"}], "short_description": "short description not provided", "description": "description not provided"}], "short_description": null, "description": null, "difficulty": null, "common_pitfalls": [], "related_concepts": [], "tags": []}]